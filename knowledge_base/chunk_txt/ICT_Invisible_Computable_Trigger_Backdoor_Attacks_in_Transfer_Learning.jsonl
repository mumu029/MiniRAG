{"[-0.05681568, 0.09496336, -0.009583035, -0.009357063, 0.056631215, 0.03407096, -0.06504289, -0.05792248, -0.07666428, 0.008854392, 0.028260268, 0.081681766, 0.0139825605, -0.05545063, 0.0022297387, -0.088248774, -0.030639885, 0.03586029, 0.009403179, 0.09385655, 0.020568015, 0.008485459, 0.0627924, 0.08455944, -0.055266164, -0.06688755, -0.024257345, 0.06448949, -0.0020014616, -0.02896124, -0.014084017, 0.09223325, 0.092159465, -0.043423414, 0.059103068, 0.063567154, -0.011704399, -0.06515357, 0.024017539, -0.02005151, -0.036856405, 0.014997127, -0.004141273, 0.014775767, 0.054048683, 0.0016002469, -0.0019080753, -0.05792248, -0.041800108, 0.020346655, -0.062238995, 0.0139825605, 0.013364598, 0.03351756, -0.008725265, 0.005003654, -0.019627236, 0.009868958, 0.04168943, 0.005340305, -0.047112744, -0.019608788, -0.010468474, -0.013143238, 0.044677787, 0.03375737, -0.0374467, -0.05253606, -0.0046554734, -0.0020129906, 0.033609796, -0.02588065, -0.012949548, -0.056557428, -0.014102464, 0.025585504, 0.0319496, -0.018345194, 0.0037377523, -0.0019933912, 0.008909732, -0.014406834, 0.020789374, 0.043644775, -0.004526347, -0.043903027, 0.009246383, -0.034937955, -0.0072356984, 0.006230356, 0.015928682, -0.0011096813, -0.038737964, 0.0063041425, 0.02505055, 0.01167673, -0.081239045, -0.004837634, 0.011252456, 0.02912726, 0.0017040092, 0.009315558, -0.017764123, -0.018160727, 0.024423365, -0.029164154, 0.01800393, -0.013060228, -0.03242921, -0.047444783, -0.010533037, -0.0036040142, 0.019737916, -0.016555868, 0.056520537, 0.03954962, 0.013300034, -0.009278665, 0.007909001, 0.008725265, 0.023667052, -0.02693211, 0.057848696, -0.019959275, -0.0067284154, 0.04202147, 0.007032785, 0.008688372, 0.019922381, 0.03265057, 0.027983569, -0.0148126595, -0.005455597, 0.03425543, -0.0076738065, 0.0068529304, -0.0059213745, 0.014517513, 0.0073140967, 0.0019611095, -0.0451574, 0.014379163, 0.049547702, -0.009094198, 0.018907815, -0.03530689, -0.01467431, 0.022560252, 0.018880146, -0.019867042, -0.016980141, 0.025253464, 0.0139825605, 0.023685498, -0.003659354, -0.014001007, -0.0064240457, 0.0003530804, -0.0012290081, -0.012303916, -0.110827476, -0.028444733, 0.009453908, -0.031064158, 0.0028523132, -0.025179677, 0.018465096, 0.02005151, -0.028057354, -0.0024142053, -0.0072356984, -0.004971372, 0.00060989236, 0.041320495, 0.008116526, -0.019073837, 0.01140003, 0.0017674196, -0.010256337, -0.017847134, -0.05076518, 0.0286292, -0.044419535, -0.0018492766, 0.008425508, -0.0058660344, -0.009232548, 0.040545736, 0.012285469, -0.021767046, -0.016684994, -0.0228554, -0.0071573, -0.020844715, -0.00020550721, -0.0035071692, 0.022394232, 0.011593719, -0.002596366, -0.022634039, -0.055745777, -0.003770034, -0.0040352046, -0.0038046215, -0.009380122, 0.003673189, 0.0026309534, -0.0056492863, -0.0040513454, 0.03698553, 0.011021873, 0.014499066, -0.0007615008, 0.02219132, -0.011547603, 0.010182551, -0.007959729, -0.0003409748, -0.0067837555, 0.0056354515, -0.021785494, -0.049215663, 0.01536606, -0.0049206438, 0.0033895718, -0.027706869, 0.021656366, 0.01406557, -0.029108813, 0.0031543772, -0.010689833, -0.039217576, -0.008005846, 0.01472965, 0.0023888412, 0.002884595, -0.030658333, -0.012552945, 0.034605917, -0.016915578, -0.023906859, 0.022154426, 0.025972882, 0.012230129, 0.013668967, 0.024570938, 0.03803699, 0.010182551, -0.0124514885, 0.006382541, 0.007899778, -0.030381633, -0.022357339, 0.02246802, -0.011861196, -0.0026032834]": "IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024 6747\nICT: Invisible Computable Trigger Backdoor\nAttacks in Transfer Learning\nXiang Chen ,B oL i u , Shaofeng Zhao , Ming Liu ,H u iX u , Zhanbo Li ,\nand Zhigao Zheng ,Member, IEEE\nAbstract —Transfer learning is a commonly used technique\nin machine learning to reduce the cost of training models.\nHowever, it is susceptible to backdoor attacks that cause models\nto misclassify data with speciﬁc triggers while behaving normallyon clean data. Existing methods for backdoor attacks in transferlearning either do not consider attack stealthiness or requirecompromising attack effectiveness for trigger concealment. Toovercome this challenge, we introduce the concept of Invisibleand Computable Trigger (ICT), which involves two criticalsteps. First, we propose a new computable trigger obtained bytraining on input data to greatly increase the attack effect duringinference. Second, we embed the trigger into an imperceptiblepertur"}
{"[-0.07683063, 0.12535524, 0.027037768, 0.0182243, 0.044885267, 0.003331472, -0.0626041, -0.042091426, -0.049370117, 0.031155007, 0.008257455, 0.06315552, -0.02711129, -0.065508224, -0.00998982, -0.11763542, 0.027423758, -0.004454982, 0.018426487, 0.06918433, 0.026945865, 0.018408107, 0.059847023, 0.0943289, -0.034445122, -0.02815898, -0.03911378, 0.04778939, 0.027368616, 0.04631895, -0.030732255, 0.103004515, 0.07962448, -0.03716544, 0.047826152, 0.013914065, 0.0044802553, -0.07076506, 0.030787395, -0.058523625, -0.019685553, 0.022810243, -0.010182817, 0.013463742, 0.053818207, -0.018987093, 0.021450084, -0.043672152, -0.033470955, 0.052274242, -0.0130042285, 0.02268158, 0.040657744, 0.045951337, -0.021597128, 0.04256932, 0.022608059, -0.010918038, 0.065214135, 0.021082474, -0.010210387, 0.002699641, -0.0141989635, 0.0014509135, 0.04396624, 0.018343775, -0.029941892, -0.06381722, 0.027019387, 0.00825286, 0.033213627, -0.029813228, 0.013436171, -0.00911215, 0.02679882, 0.037533052, 0.029298574, -0.04602486, 0.038231514, 0.0017817632, -0.0017105385, 0.001495716, 0.017728027, 0.016386246, -0.06694191, -0.04639247, 0.0050316714, -0.013289127, -0.006837559, 0.0104952855, 0.019134138, -0.005077623, -0.042753123, 0.00044142004, 0.025162952, -0.04973773, -0.03606261, -0.013629166, 0.0012154129, 0.032625448, -0.0048157, 0.014318436, -0.034500264, -0.03712868, -0.0011625688, -0.03470245, 0.014272486, -0.024133643, -0.03674269, -0.035621475, -0.0063964264, -0.053707924, 0.028820679, -0.014520623, 0.009162697, 0.0059369127, 0.0057806782, -0.0065802317, 0.014520623, 0.005288999, 0.022479394, -0.016248394, 0.05837658, -0.028416308, 0.004981125, 0.043745674, -0.008381524, 0.033213627, 0.020328872, 0.018738955, 0.02714805, -0.03126529, -0.022516156, 0.010568808, 0.0123701, -0.0013360351, -0.016873332, 0.014759569, 0.026890723, 0.009227029, -0.030327883, -0.023067571, 0.04080479, -0.0018575828, 0.011046701, 0.0042206305, 0.020457536, 0.023527086, 0.0051235743, 0.0016140407, -0.01855515, 0.016726287, 0.004811105, -0.012811233, -0.0025204308, 0.0028926367, 0.0078898445, -0.02578789, -0.032809254, 0.0015726845, -0.0783746, -0.016046207, 0.00995306, -0.021376561, -0.016082969, -0.046907127, 0.017139848, 0.010605569, -0.024280686, 0.0023641963, -0.024225546, -0.013877304, 0.021211138, 0.032864396, 0.008174743, -0.011542976, 0.013261556, 0.0065986123, -0.003104013, -0.02788327, -0.04253256, 0.024096882, -0.022001501, -0.014263296, 0.022773484, -0.004579051, 0.0027915437, 0.059810262, 0.014346007, -0.017921021, -0.0076646833, -0.03159614, -0.03718382, -0.006837559, -0.0031155008, -0.0041287276, 0.004710012, 0.00565661, 0.02885744, 0.003595692, -0.04021661, 0.0041333227, -0.012967467, -0.014621716, -0.022111783, 0.005569302, 0.016882522, -0.006350475, 0.008491808, 0.023159474, -0.009484356, 0.002111464, -0.01305937, 0.017011186, 0.004048313, -0.004121835, 0.005197096, 0.009107555, 0.005321165, -0.010274719, -0.023122713, -0.047348257, -0.012756092, 0.0045928364, 0.00093338656, -0.02301243, 0.02512619, 0.021008952, -0.07333834, 0.004027635, 0.016956044, -0.05300946, 0.01067909, 0.028342785, 0.012802043, -0.0015267332, -0.04977449, -0.006736466, 0.039334346, -0.01996126, -0.034831114, 0.043378063, 0.02984999, 0.029298574, 0.015016898, 0.0047237976, 0.014869853, 0.0013061668, -0.01580726, 0.020861907, 0.0071730036, -0.025677608, -0.032000512, 0.028030315, -0.006897296, 0.024593156]": "ticalsteps. First, we propose a new computable trigger obtained bytraining on input data to greatly increase the attack effect duringinference. Second, we embed the trigger into an imperceptibleperturbation, allowing poisoned data to appear indistinguishablefrom clean data. Our experimental results demonstrate that ourapproach outperforms state-of-the-art methods in both attackeffect and stealthiness.\nIndex Terms —Neural network, transfer learning, computer\nsecurity, backdoor attack, stealthiness.\nI. I NTRODUCTION\nDEEP neural networks have been successfully applied in\nmany ﬁelds, including object detection [1],[2], natural\nlanguage processing [3],[4]and smart healthcare [5],[6].T h e\nsuccess of deep neural networks is widely attributed to their\nenormous model scale and vast training data, as they requiretraining millions of parameters to learn valuable information\nfrom large volumes of data. However, this process is difﬁcult\nReceived 9 April 2024; revised 7 June 2024 and 3 August 2024;"}
{"[-0.05216231, 0.1041039, 0.01944131, -0.016967464, 0.013951026, -0.011992181, -0.05109552, -0.01931256, -0.02998045, 0.018126218, -0.013086559, 0.062168054, -0.06650878, -0.060034476, 0.03367743, -0.064338416, 0.01201977, -0.01690309, 0.0045867334, 0.034523502, 0.03413725, 0.035608683, 0.020673636, 0.06492699, -0.002063455, -0.033861358, -0.04171513, 0.042965848, 0.03406368, -0.014806297, 0.02460972, 0.120363235, 0.11219678, -0.0072376123, 0.01204736, 0.033291176, 0.023800433, -0.07563166, -0.000994367, -0.0037774448, -0.03571904, 0.028876876, -0.057569824, 0.008276812, 0.06260949, -0.0078445785, 0.026357047, -0.022016319, 0.00030750656, 0.026780084, -0.025161508, -0.027295087, 0.011541554, 0.03888262, 0.050506946, 0.036767438, -0.019220596, -0.015256923, 0.018889524, -0.006819173, 0.012452004, 0.02113346, -0.008640072, 0.02896884, 0.04241406, 0.022034712, -0.010723069, -0.04068513, 0.03704333, 0.044179782, 0.03566386, -0.034781, 0.00602368, -0.014171741, 0.02422347, 0.025419008, 0.059445903, -0.024278648, 0.07695596, 0.016645588, 0.011228874, 0.008915965, 0.039140124, 0.007771007, -0.010437979, -0.011587537, 0.012691111, -0.025271865, -0.014971833, -0.015983444, 0.001066789, 6.089061e-05, -0.03408207, 0.010364408, 0.037061725, -0.04226692, -0.0030992061, -0.010833427, 0.023340609, 0.026154725, 0.0037889406, -0.0108794095, -0.041126557, 0.0047867564, 0.0066444403, -0.027791694, 0.043811925, -0.018622827, -0.012028966, -0.038441192, -0.0020772498, -0.0024209674, 0.02321186, 0.037116904, 0.004379813, -0.00994137, -0.0008230829, -0.020177027, 0.019551668, 0.027534194, 0.026209904, -0.012911826, 0.039324053, -0.032978497, -0.031690992, 0.04642372, 0.027221514, -0.037300833, 0.013252095, -0.011569143, 0.032904927, -0.011477179, -0.03691458, 0.040795486, -0.0058535454, 0.021427747, -0.021795604, -0.022623286, 0.0054948833, -0.010162085, -0.031267956, 0.016268533, 0.035001718, -0.004039544, 0.0068651554, 0.0038464183, 0.027736517, 0.02896884, -0.003678583, 0.005591446, -0.04031727, 0.03382457, 0.008354981, -0.0025612134, -0.010704677, 0.041604772, -0.0138590615, -0.022476142, -0.053670526, 0.007173237, -0.060475904, -0.033309568, -0.004701689, 0.00835958, 0.025345437, -0.035259217, -0.008331991, -0.025143115, -0.017399698, -0.012479593, 0.0013622253, -0.021740425, 0.019386133, 0.022181856, -0.007872168, 0.022660071, 0.026338654, 0.01918381, -0.006773191, -0.018264165, -0.045908716, 0.001679503, 0.04605586, -0.0013334863, 0.019128632, -0.014493617, 0.0064651095, 0.018944703, -0.0006684675, -0.028030803, -0.028490625, -0.029060805, -0.017059429, -0.009922978, 0.0025957, 0.00011632082, 0.016480051, 0.020802386, 0.034339573, 0.0005132773, -0.038514763, 0.017804341, 0.0068835486, -0.026761692, -0.03590297, -0.012580754, 0.002731348, -0.03266582, 0.01988274, 0.019993098, 0.011422, 0.014475225, 0.0017059429, -0.0072468086, -0.00446488, 0.014870672, 0.0004238992, -0.0035084486, 0.01993792, -0.027203122, -0.05275088, 0.012534772, -0.01944131, -0.00534774, 0.018852739, 0.026798477, 0.007118058, 0.015146566, -0.06761236, 0.031690992, 0.0022060003, -0.067170925, -0.005743188, -0.0041476022, 0.036988154, -0.004485572, -0.022549713, 0.0132428985, 0.002391079, 0.008920563, -0.00067479006, 0.035682254, 0.005527071, 0.0026784684, 0.009821816, -0.004216576, 0.015183351, 0.010897802, -0.017087018, 0.03899298, 0.015569603, -0.022034712, -0.04057477, 0.004722381, -0.014843082, 0.009509137]": "as they requiretraining millions of parameters to learn valuable information\nfrom large volumes of data. However, this process is difﬁcult\nReceived 9 April 2024; revised 7 June 2024 and 3 August 2024; accepted\n1 October 2024. Date of publication 8 October 2024; date of current version\n31 December 2024. This work was supported in part by the National KeyResearch and Development Program of China under Grant 2023YFB4502704;\nin part by the National Natural Science Foundation of China under Grant\n62402451 and Grant 62372333; and in part by the Henan Provincial Scienceand Technology Key Project Foundation under Grant 222102210334, Grant222102210252, and Grant 222102210054. (Corresponding author: Bo Liu.)\nXiang Chen is with the College of Cyberspace Security, Zhengzhou\nUniversity, Zhengzhou 450001, China.\nBo Liu and Zhanbo Li are with the Network Center, College of Cyberspace\nSecurity, Zhengzhou University, Zhengzhou 450001, China (e-mail: liubo@\nzzu.edu.cn).\nShaofeng Zhao is with the Informa"}
{"[-0.09022991, 0.10692831, 0.022118047, 0.01456532, 0.041672744, -0.0199392, -0.058554236, -0.04383328, -0.06496261, -0.020250464, -0.014647713, 0.0653288, -0.05683313, -0.06236264, -0.015059681, -0.05408668, 0.008784051, 0.032023564, 0.0018973367, 0.037644625, 0.00449044, 0.044858623, 0.027794037, 0.09477071, -0.07019917, -0.085029975, 0.01638713, 0.029478524, 0.042112175, -0.032462995, 0.022850433, 0.09447775, 0.09081582, -0.002599969, 0.015966007, 0.017018812, 0.0066509773, -0.04335723, 0.0102625545, -0.012349853, -0.04035445, 0.051852904, -0.008234762, 0.042441748, 0.06847806, 0.045041718, 0.0030256682, -0.009530169, -0.06386403, 0.0377911, -0.047605067, 0.012386473, -0.006715061, 0.024095489, 0.028233467, 0.015499112, -0.029258808, -0.012459711, 0.01762303, -0.0089396825, 0.0056576794, -0.0193716, 0.008765741, -0.022063117, 0.03127287, 0.012935762, 0.009095315, -0.018437808, 0.02914895, 0.014867429, 0.007250618, -0.013228716, -0.011141417, 0.01200197, -0.010106922, -0.024974352, 0.009031231, -0.026402503, 0.024150418, -0.005534089, -0.007699204, -0.02043356, 0.018630061, 0.031565823, -0.045151576, -0.031602442, 0.029057402, 0.004943603, -0.012725201, -0.02398563, -0.012459711, -0.027208127, -0.036948856, -0.003748899, 0.038047437, 0.0010076024, -0.03308552, -0.03061372, 0.018144855, 0.052988105, 0.0076671625, 0.02817854, -0.021220874, 0.011617468, 0.048813503, -0.031932015, 0.055441596, -0.028489802, -0.061007727, -0.057821847, -0.008335465, -0.02805037, 0.03173061, -0.012990691, 0.037534766, -0.00086970796, 0.006097111, -0.05049799, 0.014455462, -0.0061657717, 0.012038589, 0.024882803, 0.023234935, -0.014693487, -0.012395628, 0.025651809, -0.008033356, -0.010317483, 0.04639663, -0.008578067, 0.02967993, -0.019243434, -0.05368387, 0.03940235, -0.016085021, 0.026640529, -0.02402225, -0.021623688, 0.027903894, -0.0016558783, -0.029258808, 0.0037557653, 0.046250153, -0.016414594, 0.0026915174, -0.017751198, 0.028984163, 0.02861797, 0.0029776054, -0.008683347, -0.049326174, 0.039622065, -0.0010631036, -0.0077358237, 0.0067425254, 0.016487833, -0.014574475, -0.017192753, -0.010418186, -0.005643947, -0.06884425, -0.0042203725, 0.010344948, -0.027958823, 0.018749073, -0.041233312, 0.0053921896, -0.0056256372, -0.008065397, -0.0034467902, 0.010683676, 0.00574465, -0.008321732, 0.030943295, -0.0064861905, 0.008921373, 0.015801221, 0.008372083, -0.022246215, -0.013073084, -0.029844716, 0.0033987272, -0.015206157, -0.011644932, 0.004536214, 0.025816595, -0.0047788164, 0.027940514, -0.003206476, -0.021202564, -0.040207975, -0.015581505, -0.016377974, -0.0070995637, 0.017348386, -0.0028769025, 0.009594252, 0.012441401, 0.021001158, -0.007914343, -0.021550449, 0.027958823, 0.0027899316, -0.02711658, -0.009026653, -0.01938991, -0.032389756, -0.005433386, -0.0055752858, 0.0046231844, -0.022063117, -0.0079601165, 0.008903063, 0.032353137, -0.016277272, 0.027171507, -0.0003284292, -0.012981536, 0.0013537691, -0.014748417, -0.025688427, -0.047348734, -0.019957509, 6.81605e-05, 0.00413569, -0.015691362, 0.0077358237, 0.008669616, -0.029313736, 0.0050351513, -0.020891301, -0.051303618, -0.0010636757, 0.003236229, -0.0045911428, -0.0053052185, -0.05610074, 0.0019351003, 0.002329902, -0.0005804729, -0.02303353, 0.017092051, 0.03533761, 0.025139138, 0.03314045, 0.0018801714, 0.020158915, 0.0053052185, -0.005062616, 0.04350371, 0.019591317, -0.022520859, -0.021294113, 0.021513829, -0.009905516, 0.013851244]": "1, China.\nBo Liu and Zhanbo Li are with the Network Center, College of Cyberspace\nSecurity, Zhengzhou University, Zhengzhou 450001, China (e-mail: liubo@\nzzu.edu.cn).\nShaofeng Zhao is with the Information Management Center, Henan\nUniversity of Economics and Law, Zhengzhou 450046, China.\nMing Liu is with the School of Information Technology, Deakin University,\nGeelong, VIC 3220, Australia.\nHui Xu is with the China Academy of Industrial Internet, Beijing 100020,\nChina.\nZhigao Zheng is with the School of Computer Science, National\nEngineering Research Center for Multimedia Software, Institute of\nArtiﬁcial Intelligence, Hubei Key Laboratory of Multimedia and NetworkCommunication Engineering, and the Hubei Luojia Laboratory, Wuhan\nUniversity, Wuhan 430072, China.\nDigital Object Identiﬁer 10.1109/TCE.2024.3476313for many resource-constrained users due to the signiﬁcant\nhuman and computational resources required.\nTo reduce the training cost, federated learning [7]and\ntransfer learning [8],[9]"}
{"[-0.056878258, 0.13672729, 0.0071417876, 0.014969407, 0.040052537, -0.009629068, -0.07275296, -0.033322245, -0.06419379, 0.011576829, -0.01460363, 0.06543743, -0.03888205, -0.071509324, -0.009647357, -0.09422404, -0.0012436403, 0.022550127, -0.002144365, 0.06060918, 0.009885112, 0.035827816, 0.014539619, 0.080470845, -0.033303957, -0.03902836, -0.02419612, 0.06353539, 0.032151762, 0.0026381635, -0.019294715, 0.11792637, 0.08800585, -0.019587336, 0.016789146, 0.023098791, -0.004809962, -0.05867056, 0.022989057, -0.040710934, -0.009235859, -0.00928158, 0.0051986, 0.008924948, 0.06543743, 0.024013232, 0.05735377, -0.020977287, -0.022056328, 0.029774213, -0.021050442, 0.012290093, 0.028055064, 0.02951817, 0.024159543, 0.042869017, -0.03249925, -0.0095559135, 0.0540252, 0.03763841, -0.030889831, 0.026628535, 0.0016357071, 0.009830246, 0.042686127, -0.00014745368, -0.020373756, -0.03655937, 0.016395936, 0.007905346, 0.031932294, -0.0082665505, 0.012271804, -0.005953014, 0.02170884, 0.041149866, 0.030524055, -0.037565254, 0.053001028, -0.0077544632, 0.0098393895, -0.03220663, 0.036358193, 0.04202773, -0.061304156, -0.034584176, 0.03950387, -0.046417046, -0.007155504, -0.0078001856, 0.013826354, 0.01982509, -0.01922156, 0.018361984, 0.018023642, -0.01820653, -0.0499285, -0.024891095, -0.0011647698, 0.0055872374, -0.011814583, -0.011110463, -0.06262095, -0.019166693, -0.008408289, -0.044917364, 0.018837493, -0.025860405, -0.033907488, -0.058451097, -0.019477602, -0.016697701, 0.027067468, -0.0031662534, 0.04872144, -0.0029673625, 0.013021646, -0.009857679, 0.013158812, 0.021964883, 0.0031731117, 0.008508878, 0.04312506, -0.030487478, -0.013561167, 0.02437901, -0.0066982834, -0.026902867, 0.0051711663, 0.009546769, 0.035663217, -0.014704218, -0.026683401, 0.04045489, -0.002715891, 0.034419578, -0.018407706, -0.009903401, 0.034620754, -0.003266842, -0.04136933, -0.010753832, 0.03826023, -0.0042087166, 0.005523226, -0.024763074, 0.022733014, 0.02500083, 0.021068731, 0.026171314, -0.025110561, 0.0368337, 0.00366691, -0.017319521, 0.005934725, 0.016469091, 0.00969308, -0.018837493, -0.013808066, -0.012134638, -0.07458185, -0.0302863, 0.0029970817, -0.023629166, 0.018261395, -0.035004817, 0.021123597, -0.011046452, -0.035407174, -0.002848485, 0.00093273027, -0.0032119756, 0.0115219625, 0.027616132, 0.0014973979, 0.0043801744, 0.022751303, 0.025714094, 0.007813903, -0.020483488, -0.027195489, 0.017557276, -0.012472982, -0.0059027197, -0.0025650084, 0.0024255558, 0.005806703, 0.028713461, 0.016395936, -0.023190236, -0.016816579, -0.029463304, -0.03480364, 0.004521913, 0.011357362, -0.009629068, 0.035334017, 0.0099216895, 0.048209354, -0.03484022, -0.04016227, 0.026482224, 0.0012950777, -0.015335183, -0.009322731, -0.021196753, -0.011439662, 0.023245102, -0.013716621, 0.016377646, -0.007626442, 0.017328665, -0.037437234, 0.023391413, -0.0067120004, 0.004855684, -0.013881221, -0.0026153026, 0.010561799, -0.014713363, -0.02434243, -0.015710104, -0.014457319, 0.0131496675, 0.0054683597, 0.013652611, -0.008376284, 0.004375602, -0.049452994, 0.003730921, 0.0022392385, -0.055963818, 0.005692398, 0.010186878, 0.0039069513, -0.0058569973, -0.03730921, 0.013945232, 0.004188142, -0.005518654, -0.018682038, 0.04608785, 0.014347586, 0.0030085123, 0.030359456, 0.021891728, 0.02264157, -0.00045922108, -0.00913527, 0.035900973, 0.015810693, -0.023299968, -0.019422736, 0.013552022, -0.010442921, 0.026134737]": "9/TCE.2024.3476313for many resource-constrained users due to the signiﬁcant\nhuman and computational resources required.\nTo reduce the training cost, federated learning [7]and\ntransfer learning [8],[9]have been widely used in the training\nprocess. The main idea is to use a model trained on thesource domain to accelerate the learning speed and improve the\nlearning effect on the target domain by sharing its knowledge\nand features. This greatly reduces the annotation budget andtraining cost. A common transfer learning technique involves\nusing a pre-trained model, where some of the parameters of\nthe model are frozen, and the later layers of the model are ﬁne-tuned for a new task. This reduces the number of parameters\nneeded to train the model.\nThe security issues of deep learning models have been\nbrought to light due to their sensitivity to training data [10].\nWhen a user needs to train a model, they may have to down-\nload data from an untrusted third party, which could result in a\nbackdoor"}
{"[-0.036664583, 0.107990526, -0.03232732, 0.018010672, 0.044916414, 0.0050953664, -0.08549556, -0.026005207, -0.03199651, -0.004851855, -0.020289574, 0.09983059, -0.05892063, -0.0698373, -0.0204366, -0.10828458, -0.024865756, 0.0039214566, -0.022256047, 0.085936636, 0.0408732, 0.024424678, 0.013186386, 0.09850735, -0.033742443, -0.07097676, -0.051459067, 0.06171412, 0.037252687, 0.010493973, -0.035396487, 0.085936636, 0.09306739, -0.02962572, 0.06281681, 0.045283977, -0.02295442, -0.070939995, 0.024424678, -0.0061567095, -0.029129507, 0.024645217, -0.027089523, 0.0041374005, 0.019830119, 0.008541286, 0.017679865, -0.043299127, -0.025894936, 0.012506391, -0.0054261745, 0.01752365, 0.02731006, 0.022917662, -0.0036503775, 0.00688265, -0.043850474, -0.010062085, 0.023946844, 0.021226864, -0.022715501, 0.021447403, -0.008688312, 0.006965352, 0.034128387, 0.038557544, 0.0066391383, -0.055318497, 0.035506755, 0.020510113, 0.051863387, -0.026041962, -0.011082077, -0.059361707, 0.03670134, 0.014969074, 0.028596537, -0.005357256, 0.026336014, 0.012524769, 0.00066735974, 0.012239906, 0.02096957, 0.047746662, -0.03297056, -0.018313915, 0.027273305, -0.014509618, -0.028486269, 0.016926358, 0.030893818, -0.008339126, -0.034790006, -0.003112814, 0.020381466, -0.01000695, -0.049878538, -0.043666694, -0.004525641, 0.016145281, 0.0034436223, 0.022053884, -0.0337792, -0.026942497, 0.02012417, -0.05068718, 0.044916414, -0.03357704, -0.028596537, -0.04954773, 0.0015862717, -0.026924118, 0.03438568, 0.014923129, 0.05535525, 0.004819693, 0.02784303, -0.008660745, 0.011229103, -0.009189119, -0.0005200467, -0.02034471, 0.05138555, -0.016329065, -0.0036090263, 0.02534359, 0.00625779, -0.00928101, 0.033724066, 0.03172084, 0.05142231, -0.024332786, -0.033356503, 0.032676507, -0.008536692, 0.011624236, -0.013112873, -0.016448522, 0.015382585, 0.0024420084, -0.04388723, 0.002554575, 0.058148745, -0.01146802, 0.027291683, 0.0010636405, -0.00021292911, 0.02701601, 0.011238293, -0.0040041585, -0.029258154, 0.023505766, 0.022972798, 0.00824264, -0.014748536, -0.011495587, -0.015492855, -0.012331798, -0.016907979, -0.029735988, -0.07843832, -0.02617061, 0.043299127, -0.016071768, -0.0014231647, -0.023413874, 0.007254809, 0.0016942438, -0.013930704, -0.0064369775, -0.013792868, -0.01668744, 0.037362956, 0.025178185, 0.0052699596, -0.00959344, 0.016862033, 0.034275413, 0.004091455, -0.013287466, -0.034863517, 0.02554575, -0.015005831, 0.001884918, -0.01188153, -0.0020043766, -0.014647455, 0.051275283, -0.0013887056, -0.02023444, -0.012837199, -0.019977145, -0.020987947, 0.00016913722, 0.0055548223, -0.0019400527, 0.013498816, 0.012671795, 0.019168502, -0.025839802, -0.035378106, -0.008986958, 0.014509618, -0.046533696, -0.034863517, -0.009556684, 0.012570715, 0.008766419, -0.017284732, 0.027291683, -0.0034528114, 0.031004086, -0.030324092, 0.030820305, -0.028155461, 0.015621502, 0.0127636865, -0.01470259, 0.0090880385, -0.0008626285, -0.019039854, -0.03252948, -0.016981492, 0.0036205128, -0.001559853, -0.019958766, 0.0056191464, 0.03951321, -0.04807747, 0.018332291, 0.0084448, -0.035065677, -0.0072915656, 0.0062302225, -0.009823168, -0.01563988, -0.013967461, 0.025784668, 0.015263126, 0.0060326564, -0.021043083, 0.03203327, 0.011955043, 0.0048426655, 0.01365503, 0.0013760705, 0.020730652, 0.013737733, -0.015355018, 0.037859168, -0.008775609, -0.04506344, -0.03495541, 0.042711023, -0.029533828, -0.0061750878]": "en\nbrought to light due to their sensitivity to training data [10].\nWhen a user needs to train a model, they may have to down-\nload data from an untrusted third party, which could result in a\nbackdoor attack [11],[12],[13]. The attacker chooses a trigger\nthat activates the backdoor, causing the model to misclassifydata marked with the trigger. If a model deployed on a\nCyber-Physical System (CPS) or Consumer Electronics (CE)\nis attacked, the consequences could be severe [14],[15],[16].\nFor example, a consumer-facing electronic device [17] that has\nbeen implanted with a backdoor may recognize an expensive\nitem as a cheap drink, causing problems when the user pays.\nCommon data poisoning attacks [18],[19] will completely\ndestroy the accuracy of the model, so subsequent work [20]\nproposed targeted data poisoning attacks. However, the attackonly makes the model misclassify a ﬁxed amount of the data\nand lacks generalization. Backdoor attacks are more ﬂexible,\nas shown in Figure 1, for any ima"}
{"[-0.029166592, 0.11843404, 0.0037079689, 0.018578973, 0.04323432, -0.0071351356, -0.07070689, -0.038741484, -0.0338988, -0.0058968444, -0.027693532, 0.050194528, -0.0026238887, -0.034303892, 0.025152504, -0.11534062, -0.017133532, 0.01007205, -0.014371544, 0.09803216, 0.06963892, 0.022666715, 0.0216724, 0.100389056, -0.044154983, -0.029682165, -0.0519622, 0.061095174, 0.007774996, 0.044633728, -0.024029296, 0.090887815, 0.06934431, -0.03045552, 0.06602993, -0.00046982567, -0.039036095, -0.06823952, 0.015384273, -0.024765825, -0.007756583, -0.003491613, -0.03067648, 0.01768593, 0.028080212, 0.002064586, 0.022611475, -0.06481465, -0.04555439, 0.027546227, 0.019536462, 0.015955083, 0.03922023, 0.024360733, -0.036642373, 0.007328475, -0.04374989, -0.001836722, 0.040803768, 0.040803768, -0.024581693, 0.014988388, -0.015485546, 0.023753097, 0.03133936, 0.03719477, -0.016240489, -0.041356165, 0.06231045, -0.003157873, 0.047064275, -0.036863334, -0.010707307, -0.008235328, 0.02309022, 0.054024484, 0.031155225, -0.0058692247, 0.046659183, 0.01165559, 0.024434388, 0.008539146, 0.021414613, 0.007949922, -0.059843075, -0.009482825, 0.0075448304, -0.019683767, -0.02134096, 0.00043645164, 0.035077248, 0.0046792678, -0.051372975, -0.0060809767, 0.025833795, -0.023219112, -0.044007674, -0.027711947, 0.004630933, 0.019996792, 0.009768231, 0.010090463, -0.014620123, -0.014445197, -0.00045313867, -0.044191808, 0.044523247, -0.01525538, -0.033364814, -0.04839003, 0.0021681606, -0.052404117, 0.025668075, -0.000278932, 0.038225915, -7.883174e-05, 5.268636e-05, -0.015697299, -0.010845406, -0.021543507, 0.010467934, -0.04551756, 0.03888879, -0.016406208, -0.0059290677, 0.034635328, 0.0030082653, 0.010817787, 0.020420298, 0.01768593, 0.021488266, -0.017069086, -0.022261623, 0.01364422, -0.0042189364, -0.002332729, -0.022427343, -0.0049623717, 0.018358013, -0.0067070276, -0.05755983, -0.016884953, 0.057486176, -0.003452485, 0.026515085, 0.012410533, 0.020475538, 0.029682165, 0.0074849874, 0.012880071, -0.021930184, 0.009584098, 0.013561361, -0.0064584487, -0.021893358, -0.02666239, -0.013202302, -0.025557596, -0.0002901526, -0.00987871, -0.071406595, -0.031449836, 0.032131128, -0.02450804, -0.01473981, -0.036476653, 0.025428703, 0.0031555712, -0.024600105, 0.015973497, 0.006347969, -0.0049025286, 0.03249939, 0.010698101, 0.010826993, -0.00014342197, 0.030013602, 0.03717636, -0.00836422, -0.020751737, -0.021764465, 0.018984064, -0.014040106, -0.0017676724, 0.0020323629, -0.0153658595, -0.010965092, 0.05744935, 0.009271073, -0.03452485, -8.228423e-05, -0.0014580995, -0.035592817, 6.3727115e-05, 0.010173323, -0.011001918, 0.020567603, -0.008018971, 0.03796813, -0.016056357, -0.04374989, 0.0049301484, 0.007392921, -0.02767512, -0.024084534, 0.0071949787, 0.002821831, 0.024268668, -0.010320628, 0.0053536533, -0.0044790236, 0.026533497, -0.024305495, 0.031707622, 0.0023799129, 0.015503959, -0.00032453358, 0.0068359203, 0.015955083, -0.0078762695, -0.027306855, -0.03249939, -0.019794248, 0.016443035, -0.0028471493, -0.014058519, 0.033475295, 0.017676722, -0.05417179, 0.0030589018, 0.016737647, -0.038925618, 0.008308981, 0.006923383, 0.008290567, -0.008681849, -0.033383228, 0.018440872, 0.0032545426, 0.012861657, -0.040840596, 0.029056113, 0.012447359, 0.028153865, 0.01975742, -0.003705667, 0.04330797, 0.0035790761, -0.02947962, 0.02614682, 0.0033443072, -0.031670794, -0.039588496, 0.032223195, -0.03062124, 0.019775834]": "ted data poisoning attacks. However, the attackonly makes the model misclassify a ﬁxed amount of the data\nand lacks generalization. Backdoor attacks are more ﬂexible,\nas shown in Figure 1, for any image, only the backdoor\nis activated when the trigger appears, causing the model to\noutput the label speciﬁed by the attacker [21],[22]. Backdoor\nattacks are also different from adversarial sample attacks\n[10],[23],[24] that require the attacker to be able to control\nthe inference process of the model. The generation of eachadversarial sample requires backpropagation, which will make\nthe attack easy to detect. Once the trigger in a backdoor attack\nis selected, it does not need to be changed. In the inferencephase, any picture patched with a trigger will cause the model\nto misclassify.\nIn many existing attack methods, the choice of trigger is\nusually arbitrary, and it can be any meaningful or meaningless\npattern [12],[14],[29]. But such triggers have two drawbacks:\nﬁrst, such triggers are det"}
{"[-0.043561764, 0.101742566, -0.0151358675, 0.021079464, 0.052421786, -0.026487768, -0.084687024, -0.04614594, -0.055264376, -0.02964415, 0.0003547469, 0.07486717, 0.04160518, -0.0665609, 0.018458376, -0.09066754, -0.025177224, 0.016603308, -0.029385732, 0.06667165, 0.07158158, 0.027392229, 0.027650645, 0.12418795, -0.033908036, -0.05747938, -0.07438725, 0.056667212, -0.0081309145, -0.013677656, -0.028573565, 0.047917943, 0.079001844, -0.044115517, 0.07497792, 0.0049560736, -0.048582442, -0.042306595, 0.011951798, -0.009856773, -0.058992967, -0.014222178, 0.016750975, 0.0021388642, -0.004669969, -0.013816094, 0.019436669, -0.03828267, -0.004547682, 0.02907194, -0.0008998458, 0.029699525, 0.042417347, 0.033520408, -0.016215682, 0.013003925, -0.001437446, 0.005076053, -0.014914367, 0.053750787, 0.009012301, -0.002960262, -0.038762588, 0.0379135, 0.060469635, 0.025970934, -0.008306269, -0.044669267, 0.027466062, -0.018624501, 0.028961191, -0.019436669, -0.03171149, -0.03283745, 0.021983925, 0.023460595, 0.043340266, 0.0055144397, 0.04463235, 0.01340078, 0.011767214, 0.015717307, 0.022519218, 0.037802752, -0.05932522, -0.030622445, -0.01919671, -0.007678684, -0.026321642, 0.0067373067, 0.03953784, -0.026746185, -0.061983224, 0.025048016, -0.018403, -0.0050160633, -0.03771046, -0.042195845, 0.01987967, 0.053012453, 0.0033686534, 0.020507256, -0.0037332063, -0.0018469911, -0.007267985, -0.05352929, 0.042158928, -0.034720205, -0.033686534, -0.036270708, -0.006792682, -0.053566206, 0.038688753, 0.03532933, 0.053307787, -0.007932487, -0.0074571837, -0.028296689, 0.02759527, 0.006852672, 0.03211757, -0.045407604, 0.058771465, -0.02693077, -0.010013669, 0.031951446, 0.016640225, 0.027927522, 0.032412905, -0.0038970243, 0.03865184, -0.03211757, -0.033188157, 0.042343512, 0.010742774, -0.020248838, -0.009104594, 0.026764644, 0.0140006775, -0.0039039464, -0.06021122, -0.005325241, 0.054599874, -0.012477862, 0.005749784, -0.0036270707, 0.033077408, 0.02816748, 0.015301993, -0.016944788, -0.006566567, 0.0077755903, 0.025361808, 0.0024457348, -0.033612702, -0.015154326, -0.020821048, -0.020082712, -0.0067050047, -0.0056390334, -0.07147083, -0.022168508, 0.0066542444, -0.008601603, -0.014554429, -0.029791817, 0.008075539, -0.0026257038, -0.028924273, 0.015588097, -0.0016128005, 6.918285e-05, 0.021540923, 0.03865184, 0.0074341106, -0.001601264, 0.026635434, 0.009169198, 0.0055605853, -0.0037793522, -0.03486787, 0.02646931, -0.00431926, -0.007397194, 0.0017927696, 0.00032532887, 0.0042015878, 0.068111405, -0.0049376152, -0.022094674, -0.006894203, 0.009418386, -0.0036639874, 0.007064943, 0.014849762, 0.003403263, 0.012634758, 0.007618694, 0.03125003, 0.0013382322, -0.050723616, -0.0005629804, 0.00966296, -0.020968715, -0.0040839156, 0.004268499, 0.011195005, 0.001227482, -0.013373093, 0.017821562, 0.028758148, 0.009459917, 0.003077934, 0.030530153, 0.0084354775, 0.031139279, 0.008721583, -0.004141598, 0.025380265, 0.002067338, -0.018901376, -0.030585527, -0.020544171, 0.007969404, -0.014028365, -0.01737856, 0.01226559, 0.010936587, -0.036178414, -0.0019658168, 0.007166464, -0.017793873, -0.010299773, -0.004997605, 0.0008900398, -0.024032805, -0.02157784, -0.011970256, 0.009381469, -0.0038993317, -0.031397697, 0.015154326, 0.027761396, 0.013954531, 0.034941703, 0.013493072, 0.024826514, 0.021559382, -0.038135003, 0.03715671, -0.017858477, -0.023460595, -0.01932592, 0.05600271, -0.011628776, -0.003793196]": "isting attack methods, the choice of trigger is\nusually arbitrary, and it can be any meaningful or meaningless\npattern [12],[14],[29]. But such triggers have two drawbacks:\nﬁrst, such triggers are detectable, and poisoned data can beeasily identiﬁed. Then the user may refuse to use the data\n1558-4127 c/circlecopyrt2024 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\nSee https://www.ieee.org/publications/rights/index.html for more information.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6748 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nTABLE I\nTHECOMPARISON OF DIFFERENT ATTACK METHODS ACROSS VARIOUS CHARACTERISTICS\nFig. 1. An illustration of a backdoor attack, where the backdoor is activatedonly when the trigger is present, leading to misclassiﬁcation by the model.\nset. Second and more importantly, in the context of transf"}
{"[-0.060939718, 0.14220509, 0.009092564, 0.007105601, 0.036277186, -0.02131215, -0.07389453, -0.039943993, -0.042512618, 0.04545351, -0.040986333, 0.08725883, 0.009348495, -0.057775468, 0.022652302, -0.10996697, 0.008403874, -0.016044606, -0.011140019, 0.0941085, 0.000784664, 0.026635533, 0.048468854, 0.09887348, -0.04735206, -0.06648646, -0.06637478, 0.057589337, 0.0010150027, 0.030860737, -0.020232582, 0.06354557, 0.07612812, -0.02697057, 0.04999514, 0.0058585145, -0.053866692, -0.04094911, 0.015002265, -0.015607194, -0.018417792, -0.024159973, -3.5881367e-05, -0.011875241, 0.026393563, 0.0004996489, 0.05483458, -0.02298734, -0.036668066, 0.030041754, 0.02120047, 0.03501149, 0.05483458, 0.0471287, -0.03208921, 0.039497275, -0.032591768, 0.010693301, -0.005900394, 0.04400168, -0.026337722, 0.0483944, -0.020809593, 0.00910187, 0.03253593, 0.029315839, 0.0004426459, -0.043703865, -0.0038133857, -0.0007515092, 0.03772902, -0.020418715, -0.015002265, -0.03761734, 0.02752897, 0.052265953, 0.017850088, -0.002829211, 0.047612645, 0.020120902, 0.0151697835, -0.0078687435, 0.011623963, 0.03104687, -0.05986015, -0.010665381, -0.011261005, -0.005407144, -0.016081832, -0.009292656, 0.05334552, 0.012610464, -0.050032366, 0.0030432632, -0.008361994, 0.00086377026, -0.03128884, -0.04809659, -0.00082712545, 0.01946944, -0.0004915056, 0.0043205963, -0.012014841, -0.035123166, 0.011884548, -0.04872944, 0.032815125, -0.042438168, -0.024327492, -0.04798491, 0.0122382, -0.05505794, 0.012638384, -0.011772868, 0.044522848, 0.0047556804, 0.017273078, 0.005081412, 0.0451557, -0.0041298107, -0.018101368, -0.036686677, 0.04366664, -0.029185547, -0.010786368, 0.014723066, 0.012145134, 0.041842543, 0.0015565314, 0.02425304, 0.0496601, -0.022782594, -0.045379058, -2.2157743e-05, -0.013987843, 0.0061795926, -0.0011080689, 0.014443867, 0.014118136, 0.0147137595, -0.060493, -0.029818397, 0.07296386, -0.010991113, 0.009357802, 0.0028478242, 0.019153016, 0.041619185, 0.024457786, -0.009464828, -0.020455942, 0.030730445, 0.023359604, -0.005830595, 0.0008928534, -0.018064141, -0.0064169113, -0.037635952, -0.025742099, -0.0069380817, -0.04504402, -0.030544313, 0.019711412, -0.013215394, 0.000137418, -0.043629415, 0.034788128, 0.018343339, -0.015383836, 0.015886392, -0.013187475, -0.017031107, 0.046868116, 0.033447977, 0.026747214, 0.0035039408, 0.014825438, 0.03385747, 0.012442945, -0.020027837, -0.024960343, 0.022503396, -0.014518321, -0.01691012, -0.006142366, 0.01264769, 0.0064820577, 0.050367404, 0.00039611282, -0.025109248, -0.01999061, -0.03443448, -0.010870127, 0.0028920309, 0.0009411315, -0.006370378, 0.0021928712, -0.007003228, 0.028757442, -0.018250274, -0.058371093, 0.005095372, 0.015216316, -0.0018264233, -0.02315486, 0.014667226, 0.007971116, 0.0127686765, -0.0103024235, 0.01664023, 0.014192589, 0.021498282, -0.050516307, 0.051968142, 0.015095331, 0.0013436426, 0.012368492, -0.009506708, 0.029948689, 0.0019113462, -0.019618345, -0.048431627, -0.0106281545, 0.0042973296, 0.018380566, -0.02281982, 0.023489898, 0.022038065, -0.050032366, 0.010321037, 0.005830595, -0.042214807, -0.012889663, 0.0021230716, 0.020344261, -0.020027837, -0.027138092, 0.0035737404, -0.0033527082, 0.009716107, -0.018296806, 0.0413586, 0.009809173, 0.007166094, 0.01094458, -0.0127686765, 0.021554122, 0.0075709317, -0.04169364, 0.02229865, -0.0014122789, -0.03030234, -0.027175317, 0.04735206, -0.014788212, 0.011623963]": "illustration of a backdoor attack, where the backdoor is activatedonly when the trigger is present, leading to misclassiﬁcation by the model.\nset. Second and more importantly, in the context of transfer\nlearning, the use of such a common static trigger to implanta backdoor will lead to an unsatisfactory attack success rate.\nThis is because ﬁne-tuning the model only involves minor\nweight adjustments\n1to preserve the original classiﬁcation\ncapabilities of the model. However, these small weight changes\nare not enough to mitigate the model’s inherited classiﬁcation\ncapabilities. This then inspires us to raise the followingtwo questions: 1) for the invisible backdoor attack on the\npre-trained model [26], can we use more targeted triggers\naccording to the speciﬁc model, to improve the attack success\nrate? 2) while improving the success rate of the attack, can\nwe ensure that the stealthiness of the attack is not affected,and can we use the improvement of the attack performance to\ndesign more "}
{"[-0.07362861, 0.1221011, 0.011404738, 0.037809286, 0.050800364, 0.019899625, -0.07437954, -0.060712628, -0.04839739, -0.013770165, -0.031219883, 0.06457992, -0.023241261, -0.060750175, -0.004099604, -0.09574348, -0.04223977, 0.031820625, -0.027634196, 0.033134755, 0.07922304, -0.00033293152, 0.029830664, 0.084554635, -0.030525275, -0.06330334, -0.052302223, 0.07088772, 0.011123139, 0.035650365, -0.03234628, 0.11173827, 0.08658214, -0.02399219, 0.03503085, 0.03991189, -0.013751392, -0.045994416, 0.038428806, -0.079673596, -0.029211149, 0.0026939586, 0.013047395, -0.033134755, 0.021026019, -0.017731316, 0.008635687, -0.023954643, -0.002813638, 0.07892267, 0.008767099, 0.014342749, 0.038785495, 0.051063187, 0.0006077834, 0.049298506, -0.031576574, -0.018754458, 0.018604273, 0.012878437, -0.040700365, 0.021645535, -0.045055754, -0.018012915, 0.029192375, 0.008208595, -0.010006133, -0.041676573, -0.037527688, -0.0026470255, -0.00013067928, -0.045168396, -0.039724156, -0.015375276, 0.02213364, 0.02341022, 0.010118771, -0.03208345, 0.041413747, -0.008081876, 0.014877786, -0.010972953, 0.00036197135, 0.050762817, -0.07212675, -0.036307428, 0.010447303, -0.029736798, -0.02776561, 0.018510407, 0.032102227, 0.008490194, -0.061463557, -0.0025930526, 0.00976208, -0.011921002, -0.05921077, -0.021476576, 0.020932153, 0.009541495, -0.033472672, -0.00084831537, -0.036176015, -0.030431408, 0.0011275671, -0.026000924, 0.015440983, -0.032984566, -0.014530481, -0.03649516, -0.014859012, -0.06476765, 0.013610593, 0.00037663794, 0.040625274, -0.0028793444, 0.0155536225, -0.021589216, 0.045468766, 0.008663846, 0.03125743, -0.0041418443, 0.024029735, -0.050237168, 1.0651609e-05, 0.034092188, -0.01871691, 0.03735873, 0.027239958, 0.0047965604, 0.054517463, -0.015600556, -0.014417842, 0.040925644, -0.00044351758, 0.010944794, -0.0077674245, 0.007302787, 0.020725647, -0.0014701787, -0.026582895, -0.013864031, 0.03711468, -0.014032991, 0.03696449, -0.015056131, 0.019993491, 0.019317655, 0.0053175176, 0.009799627, -0.0379407, 0.015478529, 0.022865796, 0.018163102, -0.017712543, -0.029173601, -0.002630599, -0.020950926, -0.02922992, -0.024855759, -0.042202223, -0.013028623, 0.019955944, -0.008386941, 0.008081876, -0.04892304, 0.017562358, -0.008311848, -0.033885684, -0.0077533447, -0.027108546, -0.013957897, 0.05083791, 0.012456039, 0.014887173, 0.0039963517, 0.03056282, -0.016698789, -0.0008817552, -0.035875645, -0.012521746, 0.024086056, -0.03818475, -0.015713194, 0.009480482, -0.010409757, 0.0122026, 0.03782806, -0.016238846, -0.0105130095, -0.01528141, -0.014455388, -0.028892003, 0.002834758, 0.028291259, 0.0008371688, 0.0035763006, 0.0069601755, 0.013357154, -0.0067583635, -0.043103337, -0.0059839673, 0.015638102, -0.017384011, -0.03504962, -0.013122489, 0.016022952, 0.010043679, 0.0062937257, 0.018097395, -0.0022656943, 0.010963567, -0.024123602, 0.019148696, -0.0072511607, 0.0018503366, -0.012624998, -0.011573697, 0.042089585, 0.002799558, -0.035387542, -0.039536424, -0.018050462, -0.01614498, 0.029586613, -0.0217394, 0.004392936, 0.028197393, -0.065556124, -0.018303901, 0.013976671, -0.041338656, 0.004805947, -0.028103527, 0.0060309004, -0.013009849, -0.014624347, 0.011808363, 0.010888474, -0.008992378, -0.017196279, 0.022847023, 0.014943492, 0.013000462, 0.0050969324, 0.010860315, 0.009977972, 0.002684572, -0.02742769, 0.01467128, 0.0029380107, -0.022678064, -0.016895909, 0.03841003, -0.0074435864, 0.0031750228]": "cess\nrate? 2) while improving the success rate of the attack, can\nwe ensure that the stealthiness of the attack is not affected,and can we use the improvement of the attack performance to\ndesign more stealthy attacks?\nTo answer these two questions, we propose a novel trigger\ndesign method. More speciﬁcally, we propose a new trigger\ngeneration algorithm that makes the triggers more targeted —\ndifferent models would use different triggers, which greatlyimproves the success rate of invisible backdoors in transfer\nlearning. In addition, in order to make the attack more stealthy,\nwe will generate a tiny perturbation to replace the function ofthe trigger, and will not modify the label of the poisoned data.\nThis makes the poisoned data not only appear the same as the\nclean data but also their label is not replaced. (Most existingattack methods require modifying the poisoned data’s label\n[30],[31],[32]). Through the integration of these two phases,\nour methodology has secured the foremost perf"}
{"[-0.07531563, 0.0825852, -0.020480243, 0.018773556, 0.047455125, -0.05594243, -0.065093964, -0.021126017, -0.031735152, -0.024742348, -0.026163049, 0.086201526, -0.00093406514, -0.043285273, -0.004047616, -0.089891665, -0.011725401, 0.022731226, -0.036550775, 0.07631197, 0.04738132, 0.04243654, 0.034668807, 0.09446743, -0.032602333, -0.07509422, -0.059411157, 0.06199425, 0.002453939, 0.030831069, -0.01874588, 0.089670256, 0.07660718, -0.007818472, 0.033008248, 0.036587678, -0.041144993, -0.075131126, 0.009349877, -0.040849783, 0.004432773, -0.008459632, 0.0019200229, 0.004181383, 0.008980864, 0.009183821, 0.01542476, -0.031034026, -0.032399375, 0.06789847, 0.009815756, 0.040296264, 0.05428187, -0.020055879, 0.00057917804, 0.023930518, -0.016753208, 0.029096706, 0.018404543, 0.052732013, -0.014778987, -0.00028800342, -0.01692849, -0.007823084, 0.025775585, 0.034539655, -0.015507788, -0.037602466, 0.03420754, -0.00244702, 0.029576425, -0.0014910448, -0.0578982, -0.030904872, 0.0468647, 0.02671657, -0.030609662, -0.023210943, 0.045536254, 0.010526107, 0.00875023, 0.013948706, 0.011125754, 0.030498957, -0.04273175, -0.018653627, -0.011808429, -0.0371412, 0.009160758, -0.004995519, 0.06199425, 0.0089900885, -0.03915232, 0.027196288, 0.045019634, -0.040370066, -0.04465062, -0.048894275, 0.02125517, 0.05616384, -0.023229394, 0.033524867, -0.023026437, 0.0044350796, -0.011181106, -0.022841929, 0.036698382, -0.021495031, -0.0030697302, -0.048931178, -0.024705447, -0.03907852, 0.0261815, -0.034908667, 0.037657816, -0.00037535583, 0.03465036, -0.018349191, 0.027712906, -0.015369408, 0.012361948, -0.042805552, 0.028487835, -0.013708848, -0.014345395, 0.052399904, -0.013247581, 0.015341732, 0.03754711, 0.020461792, 0.04191992, -0.010867445, 0.005950341, 0.031310786, 0.008007591, -0.014400748, -0.0026246079, 0.00814597, 0.025554178, -0.013791876, -0.039336827, 0.0094282925, 0.06310129, -0.021402776, 0.021587284, -0.0033903106, 0.002460858, 0.014677508, 0.014954268, 0.005821186, -0.041181896, 0.007361817, 0.026624316, 0.009557447, 0.0043382137, -0.028856847, 0.030831069, -0.017149897, -0.010212446, -0.009040828, -0.053248633, -0.025683332, 0.039558236, -0.0049032653, -0.0041767703, -0.028967552, 0.021679537, 0.016328843, -0.050185822, 0.0022971083, 0.014336171, -0.010839769, 0.014188565, 0.039705843, 0.011218008, 0.009105406, 0.030757267, 0.010516882, 0.01862595, -0.00064980955, -0.029152058, -0.00013247004, 0.003150452, -0.019963624, 0.015784549, -0.0031250822, -0.015240253, 0.0413295, -0.010000263, -0.030646563, 0.013588918, -0.018911937, -0.0165318, -0.0051846383, -0.01475131, 0.011587021, 0.019889822, -0.011651598, 0.021661086, 0.006614565, -0.04155091, -0.00503242, -0.017398981, -0.029650226, -0.025830938, -0.0018485265, 0.024170378, 0.01336751, 0.015738422, 0.028727693, -0.028063469, 0.0358312, -0.029318115, 0.040739078, -0.021033764, 0.0110980775, 0.0015786855, 0.0026592028, 0.03996415, -0.007952238, -0.04155091, -0.0013549711, -0.0038054506, -0.011909908, 0.008238224, -0.028709242, 0.0056366795, 0.017565038, -0.034244444, 0.013441313, 0.008593399, -0.030609662, 0.005502912, -0.005613616, 0.015729196, -0.020277286, -0.03549909, 0.016273491, 0.0042528794, -0.0082336115, -0.0127032865, 0.025406573, -0.005147737, 0.010895121, 0.0021126017, 0.014170114, 0.031089379, 0.01405941, -0.030129943, 0.025775585, -0.0005884034, -0.013607369, -0.0068821, 0.061034817, -0.007993753, -0.005156962]": "el is not replaced. (Most existingattack methods require modifying the poisoned data’s label\n[30],[31],[32]). Through the integration of these two phases,\nour methodology has secured the foremost performance onvarious attributes, as delineated in Table I.\nIn particular, the main differences between our approach and\nprevious similar approaches [26] are: 1) this work investigates\nthe behavior of dynamic model-dependent invisible triggers in\nbackdoor attacks, whereas previous work used static triggers\n1Without loss of generality, we assume that the user ﬁne-tunes only the\nlast layer of the model due to resource constraints.that were pre-speciﬁed by the attacker. 2) We try to attack\nthe model under the setting of multi-class classiﬁcation, which\ngreatly increases the difﬁculty of attack for the attacks of\ninvisible triggers and clean labels, while the previous attackmethods can only be carried out under the condition of binary\nclassiﬁcation [26], which limits the generalization ability of "}
{"[-0.070033565, 0.10887602, -0.00958248, 0.024930924, 0.0461277, -0.01679451, -0.07841709, -0.06604315, -0.03051384, 0.005907824, -0.026212249, 0.065933324, 0.01383831, -0.047994774, -0.0053037703, -0.083688825, 0.009111136, 0.016098933, -0.016089782, 0.05579255, 0.048360866, 0.042430162, 0.066519074, 0.11502638, -0.035144914, -0.10704555, -0.055755943, 0.04221051, -0.013133582, 0.028518634, -0.03946481, 0.06999695, 0.058135547, -0.008429288, 0.07841709, 0.03953803, -0.03106298, -0.08573895, 0.023979083, -0.037634347, -0.023320116, 0.011330574, -0.01608063, -0.018734802, 0.030458927, 0.007001526, 0.011769885, -0.06282154, -0.031923298, 0.05033777, -0.0048507303, 0.005093267, 0.05132622, 0.008745044, -0.023924168, 0.009573328, -0.00551885, -0.036316413, 0.020409677, 0.021471346, -0.039318375, 0.0025191766, -0.015915887, 0.015046417, 0.017517544, 0.06794684, -0.01284986, -0.05227806, 0.055243414, -0.02767662, 0.06263849, -0.033643935, -0.03950142, -0.0461277, 0.022679454, 0.045944653, -0.002791458, -0.03375376, 0.035620835, 0.034595776, -0.00865352, -0.016373504, 0.008356069, 0.050374378, -0.038037047, -0.029378952, -0.015586403, 0.008937242, -0.037524518, 0.0028806932, 0.033204623, 0.01510133, -0.05542646, 0.0075094798, 0.040819354, -0.0150189595, -0.026157334, -0.06285814, 0.0137101775, 0.03055045, -0.030660277, 0.017407715, -0.017563306, -0.012227502, -0.016895186, -0.025480064, 0.04308913, -0.022990631, -0.026596647, -0.054511227, -0.0126027465, -0.054584447, 0.018853782, -0.016812814, 0.03346089, -0.0013042059, 0.0140122045, -0.02515058, 0.016034868, -0.005120724, 0.030385708, -0.03598693, 0.04726259, -0.008667248, -0.0077062547, 0.0331131, 0.002592395, 0.013215953, 0.036060147, 0.022844195, 0.049093053, -0.022807585, -0.014753543, 0.023320116, 0.01561386, -0.00057373615, -0.0017126282, -0.0046905647, 0.014286774, -0.0015776315, -0.04828765, -0.018460233, 0.074133806, -0.020574419, 0.019183267, -0.011120071, 0.0034092397, 0.016510788, 0.0053678364, 0.019585969, -0.03181347, 0.022093704, 0.0128040975, -0.0014964045, -0.011559382, -0.02097712, -0.008914361, -0.008955547, -0.02432687, -0.004415995, -0.072523, -0.027420355, 0.023905864, -0.029983006, -0.02873829, -0.037268255, 0.011458707, 0.027127482, -0.029561998, -0.01395729, 0.0030637397, 0.0024894315, 0.016529093, 0.037634347, 0.013161038, 0.007230334, 0.018542603, 0.010991938, 0.012364786, -0.019366313, -0.008218785, 0.022258446, 0.0010959905, -0.002193125, 0.012776641, -0.009747222, -0.003935498, 0.032948356, 0.0020615605, -0.003958379, 0.013655264, -0.01257529, -0.021782525, -0.0022091416, 0.006516453, 0.0020901614, 0.034778822, -0.00028086186, 0.0026106997, -0.0015616149, -0.020135108, 0.0003958379, 0.00034378408, -0.02183744, -0.028225759, 0.019659188, 0.0077337115, 0.029140992, 0.0008917793, 0.015192854, -0.008186752, 0.020153413, -0.0018533451, 0.021983877, -0.0055325786, 0.017709741, -0.0019277077, 0.011586839, 0.065237746, -0.006777294, -0.029946396, -0.021178473, -0.019183267, -0.007143387, -0.009628242, -0.020171717, 0.018908696, 0.011989541, -0.05128961, 0.004127697, 0.008305732, -0.062162567, -0.014259317, -0.011403793, 0.0024665506, -0.021141862, -0.013920682, 0.02637699, -0.0023727394, -0.02176422, -0.015211158, 0.022349969, 0.010159077, 0.0042215083, 0.009591633, 0.032545656, 0.03454086, 0.00016273971, -0.035181522, 0.02668817, -0.0052854656, -0.02262454, -0.012209197, 0.05132622, -0.0025397693, 0.00849793]": "e attacks of\ninvisible triggers and clean labels, while the previous attackmethods can only be carried out under the condition of binary\nclassiﬁcation [26], which limits the generalization ability of the\nattack and reduces the risk of attack. We even tested the effectof the attack on the task of 1000 class image classiﬁcation\nbased on ImageNet(ILSVRC),\n2which signiﬁcantly differs\nfrom the binary classiﬁcation setting. 3) We further verify theeffect of our attack under different defense strategies and ﬁnd\nthat our attack could be executed under different models with\nbetter generalization ability, while previous work was onlytested on AlexNet [26].\nThe main contributions of this paper are as follows:\n1) We propose a new trigger design method, which gen-\nerates different triggers according to different models,\nand distributes the effect of the trigger to a smallperturbation. It can increase the attack success rate from\n29.61% to 96.65% while ensuring concealment.\n2) Our attacks can be con"}
{"[-0.059030462, 0.15126556, -0.033057056, 0.0020626073, 0.030290006, -0.0061935866, -0.056521665, -0.077403694, -0.05216817, -0.003742439, -0.066261694, 0.08057658, 0.0014377146, -0.02302188, 0.011538611, -0.09821193, 0.031839553, 0.008365723, -0.004554108, 0.08677478, 0.025954956, 0.026287002, 0.030585157, 0.090095244, -0.057185758, -0.08463492, -0.07065208, 0.052684687, 0.033315316, 0.024165595, -0.028629774, 0.09725268, 0.08980009, -0.043239813, 0.06397426, -0.036100816, -0.029404549, -0.07091034, 0.017865937, -0.03755813, -0.017045045, -0.011852209, -0.02289275, -0.024719005, 0.044826258, -0.021398542, 0.029994853, -0.06692579, -0.045822397, 0.045158304, 0.026766624, 0.031452168, 0.043793224, 0.06482282, -0.019959675, 0.023722867, -0.02685886, -0.035141572, -0.004999142, 0.024792794, -0.02791034, 0.018428572, -0.02375976, -0.013512442, 0.016150365, 0.047371946, -0.019350924, -0.04585929, 0.014462463, 0.0024926534, 0.01219348, -0.03966109, -0.026582155, -0.031323038, 0.029810382, 0.042723298, 0.00047011074, -0.019037323, 0.041690264, -0.014425569, 0.01816109, -0.019775204, 0.042612616, 0.029109396, -0.07703475, -0.015015873, -0.013051266, -0.0039960854, -0.018280996, 0.011289576, 0.039513513, -0.0136507945, -0.044789363, 0.032522094, 0.010846848, -0.011750751, -0.07814157, -0.04194852, 0.004005309, 0.04276019, -0.01695281, 0.024792794, -0.007692407, -0.009269627, 0.0032812636, -0.029570572, 0.045637924, -0.037041616, -0.03503089, -0.034864865, 0.009767696, -0.053791508, 0.035971686, -0.012949808, 0.025106393, -0.016463965, 0.011547834, 0.0034288396, 0.0027071, -0.00530813, 0.013475548, -0.0312677, 0.060875162, -0.020347062, -0.018354785, 0.0035671922, -0.0023577595, 0.030400688, 0.023593737, 0.024755899, 0.053754613, -0.022948092, -0.020217933, 0.01710961, 0.012903689, 0.0033781105, -0.0024050302, 0.005114436, 0.0066132564, 0.00082838646, -0.044457316, -0.005474153, 0.05419734, -0.0069914204, 0.041321322, -0.002256301, 0.0011921386, 0.056042045, 0.030954098, 0.02233934, -0.035252254, 0.0069683613, 0.011962892, -0.022247106, 0.007918383, -0.029755041, 0.009998284, -0.006903797, -0.01997812, -0.020900473, -0.036211498, -0.022671387, 0.0327988, -0.013152725, 0.0050683185, -0.035399828, 0.007258902, 0.010883741, -0.02630545, 5.5413115e-05, 0.009246568, -0.016178036, 0.045047622, 0.04121064, 0.02233934, -0.030087087, 0.006908409, 0.021472331, 0.0072681257, -0.037207637, -0.019701416, 0.0067746677, -0.014656156, -0.014305663, 0.0025295475, -0.011261906, -0.010883741, 0.035381384, 0.006677821, -0.022431575, 9.8360084e-05, -0.011400258, -0.027688976, 0.0069499146, 0.016805235, 0.0040698736, 0.014158087, -0.009454098, 0.026489919, -0.019148005, -0.0355843, 0.004999142, 0.0027001824, -0.048404977, -0.01445324, -0.0017859021, 0.0077246893, 0.025327757, -0.0076647364, -0.0026263944, -0.003936133, 0.011271128, -0.031249251, 0.03329687, -0.022486916, 0.009265015, 0.017847491, -0.009417203, 0.043092236, -0.010441013, -0.02822394, -0.02890648, -0.015089662, -0.0037562742, 0.016731447, -0.03051137, 0.014342558, 0.033020165, -0.017709138, -0.006378057, 0.0048100604, -0.036211498, -0.018068856, -0.02654526, 0.0082965465, -0.018769842, -0.031489063, 0.0010941388, -0.005958387, -0.004092932, -0.021583013, 0.020918919, 0.0006393045, 0.00478239, 0.015320249, 0.012977478, 0.028260833, 0.012211926, -0.027855, 0.026287002, -0.00932958, -0.023151008, -0.006165916, 0.05209438, -0.013807594, 0.016842129]": " different models,\nand distributes the effect of the trigger to a smallperturbation. It can increase the attack success rate from\n29.61% to 96.65% while ensuring concealment.\n2) Our attacks can be conducted at a smaller perturbation\nthreshold, which results in the poisoned images being\ncloser to the original images, thus bypassing some\nexisting defenses. Our method can attack under a multi-class classiﬁcation model, which greatly increases the\ncapability of attack.\n3) A comprehensive comparison has been conducted with\nboth analogous and state-of-the-art works. Extensive\nexperiments on four datasets are conducted, which verify\nthe effectiveness of the proposed method.\nII. R\nELATED WORK\nA. Backdoor Attack\nVisible Trigger-based Attack: Gu et al. [12] proposes the\nﬁrst backdoor attack method in deep neural networks, in which\nGu believes that the essence of the existence of backdoor\nattacks is to establish a connection between a trigger and thetarget label. Liu et al. [14] proposes to dynam"}
{"[-0.018546304, 0.1391248, 0.018656371, 0.0101536885, 0.026269343, -0.02239865, -0.059069335, -0.038340032, -0.057418328, 0.030011624, -0.026342722, 0.06002325, -0.035771802, -0.06919551, 0.011190154, -0.103169546, 0.020857712, -0.0073423916, 0.01593221, 0.060867097, 0.0104472, 0.04454048, 0.048502892, 0.097446054, -0.02584742, -0.044723924, -0.05389618, 0.04674182, 0.026214309, 0.030396858, -0.012731092, 0.10133509, 0.080202214, -0.025040261, 0.04028455, 0.0026576614, 0.0024444065, -0.063141815, 0.013226395, -0.05085099, -0.0049117436, 0.0074387, -0.030892162, 0.019371806, 0.054189693, 0.033331983, 0.052428618, -0.053786114, -0.014748989, 0.04028455, -0.0024466994, 0.014171137, 0.044283655, 0.06259148, -0.031222362, 0.027846972, -0.018509613, 0.0023733214, 0.041275155, 0.04600804, -0.010658163, -0.00039068083, -0.026489478, 0.010382995, 0.033827282, 0.046668444, -0.0043361844, -0.06446262, 0.058335554, -0.014299548, 0.0075258366, -0.046191484, 0.0058381413, -0.021921694, 0.029919902, 0.033442046, 0.04989708, -0.024655025, 0.04589797, 0.012813643, -0.00013392928, -0.02247203, 0.037055917, 0.03336867, -0.06035345, -0.027608493, 0.027443392, -0.042889472, -0.02755346, 0.008420132, 0.024783438, 0.014987468, -0.031974487, 0.025223706, 0.020949434, -0.0027058157, -0.05169484, -0.033387017, -0.03320357, 0.024581648, -0.014767334, -0.0039486564, -0.03320357, -0.023682768, 0.021077845, -0.06332526, 0.033387017, -0.027791938, -0.040908266, -0.029497977, 0.007603801, -0.03377225, 0.020472476, 0.034084108, 0.013685008, 0.010520578, 0.02170156, -0.019188361, 0.011125947, 0.016326617, 0.017289704, -0.022728853, 0.05954629, -0.008690713, -0.021444736, 0.029938247, 0.0037239362, 0.017904244, 0.00029752508, 0.030323481, 0.02812214, -0.016326617, -0.04109171, 0.021132879, -0.0075946287, 0.010006933, -0.0059161056, 0.008039483, 0.008796195, 0.026269343, -0.033258602, -0.02982818, 0.073744945, -0.012263307, -0.00865861, -0.02487516, 0.0073378053, 0.016913641, 0.033992384, -0.004934674, -0.03738612, 0.0417888, 0.0061316537, -0.030672027, 0.022086794, -0.012914537, -0.0024810955, -0.014482994, -0.026122587, -0.0083880285, -0.05745502, -0.031644285, 0.034652784, -0.027131535, -0.0017851505, -0.046888575, 0.018702231, 0.004691609, 0.0044508376, 0.0148774, -0.010988364, -0.016656818, 0.027535114, 0.065966874, 0.0039188466, -0.01263937, 0.0019685957, 0.01507919, -0.006255479, -0.030378515, -0.023499321, 0.032102898, -0.011327737, -0.01889485, -0.01016286, 0.009942726, -0.00607662, 0.05881251, 0.020692611, -0.0042375824, -0.015858833, -0.0003826551, -0.02788366, 0.005214428, -0.012978744, -0.021279635, 0.018271135, -0.0062417206, 0.031148983, 0.0038844508, -0.04520088, 0.0051639806, 0.0014102345, -0.0059848977, -0.014152792, 0.004925502, 0.01308881, 0.0049759494, 0.0012428408, 0.0044875266, -0.0018333049, -0.00093327713, -0.026838023, 0.020784333, 0.010887469, -0.003249272, 0.02377449, 0.0064939577, 0.021059502, -0.03166263, -0.021132879, -0.022582097, 0.003430424, -0.0023446581, 0.015088363, -0.030433549, 0.006759953, 0.031717665, -0.04255927, 0.015757937, -0.0022540821, -0.074882306, -0.012107379, 0.00814955, -0.00023303265, 0.0009298375, -0.033625495, 0.0062784096, 0.015482769, -0.013785902, -0.016399994, 0.039660838, 0.017399771, 0.0014778798, 0.034249205, -0.01588635, 0.019114982, -0.004219238, -0.035955247, 0.020986123, 0.010740712, -0.024930194, -0.0104196835, 0.028030416, 0.009328186, 0.023884557]": "n deep neural networks, in which\nGu believes that the essence of the existence of backdoor\nattacks is to establish a connection between a trigger and thetarget label. Liu et al. [14] proposes to dynamically generate\na trigger according to the model’s structure and parameters\nto inject the backdoor. The trigger generated in this waycan make the trained backdoor model return a higher attack\nsuccess rate in the transfer learning scenario. Wang et al. [33]\nproposes a work similar to ours, which also does not usestatic triggers in transfer learning, while the poisoned pictures\n2Dataset link: https://image-net.org/download.php.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. CHEN et al.: ICT BACKDOOR ATTACKS IN TRANSFER LEARNING 6749\nFig. 2. Realistic scenarios of our attack method, and the capabilities of the\nattacker.\ncan be easily detected. Xie et al. [34] makes full use of the\ncharacteristics of fe"}
{"[-0.0458319, 0.17860037, -0.0102761695, 0.008406516, 0.03888879, -0.0053458237, -0.07172083, -0.034346227, -0.03992287, 0.015594294, -0.023839235, 0.05820393, -0.02420855, -0.03229653, 0.0072893403, -0.09520922, 0.015345007, -0.007857161, -0.015068022, 0.05779768, 0.017145414, 0.01667454, 0.047826197, 0.09181152, -0.055766452, -0.063891366, -0.067953825, 0.059939705, -0.008738899, 0.025630409, -0.02976673, 0.11315789, 0.09269788, -0.026387503, 0.044687025, 0.015972842, -0.031262454, -0.07463841, 0.013082958, -0.061232302, -0.023008278, 0.010654717, -0.0026983023, -0.0038754914, 0.0593488, 0.0011581464, 0.033459872, -0.0037646971, -0.027440049, 0.0380763, -0.01438479, -0.0047272225, 0.051186956, 0.045351792, -0.0062506436, 0.022546636, -0.025538081, -5.1357765e-05, 0.050928436, 0.055360205, -0.032536585, 0.023562249, -0.003771622, -0.013923148, 0.018031769, 0.022158856, -0.01625906, -0.055618726, 0.010211539, -0.012593616, 0.023414524, -0.03015451, -0.006093685, -0.022066526, 0.025796602, 0.03669137, 0.015381939, -0.02226965, 0.045093272, 0.012233535, 0.019979902, -0.023026744, 0.02136483, 0.024614796, -0.0639283, -0.037799314, 0.0037900875, -0.021900335, 0.017579358, 0.008882008, 0.037706986, 0.004801085, -0.0380763, 0.00922824, 0.008341886, -0.022084992, -0.074195236, -0.013876983, -0.0030814658, 0.03584195, -0.01955519, -0.0057289875, -0.00235207, -0.020386146, 0.0054935496, -0.05414147, 0.034881733, -0.038741067, -0.055840317, -0.035380308, -0.0140893385, -0.032259602, 0.017542427, -0.0027513911, 0.027938623, 0.008798912, 0.0135446, -0.02847413, -0.008369585, 0.012473589, -0.0022493547, -0.03467861, 0.03911038, -0.030653084, 0.0070769843, 0.0055350973, 0.017274674, -0.0061398493, 0.0042540384, 0.031853355, 0.04634894, -0.02653523, -0.005655125, 0.022546636, -0.0034969444, 0.02705227, 0.010996332, 0.0084249815, 0.012925999, 0.0035961976, -0.047383018, -0.012159672, 0.05886869, 0.0075201616, 0.010913236, -0.036340524, 0.024817917, 0.016028238, 0.01044236, 0.025575012, -0.04228648, 0.028271006, 0.0051150024, -0.02511337, -0.011107126, -0.0016030547, 0.010211539, -0.036599044, -0.007413984, 0.0035938893, -0.05982891, -0.038519476, 0.025704272, -0.035934277, 0.009777595, -0.04945118, 0.01968445, 0.006089069, -0.01968445, -0.004240189, -0.00056637806, -0.024430139, 0.034420088, 0.026738353, 0.0003710454, -0.00012161403, 0.010386963, 0.00846653, -0.0067538344, -0.034623213, -0.040033665, 0.014273996, -0.019906038, -0.006393753, -0.010959401, -0.0071554636, -0.0022770532, 0.053956814, -0.001865037, -0.033441406, -0.0057659186, -0.013239916, -0.0134892035, 0.0047087567, 0.012547452, -0.0076217228, 0.024836384, -0.0023209092, 0.030357633, -0.024670193, -0.04616428, 0.018373385, -0.015714321, -0.022842087, -0.023931565, 0.012805972, 0.0022943649, -0.0031645615, -0.008918939, 0.022731293, -0.011744194, 0.0009359808, -0.0341431, 0.035934277, 0.0029660552, 0.0119103845, -0.008757364, 0.0056874393, 0.016766867, -0.0021812622, -0.020700064, -0.047715403, 0.009075898, -0.002910658, -0.014163202, -0.017727084, 0.032887436, 0.014994158, -0.058942556, 0.009906855, -0.0012118124, -0.060013566, 0.0026890694, -0.0015118802, 0.016489882, 0.0018488795, -0.03604507, -0.0027536994, -0.0019689067, -0.010470059, -0.007750983, 0.03674677, 0.026849147, 0.006306041, 0.019961435, 0.0015591986, 0.031262454, 0.0005259843, -0.029175825, 0.02786476, 0.020441543, -0.02989599, -0.014338626, 0.026978407, 0.0016422943, 0.0074878465]": "KS IN TRANSFER LEARNING 6749\nFig. 2. Realistic scenarios of our attack method, and the capabilities of the\nattacker.\ncan be easily detected. Xie et al. [34] makes full use of the\ncharacteristics of federated learning and proposes a backdoorattack based on distributed triggers. Lv et al. [35] proposes\nan attack on transformer models, which have a completely\ndifferent structure and principle compared with convolutionalneural. These attacks are all based on patch-based triggers, as\na result, the trigger is easily perceptible to human inspectors.\nInvisible Trigger-based Attack: Chen et al. [21] ﬁrst\nproposes backdoor attacks with invisible triggers, which\nmakes backdoor attacks more difﬁcult to detect. After that,\nNguyen and Tran [36] hides the trigger by applying a warping\ntransformation to the image. Doan et al. [27] treats the trigger\ngeneration process as a non-convex constrained optimization\nproblem and uses a two-stage stochastic optimization pro-cess to learn a hidden noise as a tri"}
{"[-0.04241448, 0.12584677, -0.037856944, 0.02197908, 0.06115918, -0.009923665, -0.04461974, -0.017733956, -0.03866554, 0.03037744, -0.054139104, 0.051860336, -0.0062941764, -0.03225191, 0.0005360961, -0.09739894, -0.0021719502, 0.020196496, -0.03425502, 0.096957885, 0.04583263, 0.028227314, 0.02747385, 0.11680521, -0.04487702, -0.08365282, -0.060865145, 0.06663557, 0.016125955, 0.034438793, -0.018478232, 0.117466785, 0.08284423, -0.011007917, 0.057557255, 0.016070824, -0.04473, -0.06174725, 0.02359627, -0.027381964, -0.018239329, -0.00365246, -0.03728725, 0.048001133, 0.03822449, -0.030138537, 0.022254737, -0.049985867, -0.017936105, 0.07486854, 0.01105386, 0.02482754, 0.047780607, 0.0451343, -0.02611394, 0.0118257, -0.036497034, 0.011724627, 0.016024882, 0.0148028005, -0.021942325, -0.006840897, -0.0066617196, -0.00853619, 0.03109415, 0.044546228, 0.00088669785, -0.026224203, 0.02752898, -0.016447555, 0.02449675, -0.038297996, -0.031700596, -0.026977668, 0.034089625, 0.04965508, 0.006197696, -0.024735654, 0.05373481, -0.0065468624, 0.0017630585, 0.000917135, 0.034383662, 0.0067536053, -0.061710496, -0.020729434, -0.002637122, -0.012441335, -0.004764278, 0.003985546, 0.048625957, -0.0053431583, -0.04855245, 0.008563755, 0.0013955154, -0.024772407, -0.0647611, -0.03405287, 0.0048699467, 0.042782024, -0.01739398, 0.016383236, -0.002247756, -0.0077597545, 0.0181015, -0.024643768, 0.03929036, -0.007782726, -0.031810857, -0.050316658, 0.006556051, -0.04362737, 0.042083688, -0.012937519, 0.038408257, -0.016171899, 0.0020237844, -0.03324428, 0.010888466, -0.028006788, 0.01647512, -0.039143346, 0.057630766, -0.013332628, -0.0014138925, 0.032417305, 0.011393838, 0.015106023, 0.022714166, 0.031186035, 0.046457455, -0.015041703, -0.011779758, 0.020012723, 0.012588353, 0.016337292, 0.00179407, 0.0075530116, 0.01946141, -0.008141081, -0.062335316, -0.023963813, 0.06586373, -0.0053753187, 0.034089625, -0.008830224, 0.012615918, 0.043296583, 0.016015692, 0.017265338, -0.03866554, 0.017853409, 0.01997597, 0.0033882884, -0.01835878, -0.016502688, -0.018239329, -0.028080296, -0.031314675, -0.011430591, -0.04906701, -0.013461268, 0.028594857, -0.012845633, 0.0009814551, -0.05094148, 0.005729079, 0.019001981, -0.0325827, 0.009174796, 0.00038477173, -0.010392282, 0.03476958, 0.030910378, 0.015087646, 0.0028576478, 0.028980777, 0.01124682, -0.0023086304, -0.032104895, -0.017789088, 0.003843123, -0.00189055, -0.00562341, -0.0049802097, 5.2717673e-06, -0.0057428614, 0.054874193, 0.009386133, -0.021776931, 0.0069327825, -0.006349308, -0.012845633, 0.00022669946, 0.0028323794, 0.00040602032, 0.009358567, -0.0027083335, 0.03238055, -0.016539441, -0.04395816, 0.01997597, -0.008127298, -0.023577893, -0.0050766896, -0.0013989611, 6.45713e-05, 0.01959005, 0.0029012938, 0.0064411936, -0.010300397, 0.013865565, -0.021740178, 0.029366696, -0.01687023, 0.01428824, -0.002843865, 0.009105882, 0.030836869, -0.010842523, -0.036552165, -0.02256715, -0.020049479, -0.010511734, 0.00988691, -0.0076127374, 0.0018250814, 0.03206814, -0.06402601, 0.011485723, -0.0071579027, -0.04039299, -0.017862597, -0.008931299, 0.0044679465, -0.002814002, -0.03394261, 0.019534918, 0.0047918437, -0.007906772, -0.02352276, 0.033960987, 0.019075489, 0.009877722, 0.009138041, -0.0029770995, 0.03269296, -0.002827785, -0.024533505, 0.023559516, 0.004065946, -0.011145745, -0.020012723, 0.034181513, -0.011154935, -0.013617474]": "he image. Doan et al. [27] treats the trigger\ngeneration process as a non-convex constrained optimization\nproblem and uses a two-stage stochastic optimization pro-cess to learn a hidden noise as a trigger. Bagdasaryan and\nShmatikov [29] eliminates the need to directly add triggers to\nthe data by injecting malicious code into the training code.\nGong et al. [37] changes the RGB value of every pixel in\nthe picture, and the backdoor is activated when the modeldetects a speciﬁc change. For the multilabel classiﬁcation task,\nChen et al. [38] uses multiple labels as trigger.\nClean Label-based Attack: To further improve the con-\ncealment of poisoned images, Turner et al. [39] ﬁrst proposes\nthe idea of a clean-label attack. He uses adversarial pertur-\nbation or generative models to change the images of thetarget class so that the poisoned images do not need to\nchange the label. Since then, a lot of related work has been\nproposed [22],[26]. Wang et al. [40] proposes a sequential\ntrigger that inj"}
{"[-0.048692606, 0.1227098, -0.01318835, 0.038356043, 0.044041153, -0.030658992, -0.071949884, -0.020820796, -0.024364762, -0.00024139804, -0.016953813, 0.059435252, 0.0054313117, -0.04548089, 0.005855849, -0.111708745, 0.0016093202, -0.009362898, -0.030751282, 0.07279895, 0.033926085, 0.020599298, 0.04197384, 0.09642539, -0.02988375, -0.07656442, -0.04455798, 0.036824014, 0.030935865, 0.067519926, -0.028665511, 0.09376742, 0.07316812, 0.0002700947, 0.06441896, 0.011720927, -0.037414677, -0.06486195, -7.289529e-05, -0.059804417, -0.031046614, -0.018670421, -0.015864782, 0.007023327, 0.030400578, -0.020802338, 0.022002118, -0.040534105, -0.02227899, 0.07996072, 0.026229035, 0.0048914105, 0.066966176, 0.022740444, -0.02137454, 0.043265913, -0.018107448, 0.010345795, 0.0087030195, 0.050095428, -0.031508066, 0.033483088, -0.005985056, 0.030197538, 0.03108353, 0.024217097, -0.02368181, -0.06035816, 0.023921767, 0.006464968, 0.037746925, -0.04485331, -0.00013288428, -0.020931546, 0.05256882, 0.040607937, -0.003608569, -0.012911478, 0.051424414, -0.011204099, 0.018855004, 0.0146557735, 0.03536582, 0.022851193, -0.048397277, -0.02268507, -0.0021099977, -0.011462513, -0.016621567, 0.004739131, 0.05596512, -0.003292473, -0.045960803, 0.015947845, -0.0134559935, -0.037839215, -0.059103005, -0.05190433, -0.020968461, 0.012256213, -1.1247937e-05, 0.0070417854, -0.013880531, -0.011554804, 0.0049606287, -0.04016494, 0.036067232, -0.033593837, -0.031415775, -0.036824014, 0.01658465, -0.056297366, 0.014277382, -0.002837941, 0.043635074, 0.007567843, 0.0026164432, -0.018375091, 0.022906568, -0.013834386, -0.033021636, -0.029422296, 0.03717472, -0.025010798, -0.0076001445, 0.025675291, 0.005837391, 0.02019322, 0.010207359, 0.05208891, 0.053713225, -0.033040095, -0.02329419, 0.0030271371, 0.001101721, 0.012570002, -0.0020315505, 0.020322427, 0.010613438, -0.0031355787, -0.05408239, -0.015966302, 0.068295166, -0.0010630742, 0.0357719, 0.004413806, -0.0022403584, 0.008241565, 0.01778443, 0.008163118, -0.04038644, 0.018319717, 0.01599399, -0.010567293, 0.0069541093, -0.024549345, -0.003963888, -0.021965202, -0.026875071, -0.006358834, -0.058807675, -0.026967362, 0.019934805, -0.0073001995, -0.003377842, -0.042416837, 0.024106348, 0.004896025, -0.038614456, 0.012689981, -0.0058927652, -0.024161723, 0.036399476, 0.025841415, 0.025361503, -0.014258923, 0.0069079637, 0.015652513, 0.008338471, -0.021393, -0.026505908, 0.021799078, -0.011471742, -0.0064788116, 0.0055282167, 0.002067313, -0.017018417, 0.055005297, 0.0031240424, -0.021153044, -0.017747514, -0.013363703, -0.015717117, 0.011877822, 0.016307779, -0.019621016, 0.00097309076, 0.003567038, 0.031711105, -0.011637866, -0.051645912, 0.016150884, -0.0027733375, -0.010834936, -0.028407097, 0.013806699, -0.0047714324, 0.011684011, -0.010041235, 0.0185043, -0.012246985, 0.017941324, -0.017350664, 0.032726306, -0.010244275, -0.000779857, 0.0047437456, 0.0061281067, 0.03189569, -0.02238974, -0.046440713, -0.015966302, -0.008809154, -0.0065803314, 0.016815377, -0.022426656, 0.019362602, 0.015237206, -0.061317984, 0.018421236, 0.017950553, -0.04688371, -0.0063034594, -0.010917998, 0.00094021217, -0.020303968, -0.033058554, 0.017018417, 0.003943123, -0.022408199, -0.025453793, 0.030658992, 0.0042476826, -0.0033478476, 0.0063496046, 0.006834131, 0.036934763, 0.006155794, -0.026579741, 0.021263793, 0.010419628, -0.018439695, -0.032135643, 0.043265913, -0.018024387, -0.0005598012]": "s of thetarget class so that the poisoned images do not need to\nchange the label. Since then, a lot of related work has been\nproposed [22],[26]. Wang et al. [40] proposes a sequential\ntrigger that injects hidden backdoors by changing the order\nof training samples without changing the samples. However,\nthe above works cannot achieve efﬁcient attacks under transferlearning and invisible triggers [33]. In this paper, we aim to\nachieve a satisfactory success rate of attack while ensuring\nstealthiness.\nB. Backdoor Defence\nIn order to alleviate backdoor attacks, various defense\nmethods have been explored, which can be mainly divided intothree categories [41], including trigger-backdoor mismatch,\nbackdoor elimination, and trigger elimination.Trigger-Backdoor Mismatch works by breaking the con-\nnection between the trigger and the backdoor, usually addinga pre-processing phase between the data and the model so that\nthe changed ﬂip-ﬂop cannot activate the backdoor hidden in\nthe model. For exampl"}
{"[-0.05863082, 0.11726164, 0.024408065, 0.011478039, 0.035068214, 0.0017299767, -0.052050933, -0.022073861, -0.02249659, 0.01527342, -0.036814272, 0.075429745, -0.00201486, -0.054881386, -0.008316754, -0.11248295, -0.020585116, -0.00976874, -0.021412196, 0.07458428, -0.00054076134, 0.024040474, 0.023507467, 0.1146885, -0.043118466, -0.07675307, -0.09035395, 0.04120699, 0.034296274, 0.042787634, -0.028653745, 0.079767324, 0.06892338, -0.010173091, 0.08506064, -0.011854821, -0.04543429, -0.060101185, -0.013554931, -0.030877674, -0.01957424, -0.008532714, -0.012663522, 0.020033728, 0.03135554, -0.022956079, 0.04212597, -0.05021298, -0.03356109, 0.045581326, 0.022753904, 0.025602737, 0.031943686, 0.055616572, 0.0031038495, 0.03793543, -0.05183038, -0.013049493, 0.014143077, 0.03271563, -0.055763606, 0.029774899, -0.036023952, -0.012884077, 0.04940428, 0.032017205, -0.0077883415, -0.048154466, 0.027955322, 0.0017012587, 0.035472564, -0.030436564, -0.0028580227, -0.0036506415, 0.047345765, 0.058851376, 0.019261787, -0.031208506, 0.033285398, -0.0043766345, 0.018811487, -0.00078515214, 0.02595195, 0.011101259, -0.041390784, -0.029444067, 0.004179054, -0.0056011733, -0.008918685, -0.0024238054, 0.045250494, -0.0013267751, -0.028819162, 0.011349383, -0.009474667, -0.010908273, -0.03565636, -0.048779372, -0.009989295, 0.025235146, 0.011165587, 0.0016886228, -0.01575129, -0.023617744, 0.013306807, -0.04624299, 0.026319541, -0.025529219, -0.03266049, -0.03442493, 0.0043100086, -0.06285812, 0.016183209, -0.01360088, 0.014087939, -0.0028212636, 0.002952218, 0.0057206405, -0.0038367347, -0.007388586, -0.009860638, -0.04201569, 0.034957938, -0.02291932, -0.027054723, 0.024113992, 0.0067315167, 0.02080567, 0.013950092, 0.030271148, 0.0510952, -0.027532592, -0.027036343, 0.009212758, -0.021632751, 0.021173261, -0.00913005, 0.014051179, 0.013343566, 0.01487826, -0.050764363, -0.026540095, 0.073628545, -0.010568251, 0.03607909, 0.0017161921, 0.017938457, 0.03368975, 0.008845167, -0.0139133325, -0.036134228, 0.023452329, 0.031282023, 0.005904436, 0.018949334, -0.02253335, -0.008601638, -0.010871514, -0.009961725, -0.00040750948, -0.046610583, -0.011248295, 0.02337881, -0.0043559573, -0.027569352, -0.047823634, 0.030675499, 0.030712256, -0.016615128, 0.024022095, 0.0027086888, -0.018370377, 0.022459831, 0.029407308, 0.008757864, 0.0042525725, 0.017543297, 0.029554345, 0.006281217, -0.03767811, -0.03317512, 0.021632751, -0.0055873883, -0.014051179, -0.009658462, -0.013499793, -0.0010895637, 0.054256484, 0.010788806, -0.015411267, -0.0072645238, -0.009107076, -0.028414812, 0.0036299645, 0.013325186, -0.0046385434, 0.011790493, 0.007131272, 0.004934914, -0.004801662, -0.045507807, 0.016054552, -0.022404693, -0.027716387, -0.022827422, 0.016302677, 0.015310179, 0.012617573, -0.02718338, 0.009203568, -0.009538995, 0.024647, -0.040692363, 0.031796653, 0.007967543, 0.003965392, 0.0013129903, 0.002674227, 0.02249659, 0.0072415494, -0.020695392, -0.029094854, -0.0151171945, -0.005614958, 0.007701039, -0.023985336, 0.013343566, 0.021044604, -0.053815372, 0.009249518, 0.010035244, -0.032605354, -0.008762458, 0.004298521, -0.0005712025, -0.012525675, -0.025345424, 0.013205719, -0.0074988636, -0.009097886, -0.034535207, 0.014538238, 0.021963583, 0.004378932, 0.022772284, -0.008454601, 0.03808246, 0.022588488, -0.04337578, 0.022956079, 0.005481706, -0.014005231, -0.029848417, 0.039258756, -0.0057482095, 0.02547408]": "ction between the trigger and the backdoor, usually addinga pre-processing phase between the data and the model so that\nthe changed ﬂip-ﬂop cannot activate the backdoor hidden in\nthe model. For example, Li et al. [25] proposes that in the\ntest phase, small changes (e.g., left and right ﬂip or a certain\nproportion of zoom) were made to each image, which will\nhave no effect on the recognition of clean images, but couldmake the trigger no longer effective.\nBackdoor Elimination tries to remove the backdoor in\nthe model [42],[43]. Liu et al. [44] believes that the root\ncause of the backdoor’s existence is the model’s redundant\nclassiﬁcation ability. If the redundant neurons that are not\nactivated by clean images can be pruned, then the backdoor\ncan be removed. Wang et al. [45] showed that for a model with\nbackdoors, the disturbance required to misclassify a pictureinto an attack label is much smaller than the disturbance\nrequired to misclassify a picture into another label. After the\nattack"}
{"[-0.047593873, 0.1206792, -0.006538632, 0.014928341, 0.02945147, -0.033337813, -0.03477447, -0.038089834, -0.04984095, 0.03797932, -0.05812936, 0.07559027, -0.021862974, -0.03689262, -0.008058173, -0.10852287, 0.020002687, 0.021623531, -0.005986071, 0.10115539, 0.0017509259, 0.041957755, 0.047225498, 0.07691641, -0.039489653, -0.07536925, -0.06380231, 0.05905029, 0.015968997, 0.03823718, -0.04438902, 0.0938616, 0.09201973, -0.013850848, 0.051240772, -0.016364997, -0.03547438, -0.06343394, 0.02919361, -0.025951922, -0.024828382, 0.011014371, -0.0108209755, 0.011041999, 0.062513, -0.011557722, 0.046857126, -0.04899369, -0.024791544, 0.039489653, 0.046157215, 0.019063335, 0.057282098, 0.051645983, -0.012837821, 0.023649586, -0.04162622, -0.0002734023, 0.0027512906, 0.034995493, -0.068333305, 0.023852192, -0.0074089146, -0.016935978, 0.03254581, 0.01690835, -0.018897567, -0.049656764, 0.04479423, 0.0073168213, 0.02749909, -0.04674661, -0.015186203, -0.03842137, 0.039268628, 0.04597303, 0.013869267, -0.023244375, 0.0435786, 0.0122852605, 0.017359607, -0.04214194, 0.031164408, 0.020205293, -0.07279063, -0.01983692, -0.00831143, -0.024386333, 0.0021342647, -0.0039692256, 0.016484719, -0.0074457517, -0.037518855, 0.01731356, 0.0044342973, -0.011861631, -0.064281195, -0.033153627, -0.021034135, 0.04943574, -0.009342876, 0.011935306, -0.030372405, -0.021660369, 0.0008840967, -0.039452814, 0.036505826, -0.024938894, -0.034553446, -0.0466361, 0.016724162, -0.035953265, 0.026854437, -0.030888129, 0.003867923, 0.002659197, 0.01257075, -0.0025371732, -0.0031841295, -0.0013756453, -0.021310413, -0.034700796, 0.04232613, -0.009780319, -0.011502466, 0.018768637, -0.0075332406, 0.0020087874, 0.012883867, 0.018501565, 0.043615438, -0.0035087587, -0.01575718, 0.013150938, -0.0038287833, 0.009789529, -0.0066767717, -0.011612979, 0.026504481, 0.014458665, -0.059418663, -0.006492585, 0.06895954, -0.014670479, 0.028272675, -0.0052263006, 0.016576814, 0.049546253, 0.0135008935, 0.009844785, -0.03606378, 0.022102417, 0.012810193, -0.007869381, 0.012183958, -0.016963605, 0.024681032, -0.015978206, -0.0174517, -0.020278968, -0.027959557, -0.023539074, 0.027517509, -0.017820073, 0.007864777, -0.040300075, 0.0063314214, 0.019818502, -0.015094109, 0.010922278, 0.009789529, -0.009163294, 0.036487408, 0.03267474, 0.012515494, -0.009467202, 0.0069346335, 0.03252739, 0.0016242975, -0.042952362, -0.03309837, 0.0046484144, -0.021807719, -0.012128701, 0.0, -0.010599951, 0.0027881279, 0.041699894, 0.022636559, -0.029783007, -0.002933175, -0.02847528, -0.017203048, -0.0031173618, 0.0129299145, 0.0009877018, 0.027572766, -0.016466301, 0.009982925, -0.010784138, -0.042952362, 0.013915313, -0.014771782, -0.022249768, -0.024312658, 0.010728882, 0.012874658, 0.019523801, 0.0043813437, 0.006621516, -0.00963297, 0.019063335, -0.05739261, 0.031201245, -0.011263023, 0.0002522496, 0.0053828596, -0.019597476, 0.01911859, -0.024478428, -0.028972585, -0.039563328, -3.07038e-05, 0.012939123, 0.0048210896, -0.020647341, 0.025380943, 0.021476181, -0.036358476, -0.003324572, 0.008168685, -0.04162622, -0.010130275, 0.009121852, 0.008435756, -0.019671151, -0.032895766, -0.0062899794, 0.0028917328, -0.002590127, -0.03436926, 0.03827402, 0.013068054, 0.010922278, 0.031072315, 0.000181165, 0.012791774, 0.005083556, -0.023373306, 0.036505826, -0.0113919545, -0.019726407, -0.009642179, 0.02134725, -0.016816257, 0.018593658]": " model with\nbackdoors, the disturbance required to misclassify a pictureinto an attack label is much smaller than the disturbance\nrequired to misclassify a picture into another label. After the\nattack label is identiﬁed, the backdoor is eliminated through“Filter, Pruning, and Unlearning” techniques.\nTrigger Elimination method occurs in the inference stage\n[46]. Gao et al. [47] proposes to ﬁlter the attacked samples by\nsuperimposing various images on the input samples. The less\nrandomness of the perturbation input prediction, the higher the\nprobability that the input sample will be attacked.\nIII. T\nHREAT MODEL\nAttacker Ability: Let’s assume that a user downloads a\nwell-known model from a trusted source, such as AlexNet andResNet, and then downloads a batch of data from an untrusted\nthird party. The user uses limited training resources to train a\ndesired model through transfer learning. Figure 2presents the\nactual scenario and illustrates the speciﬁc attack environment.\nUnder such condit"}
{"[-0.041967545, 0.13215154, -0.001361172, 0.02619736, 0.044001214, -0.03557073, -0.07147424, -0.03257569, -0.051137544, 0.019948449, -0.020262744, 0.056314155, -0.012673459, -0.0593092, -0.007926689, -0.070549846, 0.025032623, -0.011628892, -0.01676853, 0.09961283, 0.052616578, 0.036569074, -0.0005699474, 0.112554364, -0.030578993, -0.054280486, -0.0444819, 0.050139196, -0.012978509, 0.03288998, 0.013681049, 0.108191215, 0.06932964, -0.035681657, 0.03168827, 0.01931986, -0.043150768, -0.05664694, 0.047255084, -0.023220807, -0.023313249, 0.007834249, -0.003119834, 0.0074044056, 0.045036536, 0.009197732, 0.0013865929, -0.021464458, -0.00023153212, 0.031447925, 0.050767787, 0.011878478, 0.041301977, 0.021464458, -0.018774467, 0.026493168, -0.065706015, 0.033259742, -0.010889376, 0.028175566, -0.015354205, 0.023276271, -0.0031868524, -0.008402753, 0.021815727, -0.006262778, 0.0037414897, -0.037438005, 0.019615667, 0.021815727, 0.008268715, -0.032279883, -0.010630545, -0.018321514, 0.012710434, 0.019966938, 0.050139196, -0.00970615, 0.059087344, 0.02673351, 0.0033925304, -0.01050113, -0.0017343966, -0.0005433711, -0.0469223, -0.013024729, -0.010131372, -0.038935527, -0.032612663, -0.025975507, 0.035589214, 0.00311059, -0.05468722, 0.018635808, 0.019005565, -0.03257569, -0.03368496, -0.018617319, -0.006614048, 0.0469223, -0.013533146, 0.025513308, -0.027491514, -0.016971895, 0.009350258, -0.06596484, 0.041930567, -0.032353833, -0.033111837, -0.017276946, 0.0035150128, -0.050065245, 0.026067946, -0.052727506, 0.037456494, 0.005199723, 0.013921392, -0.005694275, 0.026437704, 0.010935595, -0.0034387503, -0.012275969, 0.06271097, 0.0016223136, -0.009433453, 0.01698114, -0.003711447, -0.0031914746, 0.010843156, 0.018598832, 0.05953105, -0.00893428, -0.00029956183, 0.016648358, 0.018654296, 0.003697581, -0.01831227, 0.0011456723, 0.014725616, 0.0010497663, -0.046145808, -0.017036604, 0.055167906, -0.0029210888, 0.01922742, 0.006808171, 0.029303329, 0.015502108, 0.008804864, 0.006761951, -0.02469984, 0.0067203534, 0.013523902, -0.022370365, -0.020447623, -0.003089791, 0.008264094, -0.032963935, -0.01884842, -0.009364123, -0.054132584, -0.023165345, 0.003870905, -0.01878371, 0.0066787554, -0.04862319, 0.0070392694, -0.0010670987, -0.0377523, 0.0038246852, -0.010325494, -0.009789346, 0.045997906, 0.017249215, 0.0017367075, 0.0053106504, 0.035589214, 0.015613035, -0.001351928, -0.041412905, -0.031447925, 0.022684658, -0.028730204, -0.013089436, -0.011915455, 0.0041020038, 0.013644073, 0.03952714, 0.026012482, -0.044518873, -0.022019094, -0.02867474, -0.033315204, 0.015030666, 0.013801221, -0.014753348, 0.03096724, -0.0045873113, 0.028859619, -0.02329476, -0.051470324, -0.0019978492, 0.008643095, -0.018044194, -0.020798892, 0.0049177827, 0.013551634, 0.026530143, -0.00024453143, 0.008564522, -0.0029857967, 0.007834249, -0.028046152, 0.028157078, 0.015335717, 0.012044869, -0.0030320163, -0.011684355, -0.004055784, -0.0045480244, -0.017138287, -0.019190446, -7.691257e-05, -0.00064245466, 0.0010127905, -0.0066325357, -0.0003686026, 0.028268006, -0.061157987, 0.009428832, 0.011850746, -0.036310244, 0.007164063, 0.02425613, 0.016870214, -0.0045526465, -0.047439963, 0.026955364, 0.02074343, 0.0063459734, -0.024718327, 0.050065245, -0.0049778684, 0.026104921, 0.029340304, -0.012664215, 0.03557073, -0.0012999307, -0.020872844, 0.024681352, -0.0054030903, -0.024422523, -0.012923045, 0.034479942, -0.0064846324, 0.0041782665]": "rty. The user uses limited training resources to train a\ndesired model through transfer learning. Figure 2presents the\nactual scenario and illustrates the speciﬁc attack environment.\nUnder such conditions, the attacker only knows the structure\nof the pre-trained model (called G) and accomplishes thepoisoning of the data based on it. However, the attacker\ndoes not know the new model structure (called G\n∗)when\nthe user ﬁne-tunes it. This is the minimum required to carryout a backdoor attack [41] so that our attack has very good\ngeneralization ability.\nAttacker Goal: In previous work, the user would download\nthe entire training dataset D\ntrain={(xi,yi)}N\ni=1, where xi∈\nX={0,..., 255}C×W×H,yi∈Y=/braceleftbig1,..., K/bracerightbig\n.C,W,H\nrepresent the number of channels, width, and height of a\npicture, respectively, and N =|Dtrain|represents the amount\nof data. The attacker selects a trigger t, a mask M, and a\ntarget class ˆyin advance and uses the trigger injection function\nEq.(1)to genera"}
{"[-0.04558133, 0.110713206, 0.011816365, 0.007523665, 0.05938387, -0.04272563, -0.07886119, -0.037929524, -0.028685117, 0.037526798, -0.0279895, 0.060665272, -0.018443048, -0.060592048, 0.0125028305, -0.074101694, 0.010031554, -0.0049791653, 0.017454537, 0.07109955, 0.03302358, 0.026579956, 0.012017728, 0.14534768, -0.035824362, -0.068243854, -0.034835853, 0.05799263, 0.020502444, 0.023577811, 0.012155021, 0.10763784, 0.07172195, -0.0007362346, 0.027238963, -0.015001566, -0.041663896, -0.06304502, -0.0076106177, -0.024108678, -0.03556808, -0.008210131, -0.005230869, 0.0270376, 0.05099983, -0.01199027, 0.00655346, -0.024108678, -0.016035842, 0.04173712, 0.013738469, 0.021051617, 0.023834093, 0.016063299, -0.017335549, -0.0052125636, -0.031247923, 0.0075694295, -0.016740613, 0.008457258, -0.0049288245, 0.013564564, -0.033829033, -0.009020161, 0.03902787, 0.010562421, 0.0058990293, -0.03379242, 0.021454344, -0.011001758, 0.027312186, -0.004393381, 0.02634198, -0.03018619, 0.021179758, 0.035714526, 0.020118024, -0.020612279, 0.081057884, 0.023834093, 0.007336031, 0.005830383, 0.02328492, 0.038405474, -0.049938098, -0.01597177, -0.033060193, -0.038295638, -0.01062649, -0.011184816, 0.03609895, -0.018818315, -0.05392875, 0.008329119, 0.014708674, -0.04100489, -0.016054146, -0.001231062, -0.013427271, 0.05462437, -0.013198449, 0.025536528, -0.017564371, -0.013637787, 0.020319387, -0.030662138, 0.0438972, -0.016237205, -0.03057061, -0.03091842, 0.01145025, -0.05067033, 0.04027266, -0.022058435, 0.04825397, 0.015038177, -0.01116651, -0.020026496, 0.017564371, -0.018589493, 0.0031943542, -0.01832406, 0.04148084, 0.0030730786, -0.006937881, 0.029563794, 0.0029815498, 0.006210227, 0.019239347, 0.02198521, 0.035000604, -0.003077655, -0.011258039, 0.040895056, 0.020777032, 0.012429607, -0.013546258, 0.0083016595, 0.02398054, -0.0047411905, -0.057809573, -0.019111209, 0.061543945, -0.025243636, 0.031138089, 0.008416071, 0.028081028, 0.020465834, 0.01927596, -0.002679505, -0.013317437, 0.010187153, 0.048876364, -0.019678686, -0.011541778, 0.0017676494, -0.0026634873, -0.032144904, 0.0009433184, -0.0033293592, -0.04027266, -0.032053377, 0.02268083, -0.004169136, 0.0080224965, -0.021692319, -0.019495629, 0.013564564, -0.019221043, 0.022278104, 0.024108678, 0.016310427, 0.044482984, 0.028978009, 0.02052075, 0.008475564, 0.033975482, 0.035806056, -0.00052857865, -0.027861359, -0.03216321, 0.01962377, -0.02764169, -0.019989884, -0.015550738, 0.0059539466, 0.009212371, 0.046203725, 0.03260255, -0.012621818, -0.0054734205, -0.020374306, -0.042579185, -0.009793579, 0.013079462, 0.011413638, 0.021307899, -0.018232532, 0.03238288, -0.00030318907, -0.045032155, -0.0071804323, -0.02764169, -0.012136715, -0.023303226, -0.016182287, 0.020118024, 0.03426837, 0.005500879, 0.02656165, -0.013134379, -0.0056107137, -0.018946456, 0.037380353, 0.008191825, 0.008773033, 0.0016864176, -0.013875762, 0.011285498, -0.030534, -0.027019294, -0.032785606, -0.021326205, 0.009189488, 0.009194065, -0.010049859, -0.008104873, 0.0069012693, -0.06161717, -0.0063704024, 0.012795722, -0.03902787, 0.0037618326, -0.0054093506, 0.008773033, -0.008805068, -0.02427343, 0.003121131, 0.035293493, -0.004924248, -0.014525617, 0.033224944, -0.0045741503, 0.0014312812, 0.014086278, -0.0042332057, 0.043055136, 0.016658237, -0.013161837, 0.02729388, -0.0043590576, -0.022992028, -0.025005661, 0.027092516, -0.030479081, 0.023303226]": "picture, respectively, and N =|Dtrain|represents the amount\nof data. The attacker selects a trigger t, a mask M, and a\ntarget class ˆyin advance and uses the trigger injection function\nEq.(1)to generate the poisoned data Dpoison={(T(xi),ˆy)}\nT(x)=(1−M)⊙x+M⊙t (1)\nwhere M is a two-dimensional matrix of the same size as x,\n1 at the trigger position and 0 everywhere else, ⊗represents\nmultiplication by elements. The attacker’s goal is for the userto train a backdoor classiﬁcation model f\nw:X→[0,1]Kso\nthat fwbehaves normally on clean data, but when a trigger\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6750 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nFig. 3. The overall ﬂow chart of the attack. After downloading the model, the attacker utilizes Algorithm 1to generate a computable trigger. Subsequently,\nthe functionality of the trigger is concealed by distributing it onto"}
{"[-0.04238247, 0.11230987, 0.016306601, 0.05123358, 0.062398456, -0.03779165, -0.07352661, -0.052776095, -0.027012398, -0.0017651712, -0.03439444, 0.03612059, 0.002225401, -0.030115794, 0.017839935, -0.104376934, -0.020015985, 0.013983645, -0.007028549, 0.05677929, 0.052776095, 0.014093825, 0.016031152, 0.1128975, -0.040803228, -0.076611646, -0.020162892, 0.04936052, -0.009962085, 0.03981161, -0.014470272, 0.08329588, 0.092991695, -0.009181645, 0.08065157, -0.000105732375, -0.039481074, -0.06908269, 0.0073085893, -0.02892218, -0.023082655, -0.0023757506, -0.0038723587, -0.002042916, 0.03724075, -0.009268871, -0.0037116797, -0.029491443, 0.01362556, 0.055420406, 0.019942531, 0.03472498, 0.0083093885, 0.030574877, 0.006459287, 0.022091037, -0.011229151, 0.026663495, 0.016178058, 0.015177258, -0.021081056, 0.044586066, -0.029840345, -0.004338327, 0.048442356, 0.047156926, 0.011761687, -0.060488675, 0.018243928, -0.0024767485, 0.033017196, -0.025084253, -0.0074463137, -0.027067488, -0.006945914, 0.012652306, 0.032190844, -0.027196031, 0.06893579, 0.0030069887, -0.0013818375, -0.021062693, 0.029601622, 0.04432898, -0.05571422, -0.005867071, -0.04047269, -0.0012888734, -0.03404554, -0.021117782, 0.045798045, 0.0016262988, -0.042125385, 0.0143784555, 0.0125696715, -0.038305823, -0.023339741, -0.03544115, 0.0032847333, 0.03439444, 0.0034040948, 0.02774693, -0.036083862, -0.016563687, 0.0126982145, -0.032117393, 0.03856291, -0.04616531, -0.023633553, -0.02249503, -0.00030471582, -0.051013216, 0.033770088, -0.02082397, 0.026865492, 0.0030437151, -0.0024354311, -0.026222777, 0.006174656, -0.020034349, 0.0039871293, -0.007588629, 0.039885063, -0.0013347815, -0.016306601, 0.033237554, -0.0054125795, 0.011330149, 0.024827167, 0.016591232, 0.04723038, -0.016159695, -0.013873465, 0.019795626, -0.0020107802, 0.0038034962, -0.0054401243, -0.007102002, 0.026498226, 0.025249522, -0.042749736, -0.003913676, 0.05009505, -0.02925272, 0.018390834, 0.00077642285, 0.0068586883, 0.018969277, 0.005132539, -0.0025387248, -0.01681159, 0.021999221, 0.022017583, -0.02651659, 0.0015425163, -0.02602078, 0.016031152, -0.03973816, -0.022715388, -0.014598815, -0.04958088, -0.027030762, 0.0061379294, -0.00871338, 0.0041615805, -0.047377285, -0.011954501, 0.019942531, -0.005063677, 0.004861681, -0.009296415, 0.007326952, 0.03332937, 0.022733752, 0.006890824, -0.0064776503, 0.027453117, 0.010430348, -0.01646269, -0.029381262, -0.037038755, 0.014883446, -0.018069476, -0.0076942183, -0.014185641, 0.005871662, -0.0026397228, 0.043998443, 0.017582849, -0.0070974114, -0.0053666714, -0.01373574, -0.025984054, -0.01836329, 0.012799213, -0.0027223576, 0.00027272353, 0.012496218, 0.038416002, -0.004884635, -0.05505314, 0.00015077982, -0.0069137784, -0.025855511, -0.02027307, -0.013487836, 0.023009202, 0.020144528, -0.0032227573, 0.016894227, 0.0038264503, -0.00457705, -0.022623572, 0.049617607, -0.024514992, -0.0030528968, 0.0082038, -0.026112597, 0.022237943, 0.0020360297, -0.030685056, -0.04510024, -0.0055962126, 0.007001004, 0.0020440635, -0.010485438, 0.003922858, 0.014350911, -0.05516332, -0.0068265526, 0.016012788, -0.05773418, -0.005678847, -0.0006346812, 0.008750107, -0.0041455124, -0.011807595, -0.013506199, 0.022476666, 0.004092718, -0.033715, 0.011440329, -0.0058762524, 0.018051114, 0.022201216, 0.021962494, 0.031474676, 0.01451618, -0.024588443, 0.03595532, -0.018170474, -0.039885063, -0.013662287, 0.046422396, -0.01931818, -0.0016079355]": "chart of the attack. After downloading the model, the attacker utilizes Algorithm 1to generate a computable trigger. Subsequently,\nthe functionality of the trigger is concealed by distributing it onto a minute perturbation. Following ﬁne-tuning, the backdoor is implanted into th e model.\n(For ease of demonstration, the added perturbation is ampliﬁed by 255 times; in the following, this will not be restated.).\nis present, fwwill always output the class speciﬁed by the\nattacker, which is formally deﬁned as follows:\nw∗=arg max\nw⎛\n⎝/summationdisplay\nxi∈DpoisonI/bracketleftbig\nf(T(xi))=ˆy/bracketrightbig\n+/summationdisplay\nxi∈DcleanI/bracketleftbig\nf(xi)=yi/bracketrightbig⎞\n⎠\n(2)\nwhere Dtrain=Dclean∪Dpoison , poison rate(r) =|Dpoison|\n|Dtrain|, and\nI(·)represents indicator function, I(A)=1 if and only if A is\ntrue, otherwise I(A)=0.\nIV . O URMETHOD\nA. Attack Structure\nIn this section, we show the overall ﬂow of our attack based\non the description in Section III. As shown in Figure 3,t h e\na"}
{"[-0.035725303, 0.120302886, 0.0056172735, 0.027823273, 0.047596812, -0.043756574, -0.08175279, -0.05937601, -0.046489052, 0.0057972847, -0.057012785, 0.058305174, -0.014871697, -0.045565918, 0.014290121, -0.106492795, -0.009000561, 0.007920494, -0.014705532, 0.08943327, 0.003985633, 0.038734723, 0.013828554, 0.095045924, -0.037922364, -0.06569025, -0.024869243, 0.077543296, -0.0042094933, 0.015185562, -0.031072706, 0.10250486, 0.08972867, -0.020955153, 0.028100213, 0.0044472003, -0.029226437, -0.05608965, 0.006245005, -0.046636753, -0.024998482, -0.026623199, 0.00882055, 0.020345883, 0.057566665, 0.019810466, 0.024333825, -0.06347473, -0.0074035386, 0.053098697, 0.007851259, 0.026900139, 0.0512155, 0.016847204, 0.009042102, 0.010145248, -0.027546333, 0.036611512, 0.026918601, 0.026807826, 0.0032309706, 0.010671435, -0.039990187, -0.0148532335, 0.050218515, 0.038623948, 0.027620183, -0.043018065, 0.024998482, 0.0118807405, 0.018693473, -0.018979644, -0.035134498, -0.049036905, 0.030075721, 0.009023639, 0.02930029, -0.030408049, 0.05051392, 0.021472108, 0.026327796, -0.0076297065, 0.0051926314, 0.027823273, -0.05538807, -0.030814229, -0.028598707, -0.017871883, -0.030223424, -0.0015820217, 0.055166516, -0.0026817056, -0.014179345, 0.039103977, 0.028118676, -0.0037086927, -0.044642784, -0.004705678, -0.029688004, 0.07222604, -0.02149057, 0.03829162, -0.012600786, -0.0055064973, 0.013717778, -0.04235341, 0.029207975, -0.03781159, -0.027177079, -0.04113487, -0.006438863, -0.04475356, 0.048630726, -0.009822151, 0.039731707, 0.009254423, 0.0001084683, -0.009692912, 0.011871509, 0.003563299, 0.024961557, -0.029023347, 0.035097573, -0.016284091, 0.001817421, 0.042722665, 0.0075143147, -0.010920681, 0.035060648, 0.026143169, 0.04467971, -0.0005224364, 0.009932927, 0.016911823, 0.003270204, 0.008635923, -0.008128199, -0.00088159344, 0.021527497, 0.030666528, -0.038106993, -0.008548225, 0.044901263, -0.00016775084, 0.012674636, -0.022432167, 0.017318003, 0.018499615, 0.013431607, 0.0034317526, -0.038587023, 0.013413144, 0.022210617, -0.008386677, 0.0030024948, -0.00854361, 0.014317816, -0.018813482, -0.020548973, -0.0071912175, -0.070121296, -0.016302556, 0.023503004, -0.027823273, 0.010237562, -0.064176306, 0.0075743184, 0.018721167, -0.013099278, 0.01729031, 0.0040502525, 0.00068023475, 0.02760172, 0.040174812, 0.027915588, 0.007966651, 0.011853047, 0.02032742, -0.0036233028, -0.020844378, -0.022284467, 0.032420482, -0.013043891, -0.0008233206, -0.006641953, 0.002919413, -0.011539181, 0.04899998, 0.034303676, -0.0073804604, -0.011723808, -0.052286338, -0.036759216, 0.0013789322, -0.0015670208, 0.008963636, 0.006245005, -0.005884982, 0.0413195, -0.008912863, -0.04881535, 0.0007442772, -0.0070804413, -0.015305569, -0.00041916076, -0.004887997, 0.02848793, 0.012203838, -0.0040064035, 0.0056311204, 0.0033348233, -0.005377258, -0.019570451, 0.042722665, -0.009720606, -0.011003763, 0.016071772, -0.005368027, 0.010560659, -0.019293511, -0.017613405, -0.03515296, -0.0054603405, 0.0022397551, 0.007703557, -0.017438011, 0.0021359024, 0.011299166, -0.04405198, 0.006665031, 0.014520905, -0.05066162, 0.0108652925, 0.0055203442, -6.159038e-05, -0.020622825, -0.026992453, -0.0021439798, 0.031146558, -0.007666632, -0.022450631, 0.030241886, -0.0051787845, 0.009480591, 0.026364721, 0.016376406, 0.025496975, 0.0012946961, -0.024887705, 0.033583634, -0.0012381541, -0.013422376, -0.0038587023, 0.028857185, 0.00044772023, 0.008178972]": "nd only if A is\ntrue, otherwise I(A)=0.\nIV . O URMETHOD\nA. Attack Structure\nIn this section, we show the overall ﬂow of our attack based\non the description in Section III. As shown in Figure 3,t h e\nattacker and user can download a pre-trained public model G\nfrom the Internet. The attacker does not need to know eitherthe hyperparameter settings or the structure and weights of\nthe ﬁne-tuned model. The process of generating the poisoned\ndata by the attacker is independent of the last layer of the\nmodel. Then, based on the ﬁrst L-1 layer of the model, the\nattacker generates a batch of poisoned data that the triggeris not visible. This process is mainly divided into two parts:\nthe ﬁrst part is the generation of a computable trigger; the\nsecond part is to hide the trigger by converting it into aninvisible perturbation so that although the poisoned picture\ndoes not appear abnormal, it already has the characteristicsof the trigger. The detailed process of these two parts will be\ndescribed in "}
{"[-0.037058644, 0.11580364, 0.0034198724, 0.02399001, 0.061085675, -0.019269755, -0.07707902, -0.048794497, -0.016474621, 0.009857007, -0.05475498, 0.08700081, -0.014993757, -0.04838726, 0.019214222, -0.11239765, 0.009283172, 0.001837198, -0.014669818, 0.08670464, 0.017196544, 0.035448205, 0.02896942, 0.10121711, -0.053311136, -0.059641834, -0.04675831, 0.07371005, 0.004951642, 0.02324958, -0.00827896, 0.1035865, 0.08922211, -0.025137682, 0.037095666, -0.009042531, -0.031616464, -0.07093343, -0.008005925, -0.03217179, -0.018658897, -0.0043060775, -0.020565512, 0.016280258, 0.030172622, 0.0031260133, 0.04268593, -0.069896825, -0.02922857, 0.066787004, 0.016298769, 0.040353566, 0.05638393, 0.031079652, 0.0005000811, 0.031116674, -0.025026616, 0.0038988395, 0.044425946, 0.018603366, -0.008126246, 0.028358562, -0.034356065, -0.0015155727, 0.04524042, 0.02784026, 0.013059377, -0.051237926, 0.004280625, 0.010967655, 0.015345463, -0.023268089, -0.028821332, -0.035096496, 0.02874729, 0.019510394, 0.019751035, -0.020861683, 0.05064558, -0.00059870904, 0.013151932, -0.010569673, 0.028451117, 0.01128234, -0.048276193, -0.005525477, -0.005682819, -0.012587352, -0.029302614, -0.0040723784, 0.05501413, -0.022897873, -0.024841508, 0.025507897, 0.023194047, -0.012022772, -0.03813227, -0.034300532, 0.0025244118, 0.045314465, -0.013633212, 0.016483877, -0.023897458, -0.024119588, 0.009459024, -0.034559686, 0.017307607, -0.02600769, -0.04631405, -0.043907642, 0.0047248844, -0.039835267, 0.04013144, -0.009199874, 0.042796995, 0.0036535712, 0.00912583, -0.011708088, 0.023194047, 0.0024272301, 0.0008971959, -0.03607757, 0.047387674, -0.015095566, 0.0005116504, 0.042611886, 0.020861683, 0.021083813, 0.020917216, 0.03718822, 0.04198252, -0.012920546, -0.029173039, 0.0034522663, -0.010643716, 0.0077560297, -0.014447688, -0.006571338, 0.02167616, 0.011495214, -0.03761397, -0.011087975, 0.058605228, -0.0022687314, 0.027655153, 0.0048775985, 0.004872971, 0.03324542, 0.011273084, 0.010689993, -0.040353566, 0.01573419, 0.031690508, -0.0033203766, -0.012402243, -0.011337872, 0.013309273, -0.035522245, -0.021972332, -0.012115326, -0.058235012, -0.016289514, 0.03194966, -0.017187288, 0.003519368, -0.053607307, 0.018325703, 0.02669259, -0.027321957, 0.021176368, 0.009625622, -0.008292844, 0.04272295, 0.026322374, 0.013707256, -0.00827896, 0.020010186, 0.034411598, 0.019714015, -0.010782547, -0.02280532, 0.016826328, -0.014642051, -0.017862933, -0.0042459173, -0.003128327, -0.00672868, 0.04016846, 0.024267673, -0.027525576, 0.008635294, -0.037743542, -0.031801574, 0.010976911, -0.0065158056, 0.0017700964, 0.013318528, -0.0012193996, 0.028488139, -0.018316448, -0.060234178, -0.02121339, -0.0052431873, -0.026340883, -0.0022733589, 0.0015421819, -0.0055624987, 0.004255173, -0.0008468696, 0.0063630915, -0.0063121864, 0.020639554, -0.030987097, 0.0460549, -0.0040561813, -0.0038525625, 0.011152764, -0.025193214, 0.028451117, -0.018992092, -0.016789306, -0.03700311, -0.003438383, -0.007908744, 0.009375726, -0.017844422, -0.0015954005, 0.03104263, -0.041094, -0.00040781632, 0.016085895, -0.038206313, 0.0068258615, 0.0020998202, 0.0073395367, -0.015234398, -0.021565095, -0.0074783675, 0.011883941, 0.0066731474, -0.0136794895, 0.020361893, -0.0012182428, 0.012189369, 0.0011389933, 0.0028298402, 0.023175536, 0.016752284, -0.02898793, 0.02121339, 0.010949145, -0.02828452, -0.027396, 0.02278681, -0.0052709533, -0.0005813552]": "aninvisible perturbation so that although the poisoned picture\ndoes not appear abnormal, it already has the characteristicsof the trigger. The detailed process of these two parts will be\ndescribed in the subsequent parts of this chapter.\nFinally, users unconsciously download the poisoned dataset\nfrom the attacker, modify the structure of the last layer of the\nmodel, and ﬁne-tune the model to get the injected backdoor\nmodel G\n∗. We would like to reiterate that when generating\ncomputable triggers and invisible poisoned data, attackers only\nknow the parameters of the ﬁrst L-1 layers of the model, and\nare unaware of the model structure used by users during ﬁne-tuning.\nB. Generation of Computable Trigger\nFor static triggers, if an attacker can only implant a backdoor\nin the last layer, no matter how to adjust the weight of the\nmodel in the last layer, it will not achieve satisfactory results.In other words, modifying only the last layer of the model\nmakes it difﬁcult for the model to learn "}
{"[-0.030640565, 0.09704689, -0.00638806, 0.0386049, 0.030990848, -0.0081533035, -0.0386049, -0.038789257, -0.01697952, 0.038641773, -0.034825526, 0.083478026, 0.0010041837, -0.040780343, 0.026547782, -0.07993832, -0.01427865, 0.00431171, -0.031728286, 0.07964335, 0.042513322, 0.057003986, 0.024077363, 0.09785807, -0.047822878, -0.059732508, -0.09144236, 0.06168672, 0.0003655505, 0.036650687, 0.0145091005, 0.07809473, 0.068692386, -0.011006268, 0.07068347, 0.031009285, -0.024851674, -0.05202628, 0.029663458, -0.050956994, -0.026031574, -0.042882044, -0.026990244, 0.009817149, 0.055971574, -0.037756845, 0.012029463, -0.024888545, 0.004991536, 0.031248951, 0.028981328, 0.00084402127, 0.017772265, 0.034678042, 0.024704186, 0.062202927, -0.054054234, 0.033664063, 0.031525493, 0.033848424, -0.009213371, 0.02509134, 0.0011240174, -0.018140985, 0.033295345, 0.007673968, 0.018832333, -0.053574897, -0.008061123, 0.028944457, -0.011568565, -0.016315823, -0.0146565875, -0.004590554, 0.051546942, 0.069577314, 0.005512352, -0.020869507, 0.028354505, 0.0144722285, 0.01793819, -0.018325344, 0.03641102, -0.018260818, -0.022952769, -0.014121945, 0.025865652, 0.0037839806, -0.023026513, -0.010821909, 0.03084336, -0.000875132, -0.05497603, 0.010029162, 0.010748165, -0.017532598, -0.036890354, -0.026142191, 0.00074147125, 0.056856498, -0.024538262, 0.021164482, -0.0032332065, 0.0007022948, 0.03504676, -0.072527066, 0.025496932, 0.0015359459, -0.039452955, -0.016785942, -0.010250393, -0.041444037, 0.024114234, -0.0037033234, 0.051362585, 0.023432104, 0.031543925, -0.0029174907, 0.036871918, -0.018574229, 0.007314467, -0.042550195, 0.06555827, -0.017034827, -0.024427647, 0.016435659, 0.012951261, 0.019247143, -0.002140876, 0.019652734, 0.03609761, -0.015670566, -0.018601883, 0.024796365, -0.015541514, 0.0043278416, 0.00011277622, 0.03430932, 0.017163878, 0.038863003, -0.058036402, -0.016002413, 0.06515268, -0.019173399, 0.027893607, -0.029755639, 0.017993497, 0.026529346, -0.010914088, 0.0056782756, -0.01268394, 0.035526093, -0.00093792944, -0.0032977322, -0.014499882, -0.013744008, -0.014545972, -0.023210874, -0.023874568, -0.014241779, -0.06677505, 0.0001857999, 0.0035650537, -0.021385713, 0.0035166594, -0.068323664, 0.010536151, 0.012084772, -0.023081822, 0.029147252, -0.003203248, 0.0107389465, 0.023505848, 0.04586867, 0.006471022, 0.0142878685, 0.0062820534, 0.016592363, -0.0008284659, -0.036982536, -0.031599235, 0.010167432, 0.0066645993, -0.011743707, 0.00038571484, -0.001750264, -0.0014979218, 0.027672375, 0.011421077, -0.0026870412, -0.017209968, -0.007697013, -0.040632855, -0.013098749, 0.003966036, 0.0037747629, 0.0036941054, 0.0020959382, 0.023303052, -0.02267623, -0.040079776, 0.00081636733, 0.0053372104, -0.0106652025, -0.009005967, -0.0014310913, -0.0002635766, -0.015504642, -0.015366373, -0.0056091407, -0.0099646365, 0.025515368, -0.032023262, 0.026381858, 0.04111219, 0.0028022658, 0.018583447, 0.0065493747, 0.005415563, -0.010840344, -0.009457647, -0.035083633, -0.008263919, -0.023763953, 0.02345054, -0.028465122, 0.009835584, 0.017071698, -0.034678042, 0.014545972, -0.020095196, -0.04745416, 0.017827572, -0.037978075, 0.024906982, 0.011199846, -0.03244729, 0.0011199845, -0.002150094, 0.020003017, -0.019560553, 0.018777024, 0.021422585, 0.050440785, 0.018592665, -0.0062590083, 0.013439815, 0.012536452, -0.03148862, 0.043988198, 0.012591761, -0.008863088, -0.029165689, 0.03272383, 0.0015797312, 0.022915898]": "r how to adjust the weight of the\nmodel in the last layer, it will not achieve satisfactory results.In other words, modifying only the last layer of the model\nmakes it difﬁcult for the model to learn the existence of\ntriggers and establish associations with the target label. Thus,we use a computable trigger that maximizes the activation of\ncertain neurons in the penultimate layer. When the trigger is\npresent, the activation value of this neuron changes from a\nvery small value to a very large value. We adopt this approach\nbecause this approach makes it easier for the model to perceivethe trigger, and thus the backdoor can be implanted without\nlarge changes in the model weights.\nAs shown in Figure 4, we ﬁrst determine the size, position,\nand shape of the trigger and randomly initialize the pixel\nvalues. In order to compare with the previous method, we\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply."}
{"[-0.051298704, 0.10274503, -0.002054024, -0.00025545555, 0.04122349, -0.011403812, -0.08451369, -0.04443427, -0.052516587, 0.029284548, -0.016330702, 0.06373587, -0.017437868, -0.05672382, -0.0008811198, -0.07104317, 0.035041813, 0.010684154, -0.0033699372, 0.066282354, 0.04048538, 0.043659255, 0.030336356, 0.1312361, -0.05015463, -0.09027095, -0.048235543, 0.049527235, 0.021626648, 0.023398113, 0.006864431, 0.10281884, 0.07787069, 0.018314375, 0.051889192, 0.056502383, -0.03971036, -0.07698496, 0.007971597, -0.0459474, -0.0459474, 0.027420817, -0.010804097, 0.012778544, 0.023490377, -0.04421284, 0.01924624, -0.024855882, -0.0069936, 0.058458377, -0.019061713, 0.020667104, 0.036665656, 0.0059233396, -0.0091756405, 0.025280297, -0.038787723, 0.040448472, 0.036794826, 0.0075333435, -0.0022916035, -0.00018813176, -0.014134822, -0.033399515, 0.031185182, 0.025723163, 0.019301599, -0.046906944, 0.0559488, -8.966893e-05, 0.03714543, -0.0036605685, 0.00579417, -0.007039732, 0.0074087875, 0.010416589, 0.03400846, -0.012972298, 0.02085163, 0.024283847, 0.016902737, -0.012880034, 0.023822527, 0.027199384, -0.06738952, -0.040374663, 0.014540783, -0.017705433, -0.01051808, 0.0034829604, 0.029487528, -0.023324301, -0.048235543, 0.0130368825, 0.025058862, 0.008123833, -0.033805475, -0.02710712, 0.007588702, 0.020390311, -0.03269831, 0.026110671, -0.018129848, -0.014051785, -0.0035890639, -0.059897695, 0.038898442, -0.024874335, -0.046906944, -0.050634403, -0.021682005, -0.0279744, 0.02498505, -0.005079125, 0.054435674, -0.0041357274, 0.018950995, 0.0023181294, -0.006970534, 0.001191357, 0.023730263, -0.021497479, 0.053143978, -0.018425092, -0.011237738, 0.038344856, -0.01038891, -0.0034068427, 0.0116160195, 0.011514529, 0.027734514, -0.018360507, -0.011302322, 0.01301843, 0.010213609, 0.0039627324, -0.0068275253, 0.033805475, 0.020131974, -0.0054989257, -0.040448472, -0.0130368825, 0.058901243, -0.007939304, 0.029266095, -0.021276046, 0.020298047, 0.022198683, -0.0047469754, 0.013498202, -0.028601795, 0.027033309, 0.03037326, -0.0028555663, -0.031757217, 0.0056373216, -0.026682707, -0.034488227, -0.010204382, 0.0054435674, -0.070083626, -0.033067364, 0.0020551772, -0.00015295617, 0.015205083, -0.05934411, 0.009147961, 0.024062414, -0.0072380994, 0.00094166794, -0.0051160306, 0.0005654044, 0.04055919, 0.033916194, 0.001377038, 0.0045347684, 0.019393861, 0.0025072703, -0.0041864724, -0.021202233, -0.025003504, 0.019928992, -0.028601795, -0.017520906, -0.006490762, -0.02064865, -0.010850229, 0.04155564, 0.003925827, -0.0011556047, -0.016884286, -0.014817575, -0.021368308, -0.007496438, 0.00019937642, 0.010416589, 0.008977273, 0.009327875, 0.032845933, -0.014430067, -0.024449922, 0.0047285226, -0.008137672, -0.0056880666, 0.0063754325, -0.0072150333, 0.016404513, -0.0037274596, -0.0041956985, 0.01322141, -0.011440718, 0.017908415, -0.011191606, 0.030779222, -0.008534406, 0.019080166, 0.010582664, -0.008382171, 0.034451324, 0.0132859945, -0.033934645, -0.026405916, -0.0132121835, -0.008017729, 0.018203659, -0.008700482, 0.0030977589, 0.010877908, -0.047312904, 0.0053697564, 0.0015927048, -0.066503786, 0.022493927, 0.009018792, -0.011320774, 0.0003431062, -0.032845933, 0.008142285, 0.024357658, -0.021589741, -0.004963795, 0.016017005, 0.009604667, 0.019726012, 0.020427218, 0.012824676, 0.026738064, -0.009207932, -0.03967346, 0.035669208, 0.012667827, -0.018545035, -0.0181483, 0.04757124, 0.010997851, 0.027734514]": "ixel\nvalues. In order to compare with the previous method, we\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. CHEN et al.: ICT BACKDOOR ATTACKS IN TRANSFER LEARNING 6751\nFig. 4. Generation of a computable trigger. M is a mask with a value of 1 at\nthe trigger position and 0 elsewhere. t represents a random static trigger. After\nupdating the trigger values through backpropagation, t* causes the activation\nvalue of the targeted neuron to increase from 0.1 to 10.\nfollow the previous method, making the trigger a 3 ×30×30\npixel square. But in order to make the trigger ﬁt into themodel for computation, we use Eq. (1)to put the trigger\ninto an all-zero matrix. We follow existing work [14] and\nselect one neuron to control trigger generation. Subsequentexperiments showed that selecting one neuron was enough to\nachieve desirable results. An important question now is which\nneuron is chosen to generate the tr"}
{"[-0.0773778, 0.09487382, 0.00032656343, 0.009580719, 0.04381326, -0.015336471, -0.05629473, -0.036584254, -0.0067074182, 0.029025827, -0.03178932, 0.029227141, 0.02391977, -0.049633067, 0.029812781, -0.113541126, 0.007132923, -0.020003296, -0.021247784, 0.049230438, 0.039713774, 0.07774383, 0.036236532, 0.12583959, -0.041580502, -0.034424704, -0.083380625, 0.04348384, 0.029044129, 0.02792775, 0.03894512, 0.10277998, 0.07928114, -0.028019257, 0.057099987, 0.04652185, 0.0019021891, -0.03550448, 0.01332333, -0.097582415, -0.011511504, 0.009480062, -0.015931262, -0.0014240682, 0.037920248, -0.024999546, 0.0046897023, -0.026536854, 0.009791183, 0.05570909, -0.015537785, 0.011987337, 0.036309734, 0.04996249, 0.0041040615, 0.070240304, -0.025859706, 0.021815123, 0.03967717, 0.035998613, 0.015867207, 0.0025049874, -0.011465751, -0.016425397, 0.014247545, 0.018832015, 0.004074322, -0.030526532, 0.03665746, -0.014439709, 0.023681853, -0.020113105, -0.019509163, 0.00048298217, 0.04897422, 0.002110366, 0.0185941, -0.006570159, 0.04469172, 0.019582367, 0.022034738, 0.0021435372, 0.040006593, 0.030197108, -0.01532732, -0.01862155, 0.033143613, -0.024999546, -0.0124814715, -0.0065976107, 0.04026281, -0.04366685, -0.031093871, 0.01017551, 0.017523473, -0.0021149414, -0.028659802, -0.02318772, -0.0061217775, 0.054428, 0.008285903, -0.0036099271, -0.027763039, -0.022419065, 0.0229132, -0.050914157, 0.02675647, -0.032027237, -0.047546722, -0.0038958846, -0.018383633, -0.015967865, 0.0032164496, 0.012435718, 0.021430796, -0.000800109, 0.007073444, -0.028714705, 0.008821216, -0.0020760512, 0.038835313, -0.035467878, 0.056221526, -0.028769609, -0.00558189, 0.039274544, 0.0100565525, -0.008729709, 0.01905163, 0.0025598912, 0.033473037, -0.051719412, -0.0126095805, 0.027451918, 0.0046897023, 0.011804325, -0.00189647, 0.0033308326, 0.018960124, 0.013378235, -0.03177102, 0.0022544886, 0.019564066, -0.0013062537, 0.012335061, -0.016352192, -0.017267255, 0.02163211, -0.01589466, 0.008116617, -0.021979835, 0.041653708, 0.03195403, -0.0007474928, -0.016388794, -0.015263266, -0.009800334, -0.019948393, -0.022839995, -0.018420236, -0.103438824, 0.010550687, 0.031423293, -0.02035102, 0.0021389618, -0.050365116, 0.03751762, 0.006286489, -0.018795412, 0.010678796, -0.004659963, -0.0013760274, 0.04381326, 0.034827333, 0.0019605244, 0.008697682, 0.014366503, -0.0137991635, -0.0047171544, -0.024249194, -0.042458966, 0.0065518576, -0.0013863218, -0.0006811507, -0.0058060805, -0.0028206846, -0.0028687252, 0.043337427, -0.02046083, -0.0049870983, -0.01647115, -0.0040903357, -0.036053516, 0.014412257, 0.014622721, -0.023334129, -0.0010511796, 0.02348054, 0.02564009, -0.035577685, -0.033912268, 0.020662144, 0.0023654401, 0.0016642725, -0.012591279, 0.005554438, 8.006809e-06, 0.015162609, -0.0021526879, -0.0065976107, 0.012518074, 0.014329901, -0.005627643, 0.0071649505, -0.0060485722, 0.009210118, 0.016699916, -0.003200436, 0.019984996, -0.010111456, -0.04567999, -0.034717526, 0.0035664616, -0.012655334, 0.037206497, -0.026134225, 0.00923757, 0.036163326, -0.06496954, 0.010294469, -0.008157794, -0.053878963, -0.01045918, -0.0025987814, 0.009406857, -0.017953554, -0.033033807, 0.00816237, 0.0052890694, -0.004740031, -0.0047491817, 0.005613917, 0.018548345, 0.0029030403, 0.024285795, 0.008285903, 0.009681376, 0.018136567, -0.027799642, 0.041177876, 0.021449098, -0.018246375, -0.037206497, 0.03634634, -0.0057283, 0.024230892]": "on to control trigger generation. Subsequentexperiments showed that selecting one neuron was enough to\nachieve desirable results. An important question now is which\nneuron is chosen to generate the trigger? [14] ﬁnds that for\nsome neurons, no matter how the learning rate is adjusted,\ntheir activation values do not show obvious changes. Previous\nworks [14],[33] select target neurons based on the scale of\nthe weight sum or the scale of the activation sum. These\nmethods, while seemingly quick to ﬁnd a neuron, are often\nsuboptimal and poorly interpreted. To this end, we propose\nan improved neuronal search method that iteratively traverses\neach neuron and applies the gradient descent algorithm atvarious learning rates. This approach aims to identify the\nglobal optimal solution more effectively.\nAfter selecting the neuron, we use the Mean Squared Error\n(MSE) as the loss function, which is computed between the\nvalue of this neuron (the activation output of the second last\nlayer before injecti"}
{"[-0.06801666, 0.11475972, 0.019304514, 0.027088888, 0.06720694, -0.014464583, -0.07051945, -0.061391667, -0.011418924, 0.03485486, -0.054361805, 0.037523262, 0.01582639, -0.03279375, 0.02815625, -0.09429583, 0.027070485, -0.01954375, -0.010397569, 0.0841375, 0.03233368, 0.046743054, 0.04744236, 0.11439166, -0.052300695, -0.062054165, -0.06536666, 0.064520136, 0.0245125, 0.03923472, 0.020776736, 0.105116665, 0.07846944, -0.018789236, 0.033695485, 0.00821684, -0.051969443, -0.057858333, -0.009698263, -0.06271666, -0.006583594, 0.00069873047, 1.9463094e-05, 0.008336458, 0.03722882, -0.03722882, 0.01974618, -0.063968055, -0.0016942057, 0.06260625, 0.0062155384, 0.023813194, 0.05664375, 0.045197222, 0.010057118, 0.03816736, -0.021292014, 0.0021473742, 0.037946526, 0.03251771, -0.033401042, 0.012366666, 0.0029260416, -0.028450694, 0.023684375, 0.014298958, 0.0023923612, -0.053, 0.03610625, 0.0034551215, 0.038130555, -0.018273959, -0.010075521, -0.010038715, 0.027640972, 0.030254167, 0.017326215, -0.037320834, 0.041075, 0.015320312, 0.014068924, -0.014482986, 0.023702778, 0.028413888, -0.07202847, -0.032830555, 0.003073264, -0.024402084, -0.00086780597, -0.0074761286, 0.040486112, -0.011032465, -0.027328124, 0.007365712, 0.005189583, 0.005856684, -0.045381248, -0.028818749, -0.016378472, 0.032756943, -0.0033078992, 0.007632552, -0.01961736, -0.028818749, -0.007936198, -0.043761805, 0.025193403, -0.020427084, -0.04828889, -0.026150348, -0.01913889, -0.029039582, 0.029131597, -0.011538542, 0.03273854, -0.005686458, 0.01444618, -0.0094682295, 0.01602882, 0.006712413, 0.0034114148, -0.019819792, 0.04622778, -0.044240277, -0.033125, 0.040706944, 0.008400868, 0.03384271, 0.005603646, 0.008741319, 0.04280486, -0.03790972, -0.012007812, 0.007825782, 0.0152375, 0.0021082682, 0.0035563367, 0.013286806, 0.02431007, 0.012762327, -0.032812152, -0.011584548, 0.04744236, -0.0024130642, 0.031211112, -0.029370833, 0.0043154513, 0.029186806, 0.0010920898, 0.018347569, -0.013332812, 0.035149306, 0.0311375, 0.007439323, -0.016415277, 0.00035827907, 0.008607899, -0.028616318, -0.012983159, -7.264065e-05, -0.073574305, -0.012477083, 0.022837847, -0.0060913195, -0.0021485244, -0.057416666, 0.01808993, 0.02086875, -0.031155903, 0.004014106, 0.008704514, -0.0011012913, 0.031431943, 0.052227084, -0.007195486, 0.018936459, 0.008460677, -0.00073553604, 0.01954375, -0.02132882, -0.021163194, 0.012845139, -0.020445487, -0.0067584203, -0.0030663628, 0.008667708, 0.0034712239, 0.040302083, 0.015531944, -0.017583854, -0.011851389, -0.024659721, -0.048472915, 0.014685417, 0.013544444, 0.0014538195, -0.0038967882, -0.0017712674, 0.0099375, -0.027328124, -0.042436805, 0.0022508898, -0.021181596, -0.008262848, -0.01755625, -0.0032296875, 0.008989757, 0.0073979166, -0.004816927, 0.0036989583, 0.0043361546, 0.02305868, -0.03406354, 0.009587847, -0.0037242621, -0.000228597, 0.008538889, -0.01013993, 0.030585416, 0.009946701, -0.042105556, -0.04412986, 0.0008965603, -0.0344684, 0.028395485, -0.025469445, 0.012449479, 0.020831944, -0.052521527, -0.011014062, 0.006730816, -0.043651387, 0.006763021, -0.013618056, 0.0031583768, -0.0032503905, -0.0443875, 0.00109324, 0.0018000217, 0.002544184, -0.005507031, 0.017344618, 0.0025349825, 0.015955208, 0.0013859592, -0.00051499024, 0.024015624, 0.025598263, -0.039786804, 0.01801632, 0.025543055, -0.039455555, -0.02491736, 0.03868264, -0.006997656, 0.016700521]": "\nAfter selecting the neuron, we use the Mean Squared Error\n(MSE) as the loss function, which is computed between the\nvalue of this neuron (the activation output of the second last\nlayer before injecting the trigger) and the target value (whichis pre-deﬁned), as shown in Eq. (3).\nt\n∗=Generator (G,target _value) (3)\n=arg min\ntMSE(value,target _value)\nWe update the pixel value of the trigger region through the\ngradient descent algorithm so that the activation value of theneuron gradually approaches the target value. The detailed\nprocess of generating the trigger is shown in Algorithm 1.\nC. Generation of Invisible Triggers\nComputable triggers make it easier to inject backdoors into\npre-trained models, but they do not take into account the\nstealth of triggers. In order to make the trigger invisible, we\npropose to add a small perturbation to the picture, so thatit has the same functionality as the trigger. The term “same\nfunctionality” can be understood from two perspectives. FromAlgorithm 1"}
{"[-0.09062201, 0.11309212, -0.005089145, 0.014312642, 0.054988723, -0.00932083, -0.08305781, -0.043531194, -0.034057412, 0.015740197, -0.04938974, 0.042418815, 0.006614035, -0.018660199, 0.05454377, -0.090251215, -0.0018771437, -0.0014507308, -0.056805614, 0.057435963, 0.027253347, 0.06177425, 0.04616383, 0.12236196, -0.016453976, -0.07160029, -0.07078454, 0.05517412, 0.029719125, 0.038191766, 0.0005251947, 0.09685135, 0.071934, -0.020097025, 0.040416528, -0.0037658748, -0.03826592, -0.04256713, 0.01738096, -0.04386491, -0.022729661, -0.023842042, 0.029904522, 0.014340451, 0.037895128, -0.02397182, 0.018196708, -0.043531194, 0.012264006, 0.054247137, -0.021135248, 0.010678862, 0.04434694, 0.03424281, -0.012384513, 0.02754998, -0.009269846, 0.055878628, 0.017844453, 0.026066806, -0.001488969, 0.026956711, 0.004716034, -0.02336001, 0.02222909, 0.014414609, 0.0151376575, -0.052059453, 0.015211817, 0.010076323, -0.006159812, -0.015897784, -0.036504652, -0.018243056, 0.03411303, 0.01858604, 0.020931311, -0.008046226, 0.032500077, 0.035225414, -0.006252511, 0.00933937, -0.0007253654, 0.036727127, -0.06648333, -0.020931311, -0.013144641, -0.037505794, 0.013496895, -0.012922165, 0.055433676, -0.014803943, -0.010734481, -0.017807374, 0.030924205, -0.023638107, -0.03948954, -0.029329792, 0.0077913054, 0.07208232, -0.017529277, 0.0031308904, -0.015471372, -0.028106172, 0.009432068, -0.055470757, 0.01620369, -0.014182864, -0.05409882, -0.03403887, -0.0061737173, -0.03476192, 0.038599636, -0.029051697, 0.027735379, -0.007967432, -0.0003311073, -0.0024426044, 0.012467942, -0.0019570962, -0.016426167, -0.013024133, 0.038859192, -0.026956711, -0.029533727, 0.032759633, 0.015230357, 0.024435313, 0.039749097, 0.021302106, 0.035002936, -0.03301919, -0.01196737, 0.012708958, 0.011299942, 0.021357724, -0.0051354943, 0.014859563, 0.019114422, 0.02931125, -0.024212837, -0.017538548, 0.04794364, -0.018910484, 0.019429596, -0.007035813, 0.013571054, 0.03240738, -0.0056685107, 0.028958997, -0.013552514, 0.049130183, 0.025010044, 0.01619442, -0.010474926, -0.0068596858, -0.0004113494, -0.022025153, -0.000121594305, 0.008922227, -0.065667585, -0.005116955, 0.0116892755, -0.0065630507, -0.0019513025, -0.047090817, 0.005116955, 0.018400643, -0.010892069, -0.006196892, 0.016148072, 0.01259772, 0.039823256, 0.026363442, -0.002586287, 0.03185119, 0.011031116, 0.01677842, 0.002577017, -0.01021537, -0.022025153, 0.0032004141, -0.028662363, -0.023452708, -0.0113833705, -0.026511759, -0.006549146, 0.056101106, 0.010836449, -0.016064642, -0.015869975, -0.016333468, -0.03778389, 0.019318359, 0.015462102, -0.008815623, 0.012820196, 0.015536261, 0.03190681, -0.006113463, -0.031647254, 0.03123938, -0.00691067, -0.016602293, -0.018215246, 0.0041019064, 0.004027748, 0.0060439394, -0.0046789544, -0.0049176533, -0.0023267313, 0.029144395, -0.018530421, 0.013089022, -0.01440534, 0.008834163, 0.014655625, -0.00964064, 0.026548838, -0.0007242067, -0.03010846, -0.023693725, -0.01319099, -0.022525724, 0.006345209, -0.026789853, 0.014433149, 0.03064611, -0.07000587, -0.01622223, -0.008908321, -0.047202054, -0.0023684455, -0.008537528, 0.0044796527, -0.012421593, -0.06055063, 0.001060818, -0.0056685107, -0.010512005, -0.023211693, 0.021969534, 0.002727652, 0.031091062, 0.004862034, 0.0034576524, 0.012912895, 0.0019513025, -0.04019405, 0.043901987, 0.006776257, -0.036986683, -0.020931311, 0.041862622, -0.0075132097, 0.01620369]": "ible, we\npropose to add a small perturbation to the picture, so thatit has the same functionality as the trigger. The term “same\nfunctionality” can be understood from two perspectives. FromAlgorithm 1 Computable Trigger Generate Algorithm\nInput: Model G, target_value, input x,M a s k M\nOutput: trigger\n1:// Select from layer (1)to layer (L −1) of the model\n2:SubNet _G=G[:−1]\n3:// Initialize the trigger according to the mask\n4:trigger =Random _Init(M)\n5:// Patch the trigger on input data\n6:T(x)=(1−M)⊙x+M⊙trigger\n7:// Compute activation value and deﬁne loss function\n8:value=SubNet _G(T(x))\n9:lossdef=MSE(value,target _value)\n10:// The trigger’s value is calculated based on the gradient\n11:repeat\n12: grad=∂loss\n∂trigger\n13: grad=grad⊙M\n14: trigger =trigger −lr·grad\n15:until i>epochs orloss<threshold\n16:return trigger\nthe neural network’s viewpoint, it refers to the similarity in\nactivation values at the penultimate layer of the model. From\nthe practical application perspective, it denotes t"}
{"[-0.04449264, 0.13825023, -0.011435196, 0.03737088, 0.04809023, -0.010930432, -0.08597505, -0.038435474, -0.03762785, 0.0073328423, -0.03441572, 0.046842087, 0.009581336, -0.04056466, 0.021879219, -0.09280313, -0.010765237, 0.01294031, -0.043134365, 0.07738489, 0.047576286, 0.025660358, 0.03426888, 0.10352248, -0.047319315, -0.06277427, -0.046878796, 0.065123715, 0.029459855, 0.06842762, -0.025017932, 0.110717654, 0.07782541, -0.03177259, 0.047245897, 0.0033543853, -0.049778894, -0.05238531, 0.018712973, -0.057561435, -0.01475746, 0.0026408327, 0.004329497, 0.02428373, 0.027349023, -0.019181026, 0.02064943, -0.0439787, -0.006910676, 0.084506646, -0.011820652, 0.012040912, 0.03784811, 0.009016918, -0.0094895605, 0.020796271, -0.016143266, -0.009149992, 0.03010228, 0.022136189, -0.014803347, 0.021787444, -0.026412915, 0.0042285444, 0.03199285, 0.034140393, -0.007727476, -0.04933837, 0.032543503, 0.0071676467, 0.018070545, -0.023586238, -0.020667786, 0.0030905313, 0.03751772, 0.03447078, 0.029459855, -0.0073282532, 0.042620424, 0.023769788, 0.0029161584, 0.0063646133, 0.011370953, 0.010590863, -0.05954378, -0.034140393, -0.0073511973, -0.018905701, -0.004496987, -0.015308111, 0.028799072, -0.016409414, -0.039903875, -0.015097028, 0.012481433, -0.03199285, -0.04177609, -0.02991873, -0.015041963, 0.04478632, -0.021420343, -0.009920904, -0.019548127, -0.016950889, 0.016556254, -0.060461532, 0.026578112, -0.014638152, -0.054330945, -0.032158047, 0.012499789, -0.02810158, 0.02977189, 0.003611356, 0.045226842, 0.0017139027, 0.013417541, -0.005465216, 0.011361775, -0.016804047, -0.01879557, -0.027275603, 0.04511671, -0.02465083, -0.01697842, 0.04005072, 0.010976319, 0.0035884122, 0.012316238, 0.033277705, 0.046254724, -0.018116433, 0.0030423494, 0.022044415, 0.0010978613, 0.023017231, -0.009283066, -0.00593327, 0.034323942, 0.015409064, -0.04607117, -0.03006557, 0.05322964, 0.005052227, 0.018997476, 0.025752135, 0.01494101, 0.016583787, 0.015620147, 0.015959715, -0.03685694, 0.016436946, 0.014399536, 0.005171535, -0.0121326875, 0.0006229245, -0.018979121, -0.018199032, -0.024338795, 0.005749719, -0.0596172, -0.019694967, 0.032671988, -0.006965741, -0.011710522, -0.0527157, 0.0024871093, 0.016189154, -0.035535377, 0.0025261135, 0.010866189, -0.007745831, 0.043464758, 0.02465083, 0.007952325, 0.0053183753, 0.013445074, 0.0147758145, 0.013894772, -0.022448225, -0.03814179, 0.014335293, -0.014986898, -0.0038958592, -0.0075760465, -0.012389658, 0.003822439, 0.05139414, 0.009829129, -0.029643405, -0.010315537, -0.009590513, -0.039536774, 0.014316939, 0.014436246, 0.0118940715, -0.003533347, 0.004923742, 0.024687542, -0.018786393, -0.050256126, 0.01846518, -0.008149642, -0.015289756, -0.018777216, -0.007947736, 0.0005601158, 0.0035654684, -0.011637101, 0.003611356, -0.002209489, 0.02606417, -0.00704375, 0.02828513, -0.017877817, 0.0066674715, 0.024705896, -0.0050476384, 0.026981922, -0.014069146, -0.0370772, -0.038031664, -0.011820652, -0.007741242, -0.0064839213, -0.033681516, -0.014803347, 0.022796972, -0.06497687, 0.00741544, 0.005648766, -0.048053518, -0.008498387, 0.01712526, 0.007296132, -0.006506865, -0.03441572, -0.0055753463, 0.0062682494, -0.00066192896, -0.021493763, 0.02432044, 0.017382232, 0.027459154, 0.013968192, 0.008434145, 0.019896874, 0.00046575937, -0.045226842, 0.012288705, 0.007484271, -0.022558356, -0.02610088, 0.034984723, -0.023751434, 0.009856662]": "shold\n16:return trigger\nthe neural network’s viewpoint, it refers to the similarity in\nactivation values at the penultimate layer of the model. From\nthe practical application perspective, it denotes that when an\nimage is patched with this perturbation, it becomes poisoneddata that can be injected into the backdoor. However, the\npoisoned data does not look any different from normal data,\nand in order not to change the label of the poisoned data,we decided to add perturbations only to the target label. That\nis, if Ais the target label speciﬁed by the attacker, then the\nattacker will only add perturbation to the picture labeled as A,\nso there is no need to change the label of the poisoned data\nto the label of the target label. Unlike a computable trigger,which sets a loss function based on the activation value, the\ninvisible trigger enhances the loss function. Here we denote\nthe loss function as the mean square error of the activationvalues of two poisoned pictures (one picture attached w"}
{"[-0.07105113, 0.09985169, -0.0049569495, 0.0395825, 0.054750305, -0.03664031, -0.08106554, -0.061365664, -0.029129501, 0.0011050343, -0.032126516, 0.02863609, 0.018804427, -0.049304515, 0.012874363, -0.09473484, -0.0018708487, 0.009584959, -0.051972587, 0.07850712, 0.03713372, 0.015505886, 0.021417676, 0.12302372, -0.036457565, -0.07945739, -0.049706552, 0.07945739, -0.0010473555, 0.023427868, -0.010452996, 0.08377016, 0.060890526, -0.029330522, 0.04327394, 0.024816727, -0.030682832, -0.08508592, 0.008196099, -0.067944475, -0.029750833, 0.0188958, -0.013139343, 0.003531541, 0.026351783, -0.008538745, 0.0015521876, -0.049998943, 0.0077255312, 0.050985765, -0.019645054, 0.006199613, 0.058697592, -0.022386223, -0.016191179, 0.009009313, -0.028307151, -0.003494992, 0.038266737, 0.036512386, -0.024524337, 0.009013881, -0.02523704, -0.019718152, 0.00013320374, 0.03240063, -0.017269373, -0.03812054, 0.033149883, -0.014418555, 0.05983061, -0.01790898, -0.010197153, -0.00014105605, 0.034502197, 0.035233174, -0.0017280794, -0.01143068, 0.033880863, 0.009032155, 0.018877525, 0.013276401, 0.01337691, 0.022879634, -0.044845544, -0.042689156, -0.027923387, -0.010124056, -0.022276577, -0.027265506, 0.02507257, 0.0140622035, -0.031633105, 0.020412581, 0.031852398, -0.027886838, -0.039363205, -0.041336846, -0.0031500615, 0.03643929, -0.027758917, 0.010681426, -0.025127394, -0.00048541554, -0.0029056405, -0.054384816, 0.027411701, -0.018265331, -0.014848005, -0.04053277, -0.0009976717, -0.01737902, 0.04250641, -0.0532518, 0.037334736, 0.0026406606, 0.011787032, -0.0016858197, 0.0049797925, -0.01122966, 0.006875769, -0.018347565, 0.030024951, -0.028745739, -0.023610612, 0.040642418, 0.00085204706, 0.025511157, 0.012125109, 0.03801089, 0.037151992, -0.022367949, 0.014190124, 0.035927605, 0.006048849, 0.022769988, -0.016072394, 0.018256193, 0.009639782, 0.0045823227, -0.015999297, -0.021655245, 0.059245825, -0.00558285, 0.029750833, 0.000659023, 0.0048473026, 0.026150763, 0.020723246, 0.015505886, -0.010772799, 0.023976102, 0.027302055, -0.017890705, -0.01955368, -0.0043356176, -0.021984184, -0.027228957, -0.032126516, 0.01384291, -0.097804956, -0.012737304, 0.013121068, -0.024542611, -0.0058386927, -0.058843788, -0.00388104, 0.02764927, -0.013185029, 0.01245405, 0.009324547, -0.0034995605, 0.021911087, 0.037298188, 0.0042191176, 0.021015638, 0.03234581, 0.014592162, 0.02127148, -0.00075724826, -0.014318045, 0.0197547, 0.011576875, -0.010955543, 0.020558776, -0.0022100685, -0.0012426638, 0.03071938, 0.0070767878, -0.022769988, 0.0009833948, -0.006820945, -0.041775435, 0.026260411, 0.012682481, -0.009260586, 0.012326129, 0.00047285185, 0.013879458, -0.013605341, -0.02679037, 0.012792127, 0.0019336671, -0.015314004, -0.008278334, 0.014391144, 0.021289755, 0.024944648, -0.01255456, 0.0044087153, 0.015569847, 0.004655421, -0.018557722, 0.02335477, -0.0064737303, 0.013221578, 0.0071864347, -0.0032300123, 0.02695484, -0.014729221, -0.041702338, -0.016273413, -0.012444912, -0.014921103, 0.004655421, -0.030682832, 0.004851871, 0.026333509, -0.07269584, 0.0014219821, 0.0051259883, -0.02021156, 0.0020981373, 0.0068300823, 0.013678439, -0.032089967, -0.03369812, 0.0015967316, 0.0021872253, -0.01096468, -0.014884554, 0.04060587, -0.0016424179, 0.00047456508, 0.006743279, -0.008790019, 0.029878754, 0.00052167894, -0.06597083, 0.03954595, 0.0163191, -0.036622033, -0.0141078895, 0.052009135, -0.012143384, 0.010535231]": "e activation value, the\ninvisible trigger enhances the loss function. Here we denote\nthe loss function as the mean square error of the activationvalues of two poisoned pictures (one picture attached with a\ntraditional trigger, another one with an invisible trigger). Its\nformal deﬁnition is as follows:\nT(x)=/parenleftbig\nPoison G,x,t\n∗/parenrightbig\n(4)\n=arg min MSE(sub_G (p),sub_G (˜s))\nst.||p−x||∞</epsilon1\nwhere sub_G (·)is the activation value of the deep model at\nthe penultimate layer, xis any picture of the target class, and\npis its image after adding the perturbation. Attackers select\nan image from outside the target class and patch the triggert\n∗to it as ˜s. The speciﬁc generation process is illustrated in\nFigure 5. When ˜sand pare inputted into the model, they\nproduce activation values A1 and A2, respectively. Following\nthe approach presented in previous work [26],w ee m p l o yt h e\nstandard Projected Gradient Descent (PGD) algorithm [48] to\noptimize Eq. (4). This process is i"}
{"[-0.0783042, 0.11522218, 0.00855651, 0.048015345, 0.07335983, -0.035929102, -0.042265225, -0.05372884, -0.026003733, 0.029483106, -0.035965726, 0.032339856, -0.010547994, -0.033713292, 0.009375994, -0.11112018, 0.02825617, 0.0211143, -0.053985216, 0.035214916, 0.026443234, 0.027871607, 0.02030855, 0.091489196, -0.02252436, -0.07764495, -0.0100444, 0.0825527, 0.017927926, 0.02450211, 0.010392337, 0.09031719, 0.05570659, -0.007274636, 0.03083823, 0.0382731, -0.0070274174, -0.066950455, 0.044535972, -0.06673071, 0.008739635, 0.0027926546, -0.020986112, 0.017589144, 0.0825527, -0.022359548, 0.019539425, -0.027358858, -0.012443336, 0.066913836, -0.008698432, -0.0008601147, 0.04039735, 0.016609427, -0.0038570678, 0.023275172, -0.046074223, 0.0070548863, 0.058783088, 0.040067725, -0.002252436, -0.00030129767, -0.020180363, -0.029721169, 0.05482759, 0.014146397, -0.005333512, -0.033951353, 0.0848967, 0.03981135, 0.022652548, -0.03525154, -0.04893097, -0.041422848, 0.02767017, 0.02589386, 0.003861646, -0.04614747, 0.008931916, 0.006404793, 0.038968977, -0.016984833, 0.008858667, 0.031845417, -0.044499345, -0.029409856, -0.0071098236, 0.0032092636, -0.0036121383, 0.007915573, 0.026296733, -0.006519246, -0.035562854, 0.0028224122, 0.004848231, 0.015666334, -0.012095398, -0.034171104, -0.00070960895, 0.0701002, -0.01472324, 0.043547098, -0.024850046, 0.0051824343, 0.0005024489, -0.07101583, 0.04373022, -0.037980102, -0.018083582, -0.031808794, -0.010319088, -0.025124734, 0.038529474, 0.00075195654, 0.03171723, -0.025436046, 0.021828486, -0.02179186, -0.011802399, 0.011710837, 0.029519731, -0.0059011993, 0.04482897, -0.03230323, -0.027248982, 0.028860481, -0.004843653, 0.016160771, 0.013249085, 0.026662983, 0.009568275, -0.013807616, -0.016224865, 0.03688135, 0.00015179336, 0.01942955, -0.010493056, 0.008153635, 0.028640732, 0.010236681, -0.020052174, -0.01608752, 0.02642492, -0.022615923, 0.00563109, 0.0023027954, 0.009650681, 0.031515792, 0.02545436, 0.020271925, -0.0063498556, 0.015931865, 0.0082039945, -0.020070488, -0.0187703, -0.008583979, -0.016169928, -0.017076395, -0.013743523, -0.014970459, -0.08914519, 0.0056951838, 0.02810967, -0.032944165, 0.024630297, -0.062665336, 0.028988669, 0.020381799, -0.015876928, 0.0056539807, 0.009815494, 0.014009054, 0.0136519605, 0.033823166, -0.012095398, 0.0215538, 0.03213842, 0.016316427, 0.027908232, 0.0042897006, -0.024831735, 0.0047292, -0.031460855, 0.00046925753, -0.047722343, 0.0049809967, -0.005818793, 0.018468145, -0.0010066146, 0.0009528217, -0.017085552, -0.012864524, -0.03598404, 0.002845303, 0.01538249, 0.009041791, 0.0034290135, 0.008185682, 0.013890022, -0.028787231, -0.03222998, 0.0015954756, -0.007846901, -0.03303573, -0.012113711, -0.014860584, 0.0014707217, -0.013770991, 0.0039486303, 0.017067239, -0.014512647, 0.00060202304, -0.021224175, 0.028952044, -0.017433489, -0.004720044, 0.022286298, 0.00794762, 0.017396864, -0.014540116, -0.034244355, -0.011729149, -0.010786056, -0.024355609, 0.000103222344, -0.010593775, 0.0009911634, 0.022286298, -0.05966209, -0.013111741, 0.013505461, -0.056622215, 0.009714775, -0.0001503627, -0.0025706156, -0.035434667, -0.035855852, 0.011426993, 0.004646794, 0.004378974, -0.019466175, 8.083247e-05, 0.005914934, 0.032046854, 0.027487045, -0.0038021305, 0.02620517, 0.011051587, -0.035599478, 0.046623595, 0.0114361495, -0.019759174, -0.012672242, 0.059881836, -0.020290237, 0.029464794]": "lues A1 and A2, respectively. Following\nthe approach presented in previous work [26],w ee m p l o yt h e\nstandard Projected Gradient Descent (PGD) algorithm [48] to\noptimize Eq. (4). This process is iteratively repeated until the\nvalue of the loss function is below the threshold set by the\nattacker. At this stage, the effect of the trigger is distractedinto an imperceptible perturbation. In most experiments in this\npaper, we use AlexNet as the test model. /epsilon1is used to control\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6752 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nFig. 5. Generation of invisible triggers. Where š is the picture with the\ntrigger attached and p is the poisoned picture with the perturbation added.Using the mean squared error of their activations as a loss function, a decrease\nin the loss value means that the activations of š and p are getti"}
{"[-0.0581543, 0.09735243, 0.006203921, 0.06256271, 0.050733473, -0.032052826, -0.07766152, -0.030969093, -0.005046713, -0.014731443, -0.08287814, 0.054443885, -0.017587727, -0.04801495, 0.005662054, -0.115794286, -0.0013064512, 0.031079303, -0.049337476, 0.043312646, 0.041622754, 0.011269002, 0.0006911104, 0.11623512, -0.066860914, -0.06443629, -0.046472006, 0.09066634, 0.020848114, 0.039345074, 0.0014155135, 0.119761854, 0.07575121, -0.010754688, 0.048859898, -0.0228319, -0.02110527, -0.06968965, -0.0008489637, -0.07611857, -0.012242527, -0.0014132174, -0.0010182972, 0.024283001, 0.05051305, -0.022574741, 0.009271441, -0.046361797, -0.014694706, 0.065244496, -0.006828446, 0.0015153915, 0.06028503, 0.032071196, -0.010047506, 0.026266787, -0.018092856, -0.005322239, 0.031869143, 0.0004942243, 0.0019987095, 0.010249557, -0.01419876, -0.04132886, 0.026285155, 0.0020825153, 0.00029174157, -0.042761594, 0.036277555, 0.031189512, 0.012361921, -0.031483408, 0.0036759726, -0.011976185, 0.036130607, 0.04419433, -0.005377344, -0.02020522, 0.06267292, 0.012389474, 0.029499622, 0.013372182, 0.033816192, 0.021491008, -0.03813276, -0.002302936, -0.028342415, -0.015199836, -0.013785471, 0.002546317, 0.032897774, -0.015181468, -0.033320244, 0.0047206744, 0.020921588, -0.03372435, -0.05679504, -0.030473147, -0.0013787767, 0.05403978, -0.030307831, 0.017394857, -0.04963137, 0.0024452908, 0.013666077, -0.041181915, 0.023640107, 0.005767672, -0.021546112, -0.026652522, 0.0119302645, -0.028709782, 0.043680012, -0.033540666, 0.027975047, 0.010580189, -0.0012100172, -0.012582342, 0.0064013815, 0.0010504419, -0.007935141, -0.037765395, 0.041365597, -0.0335774, -0.0024452908, 0.020388905, -0.01367526, 0.02180327, 0.009395428, 0.0349734, 0.046141375, -0.021784902, -0.00942298, 0.02929757, 0.016099887, 0.017982647, -0.015153916, -0.0053176465, 0.03146504, 0.012922157, -0.03350393, 0.010644478, 0.043973908, -0.0017404042, 0.026744364, -0.016898911, 0.026156576, 0.022868635, 0.01282113, 0.012113948, -0.028654676, 0.02079301, 0.029095517, -0.015135547, -0.0028677636, -0.014905943, 0.0012456059, -0.025495315, -0.01770712, -0.019672537, -0.06939575, -0.016384598, 0.011976185, -0.0023465608, 0.0016956313, -0.045700535, -0.008251996, -0.012784394, -0.021601217, 0.018653093, 0.0039147614, 0.012811947, 0.032512035, 0.034348875, 0.01687136, 0.01038732, 0.013307893, 0.019911326, 0.009918926, -0.025495315, -0.024007475, 0.0147681795, -0.005854922, 0.0067963013, -0.007958102, 0.002013634, -0.004904358, 0.0392716, 0.0083851665, -0.01373955, -0.014694706, -0.021858376, -0.02340132, 0.02329111, 0.029756779, -0.004748227, -0.0005473204, 0.0015016153, 0.018460223, -0.017808147, -0.02397074, 0.016338676, -0.015760072, -0.021142008, -0.0228319, 0.006874367, -0.0020331503, 0.02760768, 0.007067235, 0.018092856, -0.0025669814, 0.01849696, -0.0052763177, 0.028801624, 0.00081509695, -0.0033958547, 0.04562706, -0.005533475, 0.017734673, 0.0029228688, -0.044892326, -0.0064059733, -0.01163637, -0.030160883, -0.0085458895, -0.02136243, -0.009298993, 0.005772264, -0.06131366, 0.014097733, 0.020884851, -0.025476946, 0.011011845, -0.009744427, 0.001343188, -0.017734673, -0.04463517, 0.0061809607, 0.013684445, 0.00017076856, -0.02101343, 0.034330506, 0.015025337, 0.020297062, -0.006502407, 0.004424484, 0.031942617, -0.0169632, -0.048419055, 0.023640107, 0.006865183, -0.03655308, -0.025109578, 0.052166205, -0.01674278, 0.026670892]": "p is the poisoned picture with the perturbation added.Using the mean squared error of their activations as a loss function, a decrease\nin the loss value means that the activations of š and p are getting closer, so\nthe function of the trigger is distracted over the perturbation.\nthe order of magnitude of perturbations, and our experiments\nshow that our method can use a lower /epsilon1than previous methods.\nV. E XPERIMENT\nA. Experiment Setup\nData Sets and Models: We conducted our experiments\non the CIFAR-10, CIFAR-100, GTSRB and DTD. We used\n4%, 10%, 20%, and 20% of each class as poisoning data,\nrespectively. As mentioned in Section IV-C , since only the\npoisoned data of one class is added to the training set,\nfor a ten-class task, the poisoning rate should be multiplied\nby 0.1. Meanwhile, in order to reduce the consumption oftraining data, the poisoned data generation process will be\nrepeated twice. That is, we will generate two batches of\nsimilar poisoned data. In order to compare with"}
{"[-0.027943637, 0.11907381, -0.025621144, 0.03362084, 0.032920405, -0.053896565, -0.049841423, -0.016828852, -0.043500647, -0.00083694974, -0.075204514, 0.07044893, -0.0054882704, -0.05220078, 0.007262396, -0.08560043, -0.0011543339, 0.014534009, -0.011584813, 0.07314007, 0.062301777, 0.0072301393, 0.0147736315, 0.11686191, -0.02893899, -0.041104425, -0.06189626, 0.044680327, 0.00461964, 0.031077158, -0.012515653, 0.10042014, 0.087591134, -0.028846828, 0.027243203, -0.006658733, -0.028680936, -0.07280829, -0.007280829, -0.04394303, -0.02409125, -0.008861414, -0.008902887, 0.011363623, 0.049140986, -0.009621753, 0.029270776, -0.041251887, -0.01955686, 0.068937466, 0.04143621, 0.029270776, 0.06602514, 0.042284105, -0.006783152, 0.036570035, -0.020644376, -0.0060043796, 0.042431563, 0.0033454949, -0.022063676, 0.017787341, -0.023372382, 0.013372763, 0.022284865, -0.010506513, 0.022579785, -0.040256534, 0.026284713, -0.010331404, 0.015492498, -0.020367889, -0.015289741, -0.008704738, 0.042284105, 0.025989793, 0.020386321, -0.021289513, 0.06654125, 0.014414198, 0.028994288, 0.010285323, 0.014856577, 0.030100238, -0.06761033, -0.009575672, -0.019501561, -0.019943941, -0.013538655, 0.028146394, 0.028220125, 0.00833148, -0.04515957, 0.027095743, -0.000847894, -0.04486465, -0.017612232, -0.012395841, -0.008709346, 0.03599863, -0.020257294, 0.04062518, -0.045823142, -0.030782238, -0.0057278927, -0.027906772, 0.05282748, -0.022082109, -0.015013253, -0.044016756, -0.008345304, -0.07579435, 0.027335364, -0.022008378, 0.025842335, 0.015326605, -0.0062624346, -0.018386398, 0.01896702, 0.0025528981, 0.012589383, -0.05301181, 0.056071598, -0.021989947, -0.006820017, 0.05183213, -0.017317314, -0.0023017556, 0.027335364, 0.027353797, 0.0538597, -0.01845091, -0.020920863, 0.011649326, -0.005981339, 0.019501561, -0.013308249, 0.004317808, 0.011741488, 0.03175916, -0.03703085, -0.01681042, 0.047629524, -0.0010276106, 0.0036035494, -0.012386626, 0.006815409, 0.022045244, 0.008082641, 0.01830345, -0.057693657, 0.012441923, 0.024128113, -0.011944246, -0.0016485548, -0.011170082, 0.016819635, -0.017123772, -0.029620992, -0.02313276, -0.049657095, -0.008469724, 0.033270624, -0.022727245, 0.004518261, -0.05927885, 0.008750819, -0.0038823406, -0.01656158, 0.025252495, 0.012119355, 0.001579433, 0.037067715, 0.026118822, 0.03249646, -0.0029215477, 0.0330863, 0.021731893, 0.009935106, -0.025897631, -0.012921168, 0.025971362, -0.03384203, 0.006709422, -0.015013253, -0.00811029, -0.0018236632, 0.056034733, 0.00747437, -0.00906878, 0.00517031, -0.033436514, -0.031722296, 0.03236743, 0.0020241165, -0.010589459, -0.011400487, -0.014377333, 0.024902279, -0.010451215, -0.026487472, 0.004711802, -0.009548023, 0.011151649, 0.0075941808, 0.0002200377, 0.005695636, 0.014709118, 0.0070365984, -0.005050499, 0.011925814, 0.016358824, -0.017953234, 0.02707731, -0.005497487, -0.008372953, 0.012672328, -0.016644528, 0.021768756, -0.0053039454, -0.024625791, -0.024939142, -0.014303603, -0.009289969, -0.009750781, -0.003780962, -0.013068627, 0.008488156, -0.06598827, -0.0013156182, 0.013557088, -0.029731587, -0.009363699, -0.0049491203, -0.0018985452, -0.0060043796, -0.03362084, 0.016229797, 0.011824435, -0.018202072, -0.021492269, 0.028680936, 0.0074236807, 0.020644376, 0.004128875, -0.0021773365, 0.0117967855, 0.009990403, -0.017833423, 0.035150737, 0.0010736919, -0.014736766, -0.012976465, 0.024367737, -0.032164674, -0.007091896]": "n order to reduce the consumption oftraining data, the poisoned data generation process will be\nrepeated twice. That is, we will generate two batches of\nsimilar poisoned data. In order to compare with the previousmethods, we use the AlexNet model in the main experimental\npart, and then ResNet-18 and ResNet-34 in the later ablation\nexperiments. These models are all pre-trained on the ImageNetdataset.\nBaseline Selection: We compare this with previous back-\ndoor attack methods, including Trojan [14], which uses reverse\nengineering to generate triggers, and Hidden Trigger [26],\nwhich uses hidden triggers. The reason we chose these two\nbaselines both of them use hidden and computable triggers,\nwhich is comparable to our setting. In addition, we provide\nanother baseline for reference with models trained on benigndatasets (called standard training). At the same time, we\nselected STRIP [47], Neural Cleanse [45], SentiNet [49] and\nNAD [50] to evaluate the robustness of our method.\nAttack Setup:"}
{"[-0.066660665, 0.13052541, -0.031858794, 0.02295599, 0.030810323, -0.021723578, -0.044624384, -0.012020624, -0.0417181, 0.046463806, -0.06552022, 0.079315886, -0.01868853, -0.03388216, -0.012085005, -0.075122006, 0.029872218, 0.011128505, 0.0019704811, 0.07637282, 0.025733517, 0.006529949, 0.024960961, 0.11522141, -0.043152846, -0.019608242, -0.070449874, 0.081376046, 0.03128857, 0.034121282, -0.027517758, 0.11581003, 0.07548989, -0.026818777, 0.039474003, -0.016260494, -0.008465941, -0.06467409, 0.03244741, -0.060774513, -0.0044238106, 0.007265718, -0.0035385885, 0.030773535, 0.051209517, -0.0120942015, 0.027904036, -0.047383517, -0.018495392, 0.04190204, 0.026726807, 0.02779367, 0.0515774, 0.03575837, 0.0047227168, 0.02678199, -0.028235132, -0.047604248, 0.06728607, 0.0014152055, -0.021815548, 0.046022344, -0.018044733, -0.026800383, 0.01604896, 0.006943819, -0.002920083, -0.028694987, 0.04168131, -0.015166037, 0.021466058, -0.02282723, -0.009068352, -0.012995519, 0.03715633, 0.013694499, 0.033440698, -0.029853825, 0.0665503, 0.016582392, 0.024703441, 0.0059597283, 0.018431012, 0.050620902, -0.050363384, -0.020288829, -0.0032626754, -0.030497622, -0.0028419076, -0.0032488797, 0.008631489, 0.0035454864, -0.033072814, -0.014531436, 0.020656712, -0.02678199, -0.03075514, -0.003600669, -0.026414104, 0.044146135, -0.022551317, 0.022293799, -0.04190204, -0.013124278, -0.014283114, -0.01916678, 0.040614445, -0.005932137, -0.01111011, -0.045396943, -0.0028947908, -0.05709567, 0.012554057, -0.005853961, 0.0069392207, 0.012646028, 0.0034374204, -0.011137702, 0.010595072, 0.011054928, 0.0082728015, -0.03910612, 0.05823611, -0.010135217, 0.010595072, 0.05687494, -0.016030565, 0.00862689, 0.006369, 0.019369116, 0.0554034, 0.0022647886, -0.0029131852, 0.017207796, -0.020656712, 0.040136196, -0.0002362508, -0.015754651, 0.019920943, 0.016858306, -0.029688276, -0.004593957, 0.06231963, 0.0067644753, 0.013685302, -0.029688276, 0.02939397, 0.034250043, 0.018026339, 0.020730289, -0.057389975, 0.016380055, 0.025715124, 0.0043985187, -0.010806606, 0.00083463785, 0.022146644, -0.028143162, -0.023930885, -0.016021369, -0.05205565, -0.02060153, 0.03888539, -0.027904036, -0.0024717236, -0.06772753, -0.011569967, -0.013225446, -0.008930395, 0.009868501, -0.0028671995, -0.011947048, 0.031251784, 0.02808798, 0.00040812182, 0.013446177, 0.022238616, 0.0027844254, 0.009247696, -0.026285345, -0.018697727, 0.028639805, -0.01461421, 0.001630188, -0.015212023, -0.007238127, 0.010972154, 0.041019116, 0.0016060456, -0.026598046, -0.011330841, -0.015911004, -0.03951079, 0.016665166, 0.010043246, -0.011560769, 0.0040927147, 0.002549899, 0.017345753, -0.016665166, -0.02744418, -0.005849363, -0.019792184, -0.013768076, -0.012250553, -0.00061505684, 0.003251179, 0.018725319, 0.005674618, 8.773182e-05, -0.0010145564, -0.011091717, -0.009279885, 0.0017095131, -0.019571453, -0.00041703152, 0.0075278357, 0.007629004, 0.0035293915, -0.020987809, -0.019277146, -0.018808093, 0.0012531064, 0.0257887, -0.012857562, 0.0055044712, -0.0066954973, 0.01404399, -0.07938947, 0.0005897648, 0.002311924, -0.040651232, -0.007955502, 0.00958339, 0.010622663, -0.020325616, -0.029412363, 0.0124436915, 0.0036282605, -0.008167035, -0.015202825, 0.042306714, 0.012931138, 0.0044307085, -0.0024878187, 0.008240612, 0.030092949, 0.006139072, -0.024537893, 0.020619923, -0.0029890612, -0.013299023, -0.03528012, 0.031343754, -0.009905289, -0.009555799]": " trained on benigndatasets (called standard training). At the same time, we\nselected STRIP [47], Neural Cleanse [45], SentiNet [49] and\nNAD [50] to evaluate the robustness of our method.\nAttack Setup: For each attack method, we crop the size of\nthe picture to 3 ×224×224 and set the trigger to a 30 ×30 sizecolor matrix, ﬁxed to the bottom right corner of the image.\nWhen generating the computable trigger, we only iterated 20rounds, and the learning rate was ﬁxed at 1.0; In generating the\nhidden trigger, we performed 400 iterations with a batch size\nof 100, the learning rate was initially 0.01, and the learningrate decayed to 1/2 of the original after every 200 rounds. To\nensure the stealthiness of perturbations, we initially set /epsilon1to\n16. In subsequent experiments, we will test different ones todemonstrate the superiority of our proposed method. In the\nmodel ﬁne-tuning phase, we set the learning rate to 0.001\nand use the SGD algorithm to ﬁne-tune the model. All theexperiments were "}
{"[-0.05979229, 0.1155221, -0.005124262, 0.0053735506, 0.018632002, -0.016268378, -0.070428595, -0.051408812, -0.03899979, 0.025058104, -0.07190586, 0.07593141, -0.036322247, -0.032610618, 0.0028783581, -0.11175508, 0.014643387, -0.0015972925, -0.025889065, 0.045684412, 0.0172286, 0.040698644, 0.04476112, 0.091516554, -0.02431947, -0.05820423, -0.04830656, 0.07478653, 0.031170286, 0.026110655, -0.013692398, 0.11626074, 0.08405636, -0.035620548, 0.035103504, -0.015465115, -0.01713627, -0.06023547, 0.04221284, -0.055138905, -0.0044664177, 0.011051787, 0.01335078, 0.00055368576, 0.052775282, 0.031668864, 0.0058213463, -0.016933147, 0.005548976, 0.03309073, 0.010377785, 0.022657547, 0.05750253, 0.005941374, -0.0032061262, 0.038630474, -0.018908989, -0.015021936, 0.060567856, 0.031170286, -0.026941616, 0.014726483, 0.0029383719, 0.0076125297, 0.026258381, 0.025076568, -0.016776187, -0.05067018, 0.05813037, -0.0021997395, 0.0045379726, -0.042065114, -0.03811343, -0.011227212, 0.038002636, 0.04199125, 0.038704336, -0.014883442, 0.041437276, -0.008383477, 0.035971396, -0.00096772384, 0.02387629, 0.04284068, -0.06222978, -0.026369175, 2.5715082e-05, -0.031391874, 0.009786879, -0.0021454962, 0.028566606, -0.0022712946, -0.057539463, -0.0019943074, 0.04247136, -0.013230752, -0.020626308, -0.044650327, -0.028972855, 0.045167368, -0.034604926, 0.029711487, -0.021623462, -0.014744949, -0.013369245, -0.023229988, 0.029175978, -0.023802428, -0.033810895, -0.03706088, 0.015437417, -0.049340643, 0.00455413, 0.014283303, 0.013821659, -0.007423255, 0.014467961, -0.0019031324, 0.030320859, 0.004256369, 0.055508222, -0.042434428, 0.05085484, -0.015123498, -0.017431725, 0.0265723, -0.025538214, 0.0007484423, 0.02234363, 0.0015892137, 0.038519677, -0.024042483, -0.010183894, 0.023248455, 0.0030537832, 0.027329398, 0.0076125297, -0.018031863, 0.010636306, 0.01828115, -0.049820755, -0.004094793, 0.033201527, -0.0215496, 0.018013397, -0.032758344, 0.03244443, 0.0048934394, -0.00091925106, 0.005018084, -0.045758277, 0.0015753644, 0.016896216, 0.018299617, 0.008438875, -0.0074555706, 0.009629919, -0.028622005, -0.030985627, -0.002409788, -0.05428948, -0.01843811, 0.038630474, -0.010885594, -0.0034854214, -0.06736327, 0.0074463375, -0.019980006, -0.004644151, 0.021752723, -0.013692398, 0.0067815683, 0.027366329, 0.03922138, 0.006439951, 0.010904061, 0.014274071, 0.00043423506, -0.009537591, -0.039184447, -0.005276605, 0.020275459, -0.016176049, -0.0072016655, 0.000104880026, 0.0062275943, -0.007409406, 0.0430992, 0.0033653937, 0.0030953314, -0.010737868, -0.02635071, -0.031188753, 0.01678542, 0.014892675, -0.024559526, -0.001337617, -0.0046372265, 0.028529676, 0.006449184, -0.024965774, 0.008475807, -0.011070252, -0.006947761, -0.017376326, 0.0069569936, 0.00940833, 0.017773341, 0.023082262, -0.007317077, -0.00042817596, 0.0075571323, -0.008378861, 0.057133213, 0.002131647, 0.0050734812, 0.035805203, 0.008983616, 0.024079416, -0.033330787, -0.048343487, -0.007940298, -0.0063153068, 0.009648385, 0.012759875, -0.015141964, 0.00078248867, 0.009565289, -0.041658867, 3.999723e-05, -0.0021593457, -0.05347698, -0.018539673, -0.0038339635, 0.010682471, -0.012852203, -0.027606385, 0.03141034, 0.01986921, 0.0057105515, -0.0025967543, 0.035454355, 0.004360239, 0.01385859, 0.021568066, 0.016333008, 0.03327539, 0.012058173, -0.021734258, 0.032536756, 0.009348316, -0.016397638, -0.024744185, 0.050116207, -0.006707705, -0.002896824]": "nt ones todemonstrate the superiority of our proposed method. In the\nmodel ﬁne-tuning phase, we set the learning rate to 0.001\nand use the SGD algorithm to ﬁne-tune the model. All theexperiments were implemented with PyTorch and performed\non a server with 2 Intel Xeon CPUs, 1 NVidia Tesla V100\nGPU, 376GB RAM, and Ubuntu 18.04LTS OS.\nEvaluation Metric: We use Attack Success Rate (ASR)\nand Benign Accuracy (ACC) to evaluate the effectiveness ofdifferent attack methods. Speciﬁcally, ASR refers to the ratio\nof the amount of poisoned data misclassiﬁed by the model\ninto the label speciﬁed by the attacker to the amount of allpoisoned data. ACC is deﬁned as the accuracy of the benign\nsample on the test set. The higher the ASR and ACC, the\nbetter the attack method.\nB. Main Result\nWe evaluate the task of 10-class image classiﬁcation. We\nﬁnd that even for the same dataset, different labels have a great\nimpact on Hidden Trigger. So, we repeated the experimentthree times for the latter three dataset"}
{"[-0.079082675, 0.14780484, 0.0024224194, 0.013192869, 0.028025528, -0.023907416, -0.055752914, -0.03689531, -0.021540899, 0.03214364, -0.030392045, 0.05392678, 0.00085250527, -0.04740488, -0.014022081, -0.110835, 0.0068619684, 0.013267404, -0.029031765, 0.015857529, 0.02457824, -0.008897733, 0.037733838, 0.1033814, -0.040882986, -0.07923175, -0.0628711, 0.047777563, 0.0005016621, 0.054746676, -0.04114386, 0.12917085, 0.059256103, 0.020255152, 0.039615873, 0.01166488, -0.03149145, -0.07796463, 0.047181275, -0.037398428, -0.01893214, -0.017348249, 0.010667962, 0.0122239, 0.06793954, -0.030857895, 0.045504216, -0.0017119983, -0.0385351, 0.056237396, -0.00462356, -0.019193014, 0.044796124, 0.013658718, -0.033522557, 0.032497685, -0.0083526885, -0.031696424, 0.03087653, 0.038069252, -0.020068813, 0.0051616165, -0.0032865708, -0.007090235, 0.0012612885, 0.009643093, -0.009978504, -0.029590784, 0.034901474, -0.02005018, 0.01774888, -0.04602597, -0.0010126411, -0.033652995, 0.037193455, 0.04602597, -0.022752108, -0.014897879, 0.05191431, 0.006228413, 0.025975788, -0.019584328, 0.00722999, 0.0003645275, -0.048373852, -0.05154163, -0.009181901, -0.0045793043, 0.00797535, 0.0066476776, 0.048038438, 0.011804636, -0.058659814, -0.007733108, 0.020180617, -0.016407233, -0.03689531, -0.03348529, -0.0263112, 0.021745872, -0.034342453, 0.02370244, -0.025081357, -0.0041064667, 0.02196948, -0.05336776, 0.024764579, -0.050274517, -0.02742924, -0.042597312, -0.00034909626, -0.050759003, 0.021578167, 0.0060560484, 0.03322441, 0.02057193, 0.009498679, -0.006186486, 0.026124861, 0.0069458215, 0.021708604, -0.054448534, 0.036690336, -0.020907342, -0.012978577, 0.008585613, -0.012568629, -0.008823196, 0.025267698, 0.04188922, 0.04099479, -0.044833392, -0.009000219, 0.011813953, 0.005483053, 0.005948903, 0.010966106, 0.023348395, 0.009121341, 0.014897879, -0.049939107, -0.021652702, 0.052212454, -0.014208421, 0.021652702, -0.016230209, 0.020180617, 0.015987968, 0.018811017, 0.002429407, -0.06384007, -0.0071135275, 0.038236957, -0.022845278, 0.008948976, -0.0041903197, 0.007956716, -0.024895018, -0.024466434, -0.014981732, -0.08772885, 0.0018040036, 0.024540972, -0.014264323, 0.015447582, -0.05228699, -0.0024526995, 0.011925757, -0.03983948, 0.025975788, -0.014748807, -0.018093608, 0.028044162, 0.035255518, 0.015223973, -0.009489362, 0.019658865, 0.021429094, -0.024093755, -0.038982317, -0.022416696, 0.010276648, 0.0032097057, -0.020776905, -0.0005304865, 0.0055436133, -0.009023512, 0.054150388, 0.019015992, -0.025342233, -0.024354631, -0.0068759443, -0.017329615, 0.030708823, 0.022845278, -0.010742498, 0.015587336, -0.007700498, 0.01917438, -0.008143056, -0.037100285, 0.02001291, -0.036094047, -0.018755116, -0.03816242, 0.0062190956, -0.006433387, 0.024335997, 0.0023199324, 0.01700352, -0.017646393, 0.01241024, -0.01107791, 0.056684613, 0.011105861, -0.00088220317, -0.007546768, 0.026180763, 0.035348687, -0.019248916, -0.03408158, -0.031156039, -0.0073930374, -0.0073557696, 0.021205487, -0.018503556, 0.008483126, 0.017124642, -0.04203829, 0.008464492, 0.009615141, -0.054150388, -0.004849497, -0.0019053259, 0.027746018, -0.027280169, -0.03264676, 0.017506639, 0.017012836, -0.00667097, -0.018382436, 0.029963464, 0.008436541, 0.002485309, 0.027187, 0.007118186, 0.03950407, 0.0037524207, -0.024652775, 0.021522265, 0.003587044, -0.0077191326, -0.022789376, 0.051280756, -0.003913139, 0.01322082]": "k of 10-class image classiﬁcation. We\nﬁnd that even for the same dataset, different labels have a great\nimpact on Hidden Trigger. So, we repeated the experimentthree times for the latter three datasets. We use the same\nexperiment setting and try to poison the data on different\nlabels. As shown in Table II, our proposed approach can\nsuccessfully implant backdoors in the context of transfer\nlearning and achieve a very high ASR. In particular, our attack\nmethod can maintain 100% ASR in most cases, however,Hidden Trigger’s ASR is generally lower than 30%. Under the\nfour data sets, the ASR of our method is nearly 70% higher\nthan that of Hidden Trigger on average, which is becauseour method can be used in multi-class classiﬁcation scenarios.\nNearly 30% higher than Trojan, but our trigger is invisible.\nIn later ablation experiments, we will test the effects of\ndifferent /epsilon1, different poisoning rates, and different model\nstructures on our method. Based on these experimental results,we m"}
{"[-0.0692958, 0.11223551, -0.039386075, 0.03157549, 0.07751357, 0.009258874, -0.059782434, -0.049972933, -0.057154227, -0.043383908, -0.043939166, 0.072294176, 0.0059412266, -0.048233133, 0.023987008, -0.093727015, -0.008078958, 0.013131776, -0.05785755, 0.057191245, 0.053119376, 0.010882994, 0.025245585, 0.1076454, -0.07532957, -0.08876674, -0.03536973, 0.07677323, 0.01161408, 0.0403115, -0.040977806, 0.096170135, 0.09824309, -0.029076844, 0.033130202, 0.030076303, -0.038497668, -0.060744878, 0.010855231, -0.06389132, -0.04116289, 0.0021759048, 0.00995757, -0.026504163, 0.026356095, -0.023987008, -0.026448637, -0.058597893, -0.018554766, 0.05933823, -0.005552548, 0.050935373, 0.044309333, 0.03033542, 0.00038462965, 0.026208026, -0.008115974, -0.010642384, 0.029409997, 0.015695203, -0.0011151368, 0.026966875, -0.028040368, -0.030020777, 0.0070332275, 0.025097517, 0.0053119375, -0.035554815, 0.015315779, -0.0087637715, 0.004481369, -0.03475895, -0.02124775, -0.009388434, 0.027540639, 0.031057252, 0.013983167, -0.016944526, 0.029983759, 0.0022869557, 0.0442353, -0.011891707, 0.012863403, 0.06007857, -0.045012657, -0.028762199, 0.014890083, -0.01529727, 0.004333301, -0.0057885316, 0.050232053, -0.006066159, -0.026818808, 0.02285799, 0.042939704, -0.014214523, -0.071553834, -0.02274694, 0.017175883, 0.060633827, -0.014260794, 0.00079008134, -0.013316861, 0.0017652476, 0.014667981, -0.05770948, 0.022913516, -0.023875957, -0.031612508, -0.0579686, -0.012817132, -0.024375686, 0.038534682, -0.049935915, 0.023302194, -0.0095688915, -0.004465174, -0.015362049, 0.02704091, 0.00040603007, -0.012169335, -0.010707163, 0.0400894, -0.042125333, 0.0006998524, 0.0461972, -0.003431012, 0.031279355, 0.01309476, 0.022469312, 0.03511061, -0.035332713, -0.008999755, 0.016009847, 0.011077333, -0.020803547, -0.011151368, 0.007935517, 0.013113268, -0.0066352948, -0.032260306, 0.005844057, 0.06670461, -0.0026698501, 0.047233675, -0.02850308, -0.0070563634, 0.021951074, 7.193731e-05, 0.025782332, -0.0075468384, 0.013224319, 0.013566726, 0.028669657, -0.015500863, -0.02692986, 0.004802954, -0.03625814, -0.016565101, 0.0068481425, -0.06570515, -0.026226535, 0.014260794, -0.011697368, 0.0014853067, -0.042199366, 0.008004923, 0.015389812, -0.045678962, 0.010984791, 0.008250161, 0.00045490408, 0.022080634, 0.054489005, -0.0055664293, -0.0183049, 0.023579821, 0.010475808, 0.022025108, -0.008736009, -0.0013950777, -0.007856855, -0.01660212, -0.005992125, -0.0009161704, 0.00918484, 0.0074866856, 0.023265177, 0.00830106, -0.031890135, -0.0073339907, -0.028706674, -0.04438337, 0.015945068, 0.015528626, -0.012021267, 0.0020047012, 0.016463306, 0.01769412, -0.020914597, -0.05641389, -0.0030839778, -0.0037965549, -0.012650555, -0.0041991146, -0.0017883832, 0.0098742815, 0.0120305205, -0.009124687, 0.014779032, -0.009143196, 0.023801923, -0.017037068, 0.034092646, -0.013557471, 0.021562396, 0.010605367, 0.0005274921, 0.02541216, 0.004335615, -0.022043616, -0.014390354, -0.008310313, -0.019748563, 0.002275388, -0.01904524, 0.0075283297, 0.008282551, -0.036572784, -0.0098095015, 0.020322327, -0.038053464, 0.015917305, -0.04116289, 0.0075977365, -0.009679942, -0.038534682, -0.008837806, 0.007532957, -0.03381502, -0.01449215, 0.0062466166, 0.0085231615, 0.0020047012, -0.011762148, 0.021284768, 0.029669115, -0.0076254993, -0.03759075, 0.010068621, 0.024042534, -0.02124775, -0.0085231615, 0.055118293, -0.014519913, 0.0047937]": "sible.\nIn later ablation experiments, we will test the effects of\ndifferent /epsilon1, different poisoning rates, and different model\nstructures on our method. Based on these experimental results,we modiﬁed the model and compared it with the advanced\nmethods to show the superiority of our method, including\nInvisible Trigger [30] and ATTEQ [28].\nC. Ablation Experiment\nOrder of /epsilon1:The value of /epsilon1(deﬁned in Eq. (4)) directly\naffects the stealthiness of poisoned images and thus affects the\npossibility of the attack being discovered by users. Figure\n6\nshows the original image and the effect of different /epsilon1values.\nIt can be found that the perturbation in the poisoned image\ncan be obviously seen when /epsilon1=16 is set by predecessors.\nWith the continuous reduction of /epsilon1, the poisoning picture is\ngradually approaching the original picture, so the /epsilon1should be\nas small as possible. The authors of Hidden trigger [26] tested\nthe performance of the attack at an "}
{"[-0.058691952, 0.10824001, -0.006676721, 0.03306301, 0.0392147, -0.02360316, -0.073114045, -0.053525276, -0.049622394, 0.0045371037, -0.040069617, 0.077611655, -0.014347748, -0.053227916, 0.028435303, -0.101028964, -0.013799486, 0.02979202, -0.07448935, 0.06278069, 0.054045662, 0.01820417, 0.010751518, 0.09218242, -0.05623871, -0.08296418, -0.045087613, 0.096568525, -0.005896144, 0.028769838, -0.03601805, 0.09500737, 0.09404094, 0.008414434, 0.07054929, 0.011290488, -0.024959877, -0.058691952, 0.00055058557, -0.081105664, -0.0151376175, -0.0006516424, -0.0038308674, -0.002869085, 0.027859164, -0.02860257, 0.009831552, -0.037727885, -0.00425368, 0.049213517, 0.0022069884, 0.016029706, 0.043043245, 0.0285654, 0.00759204, 0.032356773, -0.027914919, 0.0029109016, 0.03564635, 0.030089384, -0.021930495, 0.015332762, -0.03560918, -0.0066209654, -0.007810416, 0.022450881, -0.006147044, -0.035702102, 0.057762697, -0.04029264, 0.009757212, -0.030238064, 0.005166676, -0.0064583453, 0.05192695, 0.024290811, 0.013799486, -0.033081595, 0.037003066, -0.013613634, 0.016122632, -0.021094164, -0.006806817, 0.04590536, -0.024811197, -0.025740454, -0.009418033, 0.00038825572, -0.00076083024, -0.016401408, 0.027970675, -0.008047377, -0.04044132, -0.00971075, 0.036501266, -0.026242254, -0.046462916, -0.030461088, 0.00532465, 0.06382146, -0.020276416, 0.010807274, -0.020536609, 0.0073876036, 0.0034963344, -0.075976156, 0.02403062, -0.038768657, -0.011271903, -0.058654785, -0.023194287, -0.017646614, 0.04237418, -0.029234465, 0.024327982, 0.0045045796, 0.02579621, 0.002352185, 0.0103798155, -0.017442178, 0.006281786, -0.027022831, 0.034308217, -0.021726059, -0.028881349, 0.026093572, -0.03367632, 0.02191191, 0.022190688, 0.027320193, 0.038582806, -0.029011443, -0.02860257, 0.02741312, -0.005882205, 0.009436618, -0.019700276, 0.011467047, 0.014580063, 0.006969437, -0.056610417, -0.030070798, 0.04824709, -0.003842483, 0.03179922, -0.019941883, 0.0034684567, 0.024458079, 0.01608546, 0.009069561, -0.024458079, 0.009627116, 0.0353304, -0.01622485, -0.0051759686, -0.0070251925, -0.0024044558, -0.03371349, -0.018157708, 0.0065791486, -0.08876275, 0.004720632, 0.037356183, -0.020741045, 0.00978509, -0.05252168, -0.00010149243, 0.012572865, -0.036092393, 0.030200895, 0.01543498, 0.0018922022, 0.016131924, 0.037690718, 0.008748967, -0.011532095, 0.034921527, 0.019737447, 0.011996725, -0.008107779, -0.015908903, 0.030777035, -0.012071066, -0.0017597829, 0.018826773, 0.012405599, -0.008600285, 0.020833971, 0.00015202085, -0.012786594, 0.0004835047, -0.0104541555, -0.037820812, 0.014096849, 0.007029839, 0.0014693897, -0.0041212607, 0.0026809103, 0.011708654, -0.017061181, -0.04163077, -0.002804037, -0.00073934114, -0.03025665, 0.005529087, 9.713653e-05, 0.028621156, 0.03021948, -0.00847019, 0.018789602, -0.023027021, 0.010045283, -0.025889136, 0.060030084, -0.022283614, 0.016317775, 0.007963744, -0.00895805, 0.019161306, -0.006514101, -0.027896333, -0.025015634, -0.009970942, -0.011671484, -0.0062213843, -0.033546224, -0.021986252, 0.012572865, -0.042188328, -0.011392707, 0.0074061886, -0.04025547, 0.017395716, -0.009617823, -0.004530134, -0.017079767, -0.04694613, -0.00033946967, 0.018120537, -0.012693669, -0.0051109204, 0.036148146, 0.024346568, -0.0074665905, 0.011848044, 0.007763953, 0.021521622, -0.017962562, -0.0256847, 0.023863353, 0.016336361, -0.01489601, -0.015267714, 0.042076815, -0.002966657, 0.020945482]": "on1, the poisoning picture is\ngradually approaching the original picture, so the /epsilon1should be\nas small as possible. The authors of Hidden trigger [26] tested\nthe performance of the attack at an /epsilon1of 8,16 and 32 and found\nno signiﬁcant difference in the effect of the attack, so they\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. CHEN et al.: ICT BACKDOOR ATTACKS IN TRANSFER LEARNING 6753\nTABLE II\nPERFORMANCE OF THREE ATTACK METHODS ON FOUR DATASETS WITHALEXNETMODEL .FOR THE LATTER THREE DATASETS ,\n10 C LASSES WERE SELECTED EACH TIME AND THE EXPERIMENT WASREPEATED THREE TIMES\nFig. 6. When /epsilon1is 2,8,16,32, the poisoned picture is generated. The smaller\nthe/epsilon1, the closer the poisoning image is to the original image. /epsilon1equals 0\nrepresenting the clean image.\nFig. 7. (a) and (b) are respectively the changes of ACC and ASR under\ndifferent /epsilon1values of Hidden Trigge"}
{"[-0.079840906, 0.11421788, -0.02821963, 0.0095197065, 0.06038294, -0.025950154, -0.05309085, -0.051379446, -0.030954162, 0.013421531, -0.025503699, 0.07701336, -0.0042831707, -0.033446863, 0.03778119, -0.09278808, -0.026471017, 0.036609247, -0.07027934, 0.02691747, 0.023327235, 0.03891593, 0.0559556, 0.09219281, -0.034842033, -0.07961768, -0.058894757, 0.08304049, 0.0147422915, 0.04583597, -0.038395066, 0.086835355, 0.055992804, -0.009561562, 0.06436382, 0.04047852, -0.045315105, -0.071060635, -0.0037902107, -0.052458376, -0.030414697, 0.0046621915, 0.020016033, -0.013282014, 0.022006474, -0.049965672, -0.0032460946, -0.033632886, 0.007413001, 0.047956627, -0.015988642, 0.003257721, 0.03463741, 0.03406074, 0.031363413, 0.012537924, -0.021913463, 0.0095197065, 0.04047852, 0.030544912, -0.011086947, 0.032405138, -0.030228674, -0.02485262, -0.0014091212, 0.010296351, -0.008566341, -0.024331758, 0.047956627, -0.023513258, 0.035083864, -0.050263308, -0.012723946, -0.01670483, 0.03512107, 0.030470503, 0.021132167, -0.012128674, 0.048031036, -0.012854163, 0.04631963, -0.03925077, -0.008868628, 0.06138746, -0.018220915, -0.04918438, -0.022992395, 0.031623844, 0.02230411, -0.01990442, 0.027549949, 0.008198947, -0.042710792, -0.035493113, 0.01695596, -0.008189646, -0.043901335, -0.010091727, -0.0061713, 0.058559917, -0.019885818, 0.0005694036, -0.026601233, 0.013840082, 0.008910483, -0.057555396, 0.04334327, -0.017504727, 0.00056213705, -0.06574039, -0.021913463, -0.003101927, 0.041855086, -0.026973277, 0.036981296, 0.013375025, 0.003694874, -0.013719168, -0.01168222, -0.015439876, 0.0053853546, -0.039771635, 0.036888283, -0.034525797, -0.02163443, 0.04107379, -0.046170812, 0.033279445, -0.0055667264, 0.033781707, 0.034451388, -0.010752107, -0.022992395, 0.016165365, -7.161144e-05, 0.011570606, -0.02081593, 0.017374512, 0.02954039, 0.02213669, -0.05454183, -0.019662589, 0.031642444, -0.009194167, 0.037948612, -0.017932579, 0.009868499, 0.03463741, -0.004125051, 0.0049714544, -0.014453957, 0.02526187, 0.027996402, -0.009970812, -0.01020334, 0.009222071, -0.017039672, -0.038618293, -0.0061433967, -0.0006167812, -0.09397862, 0.0048272866, 0.026843062, -0.011254367, 0.009775488, -0.05331408, -0.0053760535, 0.009096505, -0.041259814, 0.021504214, -0.007282785, -0.006617754, 0.022043679, 0.026973277, 0.018369732, 0.006757271, 0.035102464, -0.0012033337, 0.0077478415, -0.044310585, -0.005538823, 0.016090956, -0.003957631, 0.015765416, 0.008547739, 0.008626798, 0.00773389, 0.021113565, -0.010854419, 0.002476426, -0.017988386, 0.003915776, -0.03988325, 0.0031065776, 0.017551232, -0.01242631, -0.00059527234, 0.00014678347, 0.008673304, -0.01439815, -0.050635353, 0.002295054, -0.0026670992, -0.01612816, 0.0015753789, 0.0047017215, 0.021578623, 0.020350873, -0.0056736893, 0.016276978, -0.005538823, 0.004311074, -0.021708839, 0.05331408, -0.023829496, 0.017141983, 0.0197556, 0.0020020683, 0.022118088, 0.01546778, -0.040924974, 0.0024206191, 0.005645786, -0.008757014, -0.0064968397, -0.018072097, -0.01908592, 0.0048412383, -0.048254263, 0.004606385, -0.00038657823, -0.03398633, 0.016100256, -0.006064337, -0.0013544771, -0.022620348, -0.055509146, 0.024629394, 0.0084965825, -0.009738283, -0.016221171, 0.024052722, 0.013263412, -0.010184738, 0.008738412, -0.00013995294, 0.031475026, -0.023141213, -0.044124562, 0.036274407, -0.00079001475, -0.03817184, -0.017514028, 0.056736894, -0.003720452, 0.0238667]": "isoning image is to the original image. /epsilon1equals 0\nrepresenting the clean image.\nFig. 7. (a) and (b) are respectively the changes of ACC and ASR under\ndifferent /epsilon1values of Hidden Trigger and Our Method. 1, 2, 3, and 4 represent\ndifferent datasets, for example, ACC1 means accuracy under CIFAR-10 and\nASR1 means attack success rate under CIFAR-10.\nconcluded that /epsilon1did not affect the experiment. But we argue\nthis is wrong, and a decrease in /epsilon1usually leads to a decrease\nin ASR. The reason why predecessors concluded that /epsilon1had\nno effect on the experimental results was because /epsilon1was set\ntoo large. When /epsilon1=16, it is big enough to produce a suitable\nperturbation so that the poisoned picture has a similar output\nat the speciﬁed layer as the picture with the trigger added, so\nthe ASR does not improve when the /epsilon1increases.\nWe test the impact of the value of /epsilon1on four datasets. As\nshown in Figure 7(a), where 1, 2, 3, and 4 represent f"}
{"[-0.07145453, 0.13362442, -0.021076115, 0.024437152, 0.055187855, -0.030843548, -0.05529927, -0.043934878, -0.04066669, -0.026869725, -0.04014675, 0.056859087, 0.020147651, -0.0216889, 0.017872917, -0.08326458, -0.011438667, 0.028151006, -0.05775041, 0.04237506, 0.07015468, 0.021391792, 0.026368355, 0.11252974, -0.005125117, -0.07435133, -0.052216772, 0.07134312, 0.013834102, 0.024641413, -0.042932138, 0.0819276, 0.09500036, -0.034984495, 0.06235559, 0.04062955, -0.02900519, -0.069820434, 0.0015598182, -0.06280125, -0.040592413, 0.028726652, 0.012153584, -0.018745672, 0.032904737, -0.03940398, 0.006285696, -0.021503208, -0.015691029, 0.06395254, 0.004052742, -0.0035444084, 0.042003676, 0.028299559, 0.016452368, 0.024697121, -0.019646281, -0.023861505, 0.034557402, 0.059718754, -0.0071305977, 0.01920062, -0.017492248, -0.023378704, 0.009029305, 0.014836842, -0.009730294, -0.04315497, 0.035727266, -0.029135175, 0.017232276, -0.029617976, -0.023601536, -0.019052066, 0.038958315, 0.04467765, 0.01388981, -0.005891099, 0.049691353, -0.0076737483, 0.026108386, -0.026572617, 0.017594378, 0.033684645, -0.04088952, -0.024901383, 0.005101905, 0.010946581, 0.0040132822, -0.0037184951, 0.039738227, 0.006304265, -0.032347657, -0.005334021, 0.00934034, -0.032440506, -0.04207795, -0.015700312, 0.007724814, 0.049134273, -0.013945517, 0.017956479, -0.015124666, 0.013044908, 0.00368832, -0.059495922, 0.032941874, -0.011540798, -0.017501531, -0.04189226, -0.025161354, -0.042820722, 0.026851157, -0.021911731, 0.02425146, 0.022803057, 0.009748864, -0.012970631, 0.006318192, -0.025662724, 0.008439731, -0.042449336, 0.039478257, -0.056710534, -0.01876424, 0.046274606, -0.012552823, 0.015913859, -0.00088726263, 0.022357395, 0.045568973, -0.020760437, -0.011503659, 0.0146232955, 0.007994068, 0.011150843, -0.015477482, 0.0014808988, 0.02852239, 0.007613398, -0.036451466, -0.006800993, 0.05017415, -0.021298947, 0.045568973, -0.016470937, 0.019757697, 0.029172314, 0.02068616, 0.011550083, -0.015068958, 0.01110442, 0.014446887, -0.011642929, -0.014446887, -0.00384848, 0.004463587, -0.027946742, -0.0079708565, -0.008254038, -0.10450782, -0.007831587, 0.011410813, -0.024288598, 0.003804378, -0.06588375, -0.0021714433, 0.008713627, -0.043117832, 0.020073375, -0.0012859215, -0.012432123, 0.039515395, 0.024307167, 0.011327251, 0.0027598569, 0.03030504, 0.011828621, 0.0064853155, -0.025885554, -0.013453432, 0.014075503, 0.0066756504, 0.008541862, 0.012172152, 0.020463329, -0.027983882, 0.043749187, -0.0036070796, 0.00334711, -0.0003493343, 0.00960031, -0.030917825, 0.0074555594, 0.0214475, -0.011967891, 0.0058539608, -0.001078178, 0.015848868, -0.01940488, -0.04315497, 0.004681776, -0.010435927, -0.016703052, -0.0021389471, -0.0073255748, 0.02245024, 0.031344917, -0.0074555594, 0.020890422, -0.008031207, 0.012320707, -0.012487831, 0.039961055, -0.0169166, 0.01589529, -0.009637448, -0.010714466, 0.036730006, 0.0026948645, -0.036971405, -0.01362984, -0.02090899, -0.0114015285, 0.007836229, -0.015588897, -0.023267288, 0.0080265645, -0.046348885, 0.0059375223, 0.009363552, -0.042783584, 0.008532577, -0.02044476, 0.017742932, -0.0110394275, -0.04163229, 0.019479157, 0.010064541, -0.0077480255, -0.002511493, 0.019033495, -0.01755724, -0.0061882073, 0.015644604, 0.008170476, 0.029358007, 0.0058261068, -0.04594036, 0.025866985, 0.0030291113, -0.030119346, -0.006062865, 0.043043554, -0.021261808, 0.012692092]": "with the trigger added, so\nthe ASR does not improve when the /epsilon1increases.\nWe test the impact of the value of /epsilon1on four datasets. As\nshown in Figure 7(a), where 1, 2, 3, and 4 represent four\ndifferent datasets, respectively. When the /epsilon1is reduced to 8,\nthere is a signiﬁcant drop in ASR, and even in the ﬁrst and lastset of experiments, ASR is down below 10 percent. In contrast,\nthe ASR of our method is not affected by the reduction of\nFig. 8. (a) and (b) are respectively the changes of ACC and ASR under\ndifferent numbers of poisoned images of Hidden Trigger and Our Method.\n/epsilon1.A f t e rt h e /epsilon1is reduced to 2, it can still have a high attack\nsuccess rate, and the ACC is not reduced, remaining above90%, as shown in Figure 7(b). The ASR of our method is\nreduced signiﬁcantly when /epsilon1is set as 2 in the fourth set\nof experiments, but in general, it outperforms the previousmethods.\nNumber of Poisons: In actual attacks, the attacker prefers\nusing less poi"}
{"[-0.049413748, 0.13867012, -0.02619077, 0.009381007, 0.05312349, -0.024539936, -0.07371255, -0.033406217, -0.038136136, -0.025727052, -0.049747624, 0.07285931, -0.026469002, -0.044442695, 0.022110056, -0.0815401, -0.03338767, 0.041512, -0.057500985, 0.028286774, 0.066033386, -0.0006619569, 0.0032066072, 0.07849812, -0.03223765, -0.05382834, -0.06113653, 0.073081896, -0.002295402, 0.062509134, -0.03824743, 0.11759879, 0.07894328, 0.0026594205, 0.055905793, 0.0132066775, -0.042550728, -0.07334158, 0.010544938, -0.058725197, -0.014579281, 0.00604224, -0.0010601744, 0.016972065, 0.052196052, -0.01495953, 0.0062555503, -0.036151424, 0.002847226, 0.05197347, -0.017343039, -0.012640942, 0.047002416, 0.028379517, 0.0061303466, 0.009784441, -0.01623939, -0.028027093, 0.06466078, 0.011361081, -0.0036610505, 0.0033805014, -0.024076218, 0.005717638, 0.03349896, 0.023427013, 0.009422742, -0.03552077, 0.04325558, -0.0035312097, 0.0126038445, -0.048708897, -0.023111686, -0.018057164, 0.03466753, 0.050489575, 0.008611236, -0.000277506, 0.06521724, -0.013642572, 0.047410488, -0.02090439, 0.027656117, 0.03850711, -0.053308975, -0.02849081, 0.007813642, -0.015562363, -0.031217469, -0.009302176, 0.034426395, 0.002148172, -0.041512, -0.003899865, 0.0017122773, -0.023371367, -0.05397673, -0.008643696, -0.00339905, 0.03275701, -0.020756, 0.027210949, -0.042439435, 0.00870398, 0.018020066, -0.045295935, 0.0024832077, -0.014968804, -0.009469113, -0.03594739, -0.018808385, -0.040213592, 0.012826429, -0.0009569972, 0.017064808, 0.013930077, -0.008857006, -0.029084368, -0.0011169798, -0.0078090043, 0.009381007, -0.028898882, 0.0386555, -0.04466528, -0.006640436, 0.052752513, -0.009923557, 0.0046186275, 0.00937637, 0.027878702, 0.039842617, -0.01259457, -0.015840594, 0.014115564, -0.0018513926, 0.028620651, -0.00904713, -0.023835085, 0.043181382, 0.019772919, -0.040139396, -0.004509654, 0.055757403, -0.015692204, 0.032348942, -0.02706256, 0.020069698, 0.013141757, 0.00944129, -0.0038372632, -0.03795065, 0.02133101, 0.013549829, -0.00873644, -0.0061025238, -0.013772413, 0.0046580434, -0.020218087, -0.022833455, -0.016183745, -0.08858861, -0.0047948402, 0.027248047, -0.010925187, 0.011092125, -0.04826373, 0.0029701113, -0.0047902027, -0.043070093, 0.022091506, -0.0011853782, -0.014338149, 0.026357708, 0.033777192, 0.018576527, 0.009464476, 0.02173908, 0.020997133, 0.009645326, -0.01747288, -0.016526895, 0.016387781, 0.012882075, 0.006487409, 0.012279242, 0.010878815, 0.009302176, 0.03622562, 0.00855559, -0.005323478, -0.004845849, 0.008615873, -0.04247653, 0.014672025, 0.021683436, -0.008569501, -0.0022896058, 0.0030141645, 0.020570513, -0.02018099, -0.03622562, -0.0032622532, 0.01031308, -0.019772919, -0.017862402, -0.00050023536, 0.0075632343, 0.008263447, 0.01238126, 0.027600473, -0.014143387, 0.005532151, 0.014226856, 0.04136361, -0.013058288, 0.01331797, 0.009399556, -0.01453291, 0.029047271, -0.0023765527, -0.03767242, -0.0029469253, -0.028843235, 0.0038465376, 0.008843095, -0.0070438706, -0.016276488, 0.0060607893, -0.06503176, 0.015358327, 0.027600473, -0.051417008, 0.011824799, -0.014829689, 0.0157293, -0.010702603, -0.020069698, 0.020718902, 0.0029028722, -0.025819797, -0.011286886, 0.01990276, 0.013160306, 0.011073576, 0.013429262, 0.01052639, 0.026357708, 0.0045444327, -0.042921703, 0.03461188, 0.00898221, -0.029306952, -0.016545445, 0.046186272, -0.016916418, 0.019383395]": "d signiﬁcantly when /epsilon1is set as 2 in the fourth set\nof experiments, but in general, it outperforms the previousmethods.\nNumber of Poisons: In actual attacks, the attacker prefers\nusing less poisoned data to reduce the risk of detection. Todo this, we test the performance of our method and baseline\nunder different numbers of poisoned images. Since there are\nfewer pictures per label in the latter two datasets, we onlyconduct experiments on the CIFAR-100 dataset. To exclude\nthe inﬂuence of data labels, we change the label of the training\ndata and conduct four independent repeat experiments, whichcorrespond to the four groups of data in Figure 8.A ss h o w ni n\nFigure 8(a), when the number of poisoned pictures decreased,\nthe ASR of Hidden trigger show an obvious downward trend.When the poisoning rate is reduced to 1%, the ASR is\ngenerally less than 50%, and only the ASR of the second group\nof experiments is greater than 50%. We believe this is because\nthe label is more susceptible t"}
{"[-0.04188475, 0.13274585, -0.013213641, 0.013592229, 0.04325136, -0.030434774, -0.06940163, -0.031321224, -0.04018572, -0.029492922, -0.042475715, 0.07948499, -0.010360382, -0.068810664, 0.016122304, -0.066705346, -0.046981838, 0.021200923, -0.034940895, 0.0427712, 0.090565614, 0.0063113375, 0.0100002615, 0.07800758, -0.04495039, -0.069770984, -0.054221176, 0.065708086, 0.03241082, 0.027313732, -0.019945119, 0.07926338, 0.085320786, -0.0060666404, 0.055181496, 0.041700073, -0.015669845, -0.06231003, 0.008896816, -0.0654126, -0.05241134, 0.028255586, -0.019723507, 0.009247703, -0.003451152, -0.04140459, 0.0005849068, -0.01711956, -0.029345179, 0.055366173, -0.00653295, 0.022659872, 0.035254844, 0.011976305, 0.010517357, 0.0038181976, -0.029105099, -0.019317217, 0.05255908, 0.040628947, -0.020406812, 0.008462825, -0.021699551, -0.030785661, 0.028495666, 0.015411298, 0.0039382377, -0.06954937, 0.032447755, 0.002428503, 0.0056141815, -0.0409983, -0.025854783, -0.04668635, 0.032041464, 0.030933402, 0.01615924, -0.0028694193, 0.04251265, -0.031967595, 0.05673278, -0.009944858, 0.0123364255, 0.01572525, -0.053408597, -0.031210417, 0.012013241, -0.0056141815, 0.0030702555, -0.0022761445, 0.026427282, 0.0034234505, -0.062014546, 0.014644888, 0.010009495, -0.031653643, -0.045319743, -0.0044460995, 0.012160982, 0.057914715, -0.0014497146, 0.029382115, -0.04140459, 0.021736486, -0.0076179276, -0.06869985, 0.02339858, -0.015780652, -0.028680343, -0.023103096, 0.00082008145, -0.04358378, 0.018144518, 0.006634522, 0.00884603, 0.0445441, 0.0053833355, -0.035107102, 0.016436255, -0.015078879, -0.0015178144, -0.033740494, 0.042143296, -0.06615131, -0.012364127, 0.032983318, -0.007918027, -0.007590226, 0.0077287336, 0.034312993, 0.025633171, -0.004272965, -0.034737747, 0.019741975, -0.005295614, -0.0021814974, -0.0074332505, -0.0068561346, 0.04044427, 0.020388344, -0.044174746, -0.01824609, 0.05348247, -0.018162986, 0.026482686, -0.0070315776, 0.029585259, 0.028347924, 0.008970686, -0.0028093993, -0.035550326, 0.015946861, 0.013970817, -0.014811098, -0.01733194, -0.024063418, -0.009118428, -0.011911668, -0.02291842, -0.021163987, -0.08967917, -0.007705649, 0.0117546925, -0.019261815, -0.002368483, -0.061054226, 0.016657868, 0.014081623, -0.051414084, 0.010960582, -0.0020706912, -0.011828564, 0.030619452, 0.025374623, 0.0133890845, -0.015161984, 0.03852363, 0.019889716, 0.0011144105, -0.030490177, -0.018790888, 0.026390348, -0.008873731, -0.0058034756, 0.0071793194, 0.018947864, -0.009095344, 0.041626204, -0.012004007, -0.011653121, -0.006149745, 0.004796986, -0.029160503, -0.0058542616, 0.022789145, 0.0016874863, -0.009256936, 0.008592099, 0.020351408, 0.0059188986, -0.034885492, 0.0011732762, 0.010720502, -0.015734483, -0.01378614, -0.013121303, 0.022050437, 0.02548543, -0.010840542, 0.011366871, 0.0042314124, 0.011080622, 0.0031279672, 0.042291038, 0.017664358, 0.007567141, -0.0035481073, -0.0038920683, 0.022493662, 0.016916417, -0.036769196, -0.018467702, -0.0231585, 0.003271092, 0.027904699, -0.02186576, -0.018855525, 0.028661875, -0.038154274, 0.0050601508, 0.015771419, -0.044396356, 0.027387604, -0.012114813, 0.0016124613, -0.010388083, -0.03135816, 0.00442994, 0.024912931, -0.0095201, -0.03543952, 0.0032480073, 0.0028694193, 0.011690056, 0.003635829, -0.0055633956, 0.034202185, 0.012170216, -0.04487652, 0.029880743, -0.0036289035, -0.045061193, -0.012631909, 0.024635915, -0.024728253, 0.018578509]": "poisoning rate is reduced to 1%, the ASR is\ngenerally less than 50%, and only the ASR of the second group\nof experiments is greater than 50%. We believe this is because\nthe label is more susceptible to establish a connection with the\ntrigger. Then the trigger activates the backdoor in the model,resulting in a higher ASR. As can be seen from Figure 8(b),\nwith the number of poisoned images decreasing, the ASR of\nour attack is not particularly affected, and generally remainedat about 99%, only the fourth set of experiments shows a small\nﬂuctuation.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6754 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nTABLE III\nRESULTS OF OURATTACK METHOD UNDER DIFFERENT MODELS .THENUMBERS IN PARENTHESES REPRESENT THE TARGET ACTIV ATION\nVALUES OF THE SELECTED NEURONS .FOREXAMPLE ,“ R ESNET-18(10)” M EANS THAT THE TRIGGER WILL\nCHANGE THE ACTIV AT"}
{"[-0.053840984, 0.11827971, -0.012969267, 0.009699158, 0.056842443, -0.025530929, -0.059918012, -0.0234929, -0.055063803, 0.040945828, -0.05791704, 0.064772226, 0.001401144, -0.023826396, 0.005178443, -0.10049329, -0.006095555, 0.0062484075, -0.016378332, 0.079371914, 0.018675745, 0.067588404, 0.033923898, 0.12524606, -0.035517264, -0.05491558, -0.057101827, 0.03905602, 0.004671252, 0.0011469695, 0.022659162, 0.096936, 0.08085412, -0.004474397, 0.018851755, 0.010069709, -0.017749367, -0.064772226, 0.0396489, -0.03312721, -0.027105767, -0.017276917, -0.004485977, 0.015831769, 0.075703464, -0.020991685, 0.03861136, -0.008045577, 0.0057481644, 0.041056994, 0.022214502, -0.014192083, 0.023752285, 0.040686443, 0.036165725, 0.03181176, -0.010931239, 0.022140391, 0.057583544, 0.04683758, -0.00028717663, 0.018092128, -0.024789827, -0.02282591, 0.014497788, 0.019268624, -0.017119432, -0.05080247, 0.05095069, -0.020584079, 0.00778156, -0.037573818, -0.033849787, -0.024456332, 0.043947287, 0.017749367, 0.013404664, -0.009625048, 0.057064775, -0.0045160837, 0.028439749, 0.0018191712, 0.031107713, 0.02334468, -0.04924616, -0.041464597, -0.028847355, -0.008142847, -0.004430394, 0.016007781, 0.032738134, 0.019138932, -0.057472378, 0.03620278, 0.0014451469, -0.02282591, -0.033034574, -0.018851755, -0.038870744, 0.06666203, -0.03053336, 0.03381273, -0.03764793, -0.011940989, -0.013497301, -0.015396372, 0.04420667, -0.031237405, -0.023993144, -0.030496305, 0.0011753398, -0.062141314, 0.011357373, -0.01354362, 0.009643576, 0.017295444, 0.017323235, 0.010264249, 0.01686931, -0.011144306, 0.037684985, -0.029217904, 0.040019453, -0.022955602, -0.0021364552, 0.008036314, -0.032367583, 0.0074249054, -0.000622409, 0.0194539, 0.05647189, -0.012154056, 0.0063873637, 0.032330528, -0.019120404, 0.015220361, 0.0019604436, -0.009147965, -0.006035341, 0.04780101, -0.03898191, 0.0070311953, 0.058732253, -0.018036544, 0.0005917228, -0.034757636, 0.013867851, 0.019694759, 0.0056601586, 0.024196947, -0.045021884, 0.026716689, 0.007327636, -0.032738134, 0.0017809583, 0.0007758401, 0.013284234, -0.0133398175, -0.0016188424, -0.017397344, -0.03905602, 0.00028703187, 0.015692813, 0.0029458762, -0.008819101, -0.06566154, 0.012802519, 0.014683063, -0.016850783, 0.02162162, -0.016637716, 0.006530952, 0.040945828, 0.037610874, 0.010625535, 0.028680608, 0.011561175, 0.015998516, -0.023696704, -0.022288611, -0.03927835, 0.013793741, -0.0085550845, -0.008879316, 0.0046179853, 0.0019187568, 0.031311516, 0.041242268, -0.012672827, -0.024752771, -0.001988235, -0.02484541, -0.029217904, 0.038277864, 0.0080038905, 0.005178443, 0.022900019, 0.006693068, 0.032071143, -0.004863475, -0.031997032, 0.011320317, -0.0137103675, -0.010014127, 0.0031265197, -0.0018770698, 0.026661107, 0.029236432, 0.0064105233, 0.021010213, 0.0288103, 0.017452927, -0.014998031, 0.026179392, -0.009472197, -0.007429537, -0.00068957126, -0.0062854625, 0.012922948, -0.0074156416, -0.019435372, -0.029273488, -0.024159892, -0.0043771276, 0.034183282, -0.008758887, 0.0044095507, 0.013840061, -0.04932027, 0.005210866, -0.007471224, -0.062067207, 0.004821788, -0.004425762, 0.019435372, -0.022158919, -0.019565064, 0.013404664, 0.01189467, -0.022788854, -0.01758262, 0.003969522, 0.0015377845, 0.03329396, 0.024345167, 0.019361263, 0.021714259, 0.02417842, -0.03405359, 0.02910674, -0.0038259337, -0.014905393, -0.01795317, 0.032645497, -0.018573843, 0.034127697]": "METHOD UNDER DIFFERENT MODELS .THENUMBERS IN PARENTHESES REPRESENT THE TARGET ACTIV ATION\nVALUES OF THE SELECTED NEURONS .FOREXAMPLE ,“ R ESNET-18(10)” M EANS THAT THE TRIGGER WILL\nCHANGE THE ACTIV ATION OF A NEURON IN THE MODEL TO 10\nTABLE IV\nACCURACY (ACC) AND ATTACK SUCCESS RATE(ASR) OFDIFFERENT\nNUMBER OF CLASSIFICATIONS UNDER ALEXNETMODEL\nDifferent Models: To test the generalization ability of our\nmethod, we also conduct tests on ResNet-18 and ResNet-\n34. Experiments show that the model with residual structure\nis more difﬁcult to inject backdoors, and the ASR of themodel decreases signiﬁcantly. As shown in Table III,A S R\ndecreases on all four datasets, and the average ASR is also\nreduced to 67.63%. This is because ResNet is more robust than\nAlexNet. To enhance the effect of our attack, We increased\nthe target_value in Eq. (3)from 10 to 20 and 30, respectively,\nand then performed the experiment again. As shown in the\nsecond and third columns of Table III, the experiment found\nthat "}
{"[-0.1141209, 0.13362303, -0.02083689, -0.016730687, 0.024377678, -0.036965087, -0.061657913, -0.034592204, -0.042489458, 0.0067154476, -0.033943366, 0.036909472, -0.013671892, -0.012355682, -0.0018978439, -0.08238357, 0.01700876, 0.030828957, -0.030439654, 0.018686462, 0.024525983, 0.032219317, 0.041006405, 0.09684334, -0.0029359807, -0.08038145, -0.048866585, 0.040821023, 0.008921488, 0.025378738, -0.019205531, 0.10084758, 0.06855411, 0.009639842, 0.04667908, 0.027176939, -0.01369043, -0.0669969, 0.052055147, -0.048532896, -0.038855977, 0.015238366, 0.02556412, -0.033850677, 0.061546683, -0.040895175, 0.028085308, -0.008027023, 0.003024037, 0.030717727, -0.01872354, -0.00840242, 0.034480974, -0.0035106635, 0.025341662, 0.034981504, -0.036965087, -0.02002121, 0.044120815, 0.039597504, -0.015479362, -0.002576804, -0.010724324, -0.022987315, 0.013217706, 0.014737835, -0.009162485, -0.041710854, 0.038707674, 0.0016950828, 0.021596953, -0.03451805, -0.016767764, -0.027696008, 0.06017486, 0.03288669, -0.0075403955, -0.0054455837, 0.060508545, 0.0047110096, 0.017991282, 0.0016139784, 0.046234164, 0.03181148, -0.037354387, -0.050460864, -0.0018491813, -0.009037352, 0.014283651, 0.022523861, 0.03904136, 0.018779153, -0.036965087, 0.025582658, 0.01880696, -0.04178501, -0.018093241, -0.032033935, -0.021485725, 0.033739448, -0.065699235, 0.019372376, -0.042341154, -0.001868878, 0.013949963, -0.017249756, 0.009037352, -0.010613095, -0.0416367, -0.04679031, 0.0038049568, -0.057319984, 0.017045837, -0.014061193, 0.053352818, 0.0038119087, 0.023877148, -0.0072808615, 0.013217706, -0.016156005, 0.022245789, -0.048681203, 0.06188037, -0.019854367, -0.03151487, 0.031051414, -0.002748282, 0.0016522133, 0.0058534234, 0.024136681, 0.034258515, -0.02365469, -0.024322063, 0.0015282393, 0.0053111822, 0.045121875, 0.009449826, 0.0035894508, 0.02193064, 0.02193064, -0.032645695, -0.0032603985, 0.043527596, -0.023135621, 0.01278206, -0.045121875, 0.020484664, -0.007053769, 0.019854367, 0.012985979, -0.040821023, 0.010742863, 0.00790189, -0.01832497, -0.0011487865, -0.0047318647, 0.002255862, -0.031570483, -0.011438044, 0.010279409, -0.07637721, -0.015813049, 0.015822317, -0.015942816, 0.019168455, -0.04497357, 0.0020067557, -0.022097483, -0.03181148, 0.00976034, -0.023877148, -0.0073596486, 0.03288669, 0.036297712, 0.006145399, 0.037410002, 0.009232002, 0.012179569, -0.0034087037, -0.058506425, -0.036594324, -0.0018897335, -0.013718237, -0.014598799, -0.004191941, 0.010640902, -0.005403873, 0.036575787, -0.012049803, 0.007243785, -0.008221673, -0.0113546215, -0.031867094, 0.030940184, 0.03119972, -0.0154979, 0.019205531, 0.008087271, 0.036464557, -0.013625546, -0.0317744, 0.010297947, -0.011456582, 0.014663682, -0.026898867, -0.0043865917, 0.00018436777, 0.023895685, 0.0352225, -0.0024817958, 0.009593497, 0.0068683876, -0.014061193, 0.021578416, -0.015952084, 0.012457642, 0.011660501, -0.0015131772, 0.02838192, -0.009936453, -0.04178501, -0.0108355535, -0.036205024, 0.015182751, 0.04074687, -0.021596953, -0.0034226074, 0.031440716, -0.068146266, -0.017286832, -0.0143021885, -0.066477835, -0.009843762, -0.009472999, 0.020280745, -0.019205531, -0.036205024, 0.025619734, 0.008726838, -0.015664743, -0.010548212, 0.009602766, -0.0021307296, 0.008624878, 0.017555635, 0.026583718, 0.04067272, 0.006099054, -0.036594324, 0.042267, 0.027158402, -0.017648326, -0.03119972, 0.054057267, -0.024210835, -0.009097601]": ", We increased\nthe target_value in Eq. (3)from 10 to 20 and 30, respectively,\nand then performed the experiment again. As shown in the\nsecond and third columns of Table III, the experiment found\nthat the ASR of ICT returned to a high level, and the ACCwas not affected.\nNumber of Classes: According to the above experiments,\nit is sufﬁcient to prove the superiority of our method in allaspects. But Hidden Trigger can only be attacked in the setting\nof binary classiﬁcation, so we are extremely curious about\nthe performance of our method in multi-class tasks. However,since the datasets we previously used had a maximum of only\n100 labels, we conducted tests using the ImageNet dataset\nin this case. We are aware that this does not strictly adhereto the conditions of transfer learning, but we believe it still\nholds persuasive power as we only modiﬁed the weights of\nthe ﬁnal layer. We divided the experiment into two groups. Weﬁrst tested our method against Hidden Trigger [26] using the\nAlexNet m"}
{"[-0.075022586, 0.14037198, -0.035646804, 0.025512109, 0.046704512, -0.02493984, -0.030680988, -0.025973616, -0.07085056, 0.035739105, -0.0420156, 0.038212784, -0.0069410657, -0.038360465, -0.0013914437, -0.0721797, 0.016817316, 0.022853829, -0.04803365, 0.050470408, 0.028927261, 0.040538777, 0.04389855, 0.07642557, -0.058445252, -0.07561331, -0.055676207, 0.071109004, 0.016946537, 0.014795915, -0.0099870125, 0.10101466, 0.07760702, -0.034022298, 0.04659375, 0.041757155, -0.014537471, -0.06420486, 0.051393423, -0.029038023, -0.014297488, -0.030754829, 0.020841658, -0.01578354, 0.037142087, 0.024201429, 0.031364016, -0.037640512, -0.011288462, 0.0590729, -0.007887155, -0.011048478, 0.028391913, 0.00018114151, 0.017804941, 0.01573739, -0.030367162, -0.017472656, 0.053350214, 0.02565979, -0.014242107, 0.028096547, -0.03202859, -0.052944086, 0.044193912, -0.003112865, -0.017426506, -0.060217436, 0.0023352257, -0.015580477, 0.01509128, -0.027191995, -0.01973404, -0.032453176, 0.05704227, 0.0432709, 0.029776433, 0.004850439, 0.042458646, 0.018820256, 0.00021820629, 0.0023548396, 0.018008005, 0.026601266, -0.016226588, -0.046446066, -0.009013233, -0.033708476, -0.004645068, -0.014805146, 0.04515385, -0.0043958547, -0.046150703, 0.010393138, 0.025973616, -0.004432775, -0.046298385, -0.013891362, -0.005759608, 0.06749079, -0.013097569, 0.03225011, -0.040907983, -0.004298938, -0.0035328364, -0.025272125, 0.021377007, 0.0157097, -0.023703001, -0.041720238, -0.040428016, -0.033856157, 0.020915499, -0.042274043, 0.019918643, 0.026748948, 0.021930814, -0.020675516, 0.0003380539, -0.0032443944, 0.03481609, -0.041646395, 0.035776027, -0.031400938, -0.0025359811, 0.03461303, 0.010799265, 0.025179824, -0.0053350213, 0.01053159, 0.04903051, -0.018257217, -0.017888013, 0.033837695, 0.0015864305, 0.004938125, 0.013872901, -0.0034336124, 0.020897038, 0.014177496, -0.040834144, -0.0063411067, 0.04064954, -0.0044420054, 0.014057504, -0.03274854, 0.014408249, -0.0027528894, 0.017435735, 0.025069062, -0.03740053, 0.018257217, -0.006105738, 0.010042393, -0.010014703, -0.016688094, -0.0012299162, -0.0015633551, -0.01905101, -0.019475596, -0.062691115, -0.018921789, 0.034576107, -0.014528241, 0.014159036, -0.039098877, 0.0029051867, 0.022263099, -0.0022163875, 0.028447293, -0.0035420666, 0.0037982028, 0.020620134, 0.051024217, 0.011445374, 0.010808495, 0.0125253005, 0.020029405, -0.007850234, -0.031197876, -0.011934572, 0.010670043, 0.008080988, -0.006105738, -0.003975883, -0.016161976, 0.0144636305, 0.031936288, 0.010162385, -0.021838512, -0.0013764447, -0.0141498055, -0.0459661, -0.0049935062, 0.013051419, -0.0010055085, 0.023979906, 0.0016360425, 0.018700264, -0.042754013, -0.029850274, -0.019530978, 0.008810169, 0.016466571, -0.017768022, -0.009253216, -0.0015887379, 0.019272534, 0.026619725, 0.020564754, 0.020140167, 0.010263916, -0.019143311, 0.041646395, -0.045449212, 0.007033367, 0.0074441084, 0.0063687973, 0.025752092, 0.011593057, -0.024626015, -0.034317665, 0.0117407385, 0.010356218, 0.02174621, -0.018811027, 0.00922091, 0.008588646, -0.035886787, 0.012792975, -0.023887604, -0.061361976, -0.019567898, -0.007914846, 0.019844802, -0.02822577, -0.030477924, 0.017638799, 0.02626898, -0.029499529, -0.0013176026, 0.03994805, -0.0025752094, 0.022263099, 0.013171411, 0.021801593, 0.017851092, 0.019955564, -0.02558595, 0.029942576, 0.0080625275, -0.009363978, -0.025124444, 0.04268017, -0.008030223, 0.00853788]": "ve it still\nholds persuasive power as we only modiﬁed the weights of\nthe ﬁnal layer. We divided the experiment into two groups. Weﬁrst tested our method against Hidden Trigger [26] using the\nAlexNet model, and the second group was compared with the\ncurrent excellent methods, Invisible Trigger [30] and ATTEQ\n[28] with ResNet-18 model.\nAs shown in Table IV, with the continuous increase of the\nnumber of classes, the ACC of the model continues to decline,\nwhich is in line with common sense. However, because Hidden\ntrigger [26] could not complete the attack under multiple\nclassiﬁcation tasks, the ASR of the model was very low, with\n8.32% ASR for the task with 100 classiﬁcation tasks andTABLE V\nACCURACY (ACC) AND ATTACK SUCCESS RATE(ASR) OFDIFFERENT\nNUMBER OF CLASSIFICATIONS UNDER RESNET-18 M ODEL\nonly 1.27% ASR for the task with 1000 classiﬁcation tasks.\nOur approach can perform well on a variety of classiﬁcation\ntasks, with ASR achieving 98.4%, 98.35%, and 98.87% on the\n100/500/1000 class "}
{"[-0.112400606, 0.14581305, -0.01421494, 0.006951765, 0.057006307, -0.028649699, -0.045355916, -0.04172891, -0.022531413, 0.033449072, -0.02678124, 0.07708308, -0.02174373, -0.041985366, -0.0010292551, -0.0706717, 0.026616376, 0.027678832, -0.033412438, 0.04550246, 0.040409997, 0.023429006, 0.04275473, 0.09261693, -0.049605746, -0.06620205, -0.043560732, 0.07015879, 0.01586358, 0.042937912, -0.008650781, 0.10881024, 0.09100492, -0.027862016, 0.014498873, 0.028466517, -0.012996779, -0.06792397, 0.06777742, -0.06462669, -0.020644637, 0.009617067, 0.03224007, -0.0020836978, 0.067850694, -0.030554794, 0.042205185, -0.0047718966, -0.03583044, 0.05184057, -0.00484517, 0.012456391, 0.046015374, 0.0140775535, 0.01947227, 0.00834395, 0.0007298667, -0.029235883, 0.04612528, 0.051254384, -0.016880242, 0.0056878077, 0.011503844, -0.07129452, 0.022439823, 0.03366889, -0.01760381, -0.029657202, 0.030206747, -0.006296889, 0.04132591, -0.03605026, -0.035152666, -0.053928845, 0.04850665, 0.020901091, -0.0019760781, -0.006924288, 0.042022, -0.005316864, 0.03964063, -0.02646983, 0.0048680673, 0.0247296, -0.041179363, -0.039274268, 0.0047947946, -0.028722972, 0.007757767, -0.020681273, 0.023520596, 0.010148295, -0.04019018, 0.0204065, 0.044806372, -0.009406407, -0.04114273, -0.020369863, 0.007808142, 0.029474018, -0.025572238, 0.022274958, -0.02689115, 0.007890574, -0.0086324625, -0.035903715, 0.014004281, -0.015643762, -0.020553045, -0.0620255, -0.0114397295, -0.017301561, 0.029638883, -0.017145855, 0.010139136, 0.025187556, 0.022293275, -0.034255076, 0.03028002, 0.001966919, 0.009090418, -0.0502652, 0.040922906, -0.048360106, -0.018364018, 0.03658149, -0.01546058, 0.017136697, 0.00906752, 0.022989368, 0.0327713, -0.022201685, 0.0057748193, 0.018592995, -0.0108810235, 0.013537166, 0.008504234, 0.0010424213, 0.032258388, 0.0062236157, -0.03698449, -0.003143865, 0.041362546, -0.004151367, 0.024180053, -0.041838817, 0.021011, 0.018006813, 0.014242417, 0.024033507, -0.036947854, 0.014361486, 0.029620565, 0.0045062825, -0.00048629154, -0.01804345, -0.0010887893, -0.011073365, -0.011091683, -0.017860265, -0.07286989, -0.020351544, 0.02337405, -0.01938068, -0.004309362, -0.051913843, 0.0011654969, -0.0014379804, -0.028484834, 0.0050420905, 0.000700672, -0.024363235, 0.016926037, 0.049788926, 0.016449763, 0.018290745, 0.016229944, 0.0068876515, 0.004501703, -0.02214673, -0.013619598, 0.01606508, 0.020974364, -0.00036922665, 0.012648732, 0.019618815, -0.0074967323, 0.038285084, -0.005069568, -0.029107654, 0.004561237, -0.011769458, -0.021670457, 0.0088339625, 0.01791522, -0.0067823217, 0.018464768, -0.0016520746, 0.013573802, -0.017017629, -0.03495117, 0.01864795, -0.007698233, -0.0045383396, -0.032496527, 0.010633728, 0.018153358, 0.028155107, 0.011430571, 0.027678832, -0.012135822, 0.02914429, -0.018418971, 0.036434945, -0.006851015, 0.0042933333, -0.0048039537, -0.0052390113, 0.044220187, -0.0028576427, -0.034749668, -0.01813504, -0.01576283, -0.0056832284, 0.021285774, -0.014343168, -0.00886144, 0.020351544, -0.043707278, 0.011769458, -0.0056923875, -0.0691696, -0.003008768, -0.0036453262, 0.027330788, -0.037991993, -0.026726285, 0.0038399573, 0.012923505, -0.011210752, -0.0016245974, 0.032588117, 0.0105055, 0.01153132, 0.00036035376, 0.02007677, 0.035152666, 0.018080086, -0.034969486, 0.011467207, 0.0026080569, -0.017228289, -0.02720256, 0.03553735, -0.009534635, 0.02381369]": "EL\nonly 1.27% ASR for the task with 1000 classiﬁcation tasks.\nOur approach can perform well on a variety of classiﬁcation\ntasks, with ASR achieving 98.4%, 98.35%, and 98.87% on the\n100/500/1000 class classiﬁcation tasks, respectively. This is abreakthrough step up from previous work.\nA ss h o w ni nT a b l e V, by comparing the second and fourth\ncolumns (num_class =200), it can be found that our method\nand Invisible Trigger [30] have similar ASR, both reaching\n99.5%. But the ACC for our method is 6% lower, and we\nthink there are two main reasons for this. First, although they\nare all ImageNet’s 200 labels, the data sets are not exactly the\nsame, which can still affect the results. Second, the InvisibleTrigger method trains the entire model, and we only train the\nlast layer of the model. When the Invisible Trigger’s poisoning\nrate(PR) also dropped to 0.1% (num_class =200), the ASR of\nthe poisoned model dropped sharply, to 60%. Compared to\nthis, our ASR is 99.5% under the same poisoning "}
{"[-0.07347122, 0.119192384, -0.0051339446, 0.02321115, 0.040665638, -0.03033317, -0.07860055, -0.05018627, -0.03544405, -0.02081254, -0.02016676, 0.08206931, -0.017906534, -0.061515078, 0.0008971718, -0.062917344, -0.010046479, 0.008284424, -0.023617066, 0.055906024, 0.07324981, 0.020720286, 0.019908449, 0.10494834, -0.03232586, -0.09616575, -0.043027345, 0.06693962, -0.006171804, 0.01704857, -0.04797217, 0.07579602, 0.09129472, -0.015074331, 0.02946598, 0.04073944, -0.029263021, -0.09365643, 0.00974204, -0.055204894, -0.049558938, 0.014797568, -0.0038008718, -0.019945351, 0.010461623, -0.015203487, -0.008076852, -0.0464961, -0.035241093, 0.04941133, -0.021439869, 0.023063542, 0.03144022, -0.0045227604, 0.010507749, 0.019668588, -0.0076617086, -0.013432207, 0.057935618, 0.04029662, -0.017998789, 0.0052077477, -0.021771984, -0.04561046, 0.02963204, 0.013164669, 0.01227903, -0.04254762, -0.004716494, 0.0050370777, 0.022288607, -0.029336825, -0.034503058, -0.05645955, 0.031735435, 0.02880175, 0.0019753925, -0.022510016, 0.032381214, -0.001439165, 0.029502884, -0.0021829642, 0.03472447, 0.030167112, -0.057271387, -0.030370072, 0.008681118, -0.007384946, -0.0028921682, 0.005438383, 0.036551103, -0.0031297226, -0.029484432, -0.00029953776, 0.026310889, -0.012906358, -0.0254437, -0.027122725, 0.007486426, 0.055610813, -0.032879386, 0.05003866, -0.029189218, 0.0035402537, 0.0007610969, -0.064245805, 0.03125571, -0.04044423, -0.044651017, -0.021716632, -0.009677462, -0.05003866, -0.001136456, -0.011836209, 0.02238086, 0.027750054, 0.02036972, -0.02012986, -0.006799132, -0.0051985225, 0.025499051, -0.03073909, 0.05180994, -0.049743447, -0.0038469988, 0.030720638, -0.019281121, 0.009788167, 0.026513848, 0.019982252, 0.04697582, -0.007887731, -0.032657977, 0.022842132, 0.007417235, -0.0058258506, 0.003138948, -0.006453179, 0.035942223, 0.011937689, -0.049079217, -0.017463714, 0.06062944, -0.016965542, 0.031071203, -0.022676075, 0.023746222, 0.032787133, 0.0022902098, -0.0045296797, -0.026255537, 0.012039169, 0.010913668, 0.000312511, -0.015784688, -0.022860583, -0.0002394284, -0.017878858, -0.008238297, -0.015738562, -0.07369263, -0.0027837695, 0.015554053, -0.015507925, 0.0059457812, -0.05269558, -0.0025231515, 0.015046655, -0.029687392, 0.00912855, 0.0029290698, -0.011873111, 0.02125536, 0.05778801, 0.0126019195, -0.014114887, 0.013293825, 0.005124719, 0.0153787695, -0.0059919083, -0.024373552, 0.01527729, -0.010692258, -0.00054516445, 0.0047372514, -0.0008297109, -0.015424897, 0.059374783, 0.01505588, -0.005696695, -0.0016582686, -0.002760706, -0.028229775, -0.010092606, 0.016661102, -0.0017378379, 0.0035333347, 0.004146825, 0.020388171, -0.005645955, -0.048156675, -0.004963274, 0.0011612494, -0.009170065, -0.024982428, -0.000703438, 0.011540996, 0.0109044425, -0.0078508295, 0.015185036, -0.0032842483, 0.0070482185, 0.00020180599, 0.038451537, -0.0041237613, 0.014982076, -0.013395305, -0.00072246545, 0.043949887, -0.0035333347, -0.0276947, -0.02880175, -0.0028022204, 0.0063194106, 0.000654428, -0.046828214, -0.01018486, 0.017002443, -0.038008716, -0.00060311164, 0.006042648, -0.06483623, 0.019668588, -0.017565193, 0.006213318, -0.011863886, -0.028192874, -0.0023686257, 0.017602095, -0.0027514806, -0.026089478, 0.016458144, 0.010821414, 0.0059088795, 0.0036486522, 0.031809237, 0.028063718, 0.016688779, -0.03747364, 0.02787921, -0.012371284, -0.026606102, -0.020259015, 0.03765815, -0.007670934, -0.00020022037]": "en the Invisible Trigger’s poisoning\nrate(PR) also dropped to 0.1% (num_class =200), the ASR of\nthe poisoned model dropped sharply, to 60%. Compared to\nthis, our ASR is 99.5% under the same poisoning rate which\nmeans that we can complete the attack successfully. When wecompare ATTEQ in ten labels (num_class =10), our poisoning\nrate at this point is about 3.8%. Our method can maintain the\nASR of 99.5%, while the ASR of ATTEQ can only achieve88.82% under 5% PR.\nWe attribute the excellent performance of ICT to the use\nof computable triggers and the generation of unseen pertur-bations. A computable trigger can cause a neuron to produce\na larger activation value, and an invisible perturbation can\nmake the trigger more hidden. Both techniques make backdoorsamples more covert and efﬁcient.\nD. Defense Experiment\nA qualiﬁed attack method not only has excellent attack\neffect but also needs to be able to successfully bypass\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on M"}
{"[-0.054619793, 0.117937475, -0.01380237, 0.014088, 0.022924097, -0.012973122, -0.07138903, -0.025301274, -0.0607378, 0.019846667, -0.045737628, 0.10275303, -0.031363998, -0.0725684, -0.011286985, -0.088158265, 0.0071960287, 0.003151142, -0.012365007, 0.100173146, 0.043968566, 0.013332463, 0.033040922, 0.12796216, -0.061732896, -0.07470602, -0.048686065, 0.084546424, -0.014954103, 0.007325023, -0.04717499, 0.11189318, 0.0924335, -0.016004484, 0.04636417, 0.028820971, -0.020952329, -0.09464482, 0.020307358, -0.035676084, -0.035768226, 0.024951147, -0.0026144343, 0.013830012, 0.040319875, -0.008817669, 0.010485379, -0.05749452, -0.033022493, 0.048354365, -0.004915597, 0.045332216, 0.04028302, 0.028452415, -0.025798824, 0.020233648, -0.0023679633, -0.017718263, 0.022997808, 0.018501442, -0.012171516, 0.01258614, -0.011581829, -0.004242985, 0.030497894, 0.041425537, -0.020104654, -0.063759945, 0.0012565409, -0.011664754, 0.02183686, -0.040872708, -0.00062020833, -0.017635338, 0.026075238, 0.02021522, 0.030258333, -0.030866448, 0.03530753, -0.006247001, 0.03792427, 0.0035404277, 0.030497894, 0.058637038, -0.060148112, -0.037610997, -0.0072835605, -0.03208268, 0.008739351, 0.009997044, 0.0384771, -0.0038421818, -0.05174507, 0.01737735, 0.023292651, -0.011498904, -0.050565694, -0.006062723, -0.013314036, 0.03492055, -0.013995862, 0.02581725, -0.03565766, -0.009163189, 0.011517332, -0.03840339, 0.027254613, -0.032266956, -0.033667464, -0.038587667, 0.008624177, -0.03492055, 0.033704318, -0.0006323015, 0.01923855, -0.0048971693, 0.0015271981, -0.010255032, 0.018943707, -0.010881575, 0.0116094705, -0.02955808, 0.04562706, -0.020252075, -0.013295608, 0.01742342, 0.0055974233, 0.017358921, 0.028139144, 0.024250893, 0.06235944, -0.008218768, -0.02695977, 0.03315149, -0.009683772, 0.0013924454, -0.0086103575, -0.0061825034, 0.015746497, 0.008674854, -0.052592743, -0.0014016592, 0.062727995, -0.004595415, 0.034146585, -0.034625705, 0.013185041, 0.03501269, 0.0061318274, 0.0018842354, -0.04507423, 0.013212683, 0.012927053, 0.005215048, -0.009333646, -0.028968392, 0.006012047, -0.026849203, -0.011462049, 0.0023011628, -0.05944786, -0.017920967, 0.03344633, -0.017745905, -0.0044526006, -0.0445214, 0.012070163, 0.0069564683, -0.012834914, 0.011121135, 0.0020305056, -0.017008794, 0.027789017, 0.030571604, 0.018298736, -0.018344807, 0.01368259, 0.02485901, 0.000104087885, -0.015516149, -0.022113277, 0.024822153, -0.02517228, -0.011111922, 0.0049294177, -0.0033008673, -0.0025176888, 0.05148708, 0.019293834, -0.022592397, -0.005555961, -0.011756892, -0.018842354, -0.0019487325, 0.0030405754, 0.00020400074, 0.016760021, -0.010181321, 0.021947427, 0.002589096, -0.03044261, 0.0019855879, 0.0026305586, -0.009831194, -0.00848597, 0.006362174, 0.016852159, 0.031327143, -0.0021525894, 0.02428775, -0.010595945, 0.0065786997, -0.019054273, 0.05016028, 0.014861965, 0.013332463, -0.0004808486, -0.0026397724, 0.037739992, -0.020768052, -0.01079865, -0.039029934, -0.0077534677, -0.018317165, 0.020252075, -0.020399498, -0.002494654, 0.008794635, -0.05384583, 0.012549285, -0.0071131038, -0.05237161, 0.00027612803, 0.008435294, -0.00010559953, -0.006974896, -0.021818433, 0.0024462813, 0.024398316, -0.023550639, -0.02143145, 0.030110912, 0.022150133, 0.0111764185, -0.0024485847, 0.009361288, 0.034607276, 0.010291887, -0.021136606, 0.021818433, -0.005058412, -0.0011839817, -0.020860191, 0.039582767, 0.0053578625, 0.012862556]": "ense Experiment\nA qualiﬁed attack method not only has excellent attack\neffect but also needs to be able to successfully bypass\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. CHEN et al.: ICT BACKDOOR ATTACKS IN TRANSFER LEARNING 6755\nFig. 9. The output results under the heatmap of Grad-CAM. Note that in our\nmethod and Hidden Trigger, the target class and poison class are the sameclass.\nadvanced backdoor defense strategies. In this section, we test\nwhether ICT can bypass these detection methods, includingSentiNet [49], Neural Cleanse [45], STRIP [47], and NAD\n[50]. In addition to these detection methods, we also use\ntwo indicators used in an invisible trigger, PSRN [51] and\ninﬁnite norm, to visually evaluate the concealment of poisoned\nimages. We randomly select 10 classes for testing.\nSentiNet [49]:It takes advantage of the neural network’s\nsensitivity to attacks - when clean and poisoned images"}
{"[-0.047731932, 0.113109544, 0.0067371055, 0.022629293, 0.010253321, -0.009634984, -0.065636024, -0.0274837, -0.03615888, 0.0060264794, -0.082395725, 0.0759724, -0.036841817, -0.040976368, -0.0120252725, -0.10535726, 0.00047038612, -0.019306883, -0.02552717, 0.086087294, 0.043560464, -0.012735899, 0.0205251, 0.10653856, -0.063051924, -0.06833086, -0.06294118, 0.088006906, 0.024973435, 0.05463516, -0.040607214, 0.112445064, 0.06929067, 0.008965888, 0.061686046, -0.013225031, -0.045110922, -0.05799448, 0.025010351, -0.04869174, -0.029366398, 0.023607558, -0.021152666, 0.01943609, 0.03425772, -0.011489996, 0.011499224, -0.06722339, -0.02892341, 0.090886325, 0.014046404, 0.011259273, 0.008735165, -0.027040713, -0.024308953, 0.012163706, -0.014092549, -0.045258585, 0.030492324, 0.0021837912, -0.009681129, 0.011646887, -0.037875455, -0.0040745647, 0.015652236, 0.028480422, -0.006649431, -0.048322584, 0.01943609, 0.0012908941, 0.024161292, -0.045553908, 0.0021030384, -0.007073961, 0.027852856, 0.040570296, 0.031525962, -0.034645334, 0.05116509, -0.019343799, 0.023699846, 0.0032924144, 0.039462827, 0.062055204, -0.034294635, -0.035531312, -0.012643609, -0.023256859, 0.001285126, 0.0009500011, 0.027391411, -0.0037192516, -0.03698948, -0.0007204319, 0.004584462, -0.029200278, -0.048728656, -0.02231551, -0.017977921, 0.017331896, -0.02434587, 0.01501544, -0.037487842, -0.01568915, 0.007876877, -0.02189098, 0.0056111785, -0.028960325, -0.029366398, -0.048138004, 0.002734065, -0.03658341, 0.0178118, -0.017525705, -0.0028794205, -0.0010440206, 0.012597465, -0.018254789, 0.010714767, -0.013594187, 0.01289279, -0.009634984, 0.0259517, -0.029163362, -0.01865163, 0.04725203, 0.022573918, 0.0076876837, 0.020155944, 0.027557531, 0.042895984, -0.035143696, -0.033242542, 0.021263413, -0.002175716, 0.0174611, 0.016888909, 0.0077661294, -0.0018630866, 0.006557142, -0.057366915, -0.0073323706, 0.04503709, -0.004556775, 0.04311748, -0.004434492, 0.013428067, 0.0128374165, 0.014277127, 0.016805848, -0.053306196, 0.008070683, 0.029569434, -0.01738727, 0.014738573, -0.019343799, 0.0045290887, -0.034792997, -0.02672693, 0.005841901, -0.060430914, 0.0006044937, 0.02637623, -0.012782043, -0.0135665005, -0.044852514, -0.008518286, 0.007221624, -0.034460757, 0.017516475, -0.013105055, -0.01984216, 0.025176471, 0.027243748, 0.02536105, -0.013677248, 0.02179869, 0.02670847, 0.0018896197, -0.021429533, -0.01687968, 0.0057726842, -0.006437166, -0.0028009748, 0.00089578127, 0.0042568357, 0.010188719, 0.03876143, 0.016621271, -0.02790823, -0.01611368, -0.00865672, -0.025084183, 0.009930309, 0.009727273, -0.007839961, 0.0152738495, -0.00011918275, 0.024069002, -0.012237538, -0.01925151, 0.012320598, -0.004046878, -0.023090737, -0.027557531, -0.018891582, 0.018448595, 0.011176213, 0.00496054, 0.0030040108, -0.014609368, 0.008449069, -0.021466449, 0.054745905, -0.0018873125, -0.0021803305, -0.009847249, -0.0055696485, 0.03604813, -0.02637623, -0.03470071, -0.012329826, -0.016095223, -0.01638132, 0.021909436, -0.027834399, -0.017267294, 0.023533726, -0.047953427, 0.026653098, 0.003996119, -0.045923065, -0.0031424444, -0.025804037, 0.007240081, -0.017968692, -0.029957049, 0.012246766, 0.026025532, -0.018808523, -0.022610834, 0.03580818, 0.0104009835, 0.017027343, 0.0058880458, -0.0042868294, 0.017793342, 0.01645515, -0.030750735, 0.020765051, 0.013474211, -0.02824047, -0.03420235, 0.047731932, -0.00949655, -0.0027479085]": "evaluate the concealment of poisoned\nimages. We randomly select 10 classes for testing.\nSentiNet [49]:It takes advantage of the neural network’s\nsensitivity to attacks - when clean and poisoned images\nare fed into the model, different heat maps are obtained\nto defend against backdoor attacks. We used the commonvisualization tool Grad-CAM [52] to generate heat maps to\nhelp us understand which areas the model is more concerned\nabout when poisoned data is fed into the model. Among\nthem, the heat maps of clean pictures, trojan, and our method\nare obtained under the ten-class model, while the heat mapsof Hidden triggers are obtained under the two-class model.\nAs shown in Figure 9, the trigger generated by trojan was\nsuccessfully identiﬁed by the Grad-CAM. Although the triggerof Hidden Trigger is invisible and cannot be identiﬁed by the\nheat map, there is a big gap between the heat map of the\npoisoned picture generated by it and that of the clean picture,which increases the possibility of th"}
{"[-0.036358014, 0.118227884, -0.0029570756, 0.011414725, 0.0254212, 0.008046371, -0.051871747, -0.01942893, -0.045438327, -0.017940052, -0.06495916, 0.087935664, -0.007775248, -0.046908826, -0.0068240208, -0.10396407, -0.029795926, -0.00719624, 0.0072467886, 0.08771509, 0.017554047, 0.008198015, 0.03126642, 0.10866966, -0.06973828, -0.062201984, -0.06731196, 0.07889211, 0.004200104, 0.066098794, -0.052606996, 0.10661096, 0.06624585, 0.011083864, 0.048563134, -0.012728982, -0.031744335, -0.09389117, 0.0027548824, -0.07227488, -0.017287519, 0.0036394778, -0.01821577, 0.018785587, 0.021910392, -0.01499906, 0.02264564, -0.06955446, -0.036358014, 0.09830266, 0.011139007, 0.03996073, 0.03227739, 0.010321044, -0.0037474674, -0.029759165, -0.008933264, -0.04407812, 0.02801295, 0.023105169, -0.021138381, 0.028325431, -0.023674987, -0.009980992, 0.037607938, 0.013730757, 0.0072835507, -0.046577964, 0.01743457, -0.00062553526, 0.024483759, -0.03610068, -0.01423624, 0.0047055874, 0.03292073, 0.036339633, 0.009392793, -0.027663708, 0.075657025, 0.012122402, 0.004866423, -0.0043977024, 0.040291592, 0.048746943, -0.049849816, -0.023141932, -0.020586945, -0.02742475, -0.0035889295, -0.016432794, 0.034979425, -0.011093055, -0.04562214, 0.010137232, 0.0062955613, -0.02266402, -0.025366057, -0.0300165, -0.022314778, 0.022755926, -0.021101618, 0.023711748, -0.018712062, -0.009411175, 0.005178903, -0.047680836, 0.038821097, -0.015725117, -0.009539844, -0.043269347, 0.0007507572, -0.029354777, 0.012728982, -0.027792376, 0.0141259525, 0.0060703917, 0.0070354044, -0.019061305, 0.022682402, -0.0033407833, -0.003526893, -0.022572115, 0.041100364, -0.04558538, 0.0030122192, 0.053158432, 0.024244804, 0.022719163, 0.01759081, 0.02940992, 0.037405744, -0.021800105, 0.0015899739, 0.031873003, 0.0014360313, 0.006001462, -0.019723028, -0.0081336815, 0.019006161, 0.010789765, -0.062201984, -0.029906213, 0.054445118, 0.010247519, 0.027516657, -0.022222871, -0.0034257963, 0.016322507, 0.005004282, 0.016101932, -0.05238642, 0.0061025587, 0.015054204, -0.02494329, -0.0012303917, -0.023362506, 0.018776396, -0.04242381, -0.02817838, 0.014245431, -0.042534098, -0.00887812, 0.027204176, -0.0031753525, -0.02343603, -0.03317807, 0.0051972847, 0.011074673, -0.04290172, 0.008868929, -0.0039956137, -0.024594046, 0.021836866, 0.03687269, 0.009346841, -0.014870391, 0.014815248, 0.006470183, 0.015146109, -0.01759081, -0.017655144, -0.0020529504, -0.011865065, 0.0056568147, -0.004266736, 0.010991958, 0.0053075715, 0.02799457, 0.011993733, -0.039409295, -0.0056430288, -0.006341514, -0.053048145, 0.0002386684, 0.005601671, 0.004209295, 0.010265901, 0.0067550912, 0.0152563965, -0.00054396864, -0.028913628, 0.013767519, -0.0020081461, -0.016414413, -0.011883446, -5.412043e-06, 0.008556449, 0.008450757, 4.3870758e-05, 0.0058544124, -0.010854099, 0.00012816579, -0.014291383, 0.036302872, 0.005371906, 0.0070813578, 0.004907781, -0.0061622974, 0.040990077, -0.022516971, -0.015045013, -0.013638851, -0.002364282, -0.010946005, -0.011984543, -0.017361045, 0.017793002, 0.01330799, -0.039850444, 0.007632794, 0.011718015, -0.0646283, 0.006782663, -0.009379008, 0.0047974936, -0.008331279, -0.029189346, 0.0013085117, 0.008735666, -0.025237389, -0.023013264, 0.008101515, -0.0012315405, -0.0064518014, -0.006245013, 0.019502454, 0.015559686, 0.020531802, -0.023546318, 0.02755342, 0.009149243, -0.0124165015, -0.030273838, 0.034685325, -0.008547259, -0.013785901]": "s invisible and cannot be identiﬁed by the\nheat map, there is a big gap between the heat map of the\npoisoned picture generated by it and that of the clean picture,which increases the possibility of the attack being discovered.\nIn contrast, our method shows that not only the trigger is\ninvisible and cannot be recognized by the heat map, but alsothere is a high similarity between the heat map of the poisoned\nimage and that of the clean image.\nNeural Cleanse [45]:For a backdoor model, assume\nthat class A is the target class of the attacker. The order\nof magnitude of disturbance required for all classes to be\nmisclassiﬁed as Class A is much smaller than that requiredfor all classes to be classiﬁed as other classes. The defender\niterates over each label, calculates the disturbance required for\neach label to be a target label, and then detects if there is\na disturbance order of magnitude that is signiﬁcantly smaller\nthan the others (threshold 2) based on Median AbsoluteDeviation(MAD) [53]. I"}
{"[-0.029334279, 0.10930135, -0.008347342, 0.0015741365, 0.06424896, -0.022042563, -0.05911499, -0.044754773, -0.04728455, 0.017624749, -0.0648814, 0.07745589, -0.0073335697, -0.043973517, -0.015969232, -0.10461382, -0.06104953, 0.045833647, -0.011179392, 0.06618349, 0.060565893, 0.033370767, 0.0066825235, 0.10565549, -0.0451268, -0.0874262, -0.063802525, 0.07671184, -0.00902164, 0.06450937, -0.03286853, 0.08571488, 0.07886959, 0.006375602, 0.04471757, -0.03284993, -0.03134322, -0.070871025, 0.018703626, -0.039174378, -0.007928812, -0.005757108, 0.011021282, 0.023791086, 0.05107922, 0.0014543906, 0.01255589, -0.067373976, 0.0028297256, 0.04159255, -0.009579679, 0.048140213, -0.002361205, 0.023214446, 0.016201748, 0.009681987, -0.017810762, -0.037723474, 0.04077409, 0.010351634, -0.047991402, 0.00037754863, -0.0061012325, -0.018871037, 0.02174494, 0.03370559, -0.01637846, -0.07946483, 0.054092634, -0.017736357, -0.003345912, -0.023865491, 0.0062267915, 0.0022286705, 0.044271138, 0.017271325, 0.013755675, -0.042931844, 0.06320728, -0.017438736, 0.02907386, 0.014146303, 0.011783935, 0.022098366, -0.042634223, -0.017141115, -0.028534422, -0.012937217, 0.001475317, 0.009077444, 0.0066360203, -0.015439094, -0.04203898, 0.004699158, 0.040662482, -0.0578129, -0.017150415, -0.037556063, -0.0011730456, 0.06052869, -0.007268465, 0.052083693, -0.038430326, -0.029352881, 0.014936859, -0.018312998, 0.030729378, -0.023195844, -0.012351275, -0.024888564, 0.001397424, -0.031287417, 0.02286102, 0.009472721, 0.028013585, 0.008314789, 0.0040574125, -0.023121439, -0.0008905381, -0.029799312, 0.0070498995, -0.023344655, 0.045759242, -0.037574664, -0.0034668208, 0.042708628, -0.0025786078, 0.012760504, 0.02877624, -0.004699158, 0.05204649, -0.0018310673, -0.00058041926, 0.023381857, -0.006505811, 0.015355389, -0.00041416998, 0.000694643, 0.031901263, 0.010835268, -0.049330696, -0.010481843, 0.05245572, 0.008365943, 0.024200315, -0.027455546, 0.006403504, 0.034933276, 0.002375156, 0.021558927, -0.032942936, 0.0009806383, 0.017531743, -0.0013276691, -0.0064174547, -0.012118759, 0.025725624, -0.061309945, -0.0006597655, -0.0063477, -0.039397594, -0.007366122, 0.020666065, -0.017429436, -0.0055664447, -0.039099973, 0.018526914, -0.0041643702, -0.031957064, 0.019289568, -0.004559648, -0.007989266, 0.016173847, 0.036625996, 0.011514216, -0.013988191, 0.0039458047, 0.0026832402, -0.02185655, 0.0023426036, -0.029706305, 0.020201031, -0.015085669, -0.0007986941, 0.013597564, -0.0018682699, 0.018145585, 0.04561043, 0.019866208, -0.023437662, -0.010351634, -0.009737791, -0.04274583, -0.004145769, 0.018954743, 0.031157209, 0.022768013, -0.021763543, 0.023474865, -0.016694684, -0.032515105, -0.00078241795, -0.006673223, -0.015615807, -0.011914144, 0.0076962956, 0.014825251, 0.0042131986, 0.021354314, -0.002876229, -0.039397594, -0.008156678, -0.011960648, 0.05937541, -0.029166868, 0.003045966, 0.005617598, -0.0007934625, 0.028869247, -0.012286171, -0.031064201, -0.010556248, -0.003727239, -0.00959828, -0.0020589335, -0.010249327, 0.0069336416, 0.028255403, -0.061309945, -0.004529421, 0.016108742, -0.07407045, 0.0031087454, 0.0045363964, 0.016304055, 0.009951705, -0.019996418, -0.0004008003, -0.0044201384, 0.00550134, -0.024758356, 0.035361107, 0.008993737, 0.017931672, -0.0041085663, 0.023344655, 0.021949556, 0.01650867, -0.019791802, 0.0041387933, -0.011309601, -0.010509745, -0.00479449, 0.045498826, -0.0009969145, 0.0026344117]": "each label to be a target label, and then detects if there is\na disturbance order of magnitude that is signiﬁcantly smaller\nthan the others (threshold 2) based on Median AbsoluteDeviation(MAD) [53]. If yes, the label is considered to be\nattacked, that is, the network has a backdoor. As shown in\nFigure 10(a), Trojan has the lowest MAD value, followed by\nour method, and Hidden trigger has the highest. In the end,\nonly the Trojan attack was detected, and the “Anomaly Index”\nFig. 10. (a) MAD values of the three methods, and (b) anomaly index of\nthe three methods under the setting of threshold 2.\nFig. 11. The distribution of the entropy prediction results for the clean dataand the poisoned data for the four attack methods.\nfor both Hidden Trigger and ICT falls below the threshold., as\nshown in Figure 10(b). Our method has a higher value than\nthe Hidden Trigger, which we think is because we use a lowerorder of magnitude perturbation, which makes the poisoned\npicture look more similar to the "}
{"[-0.051529575, 0.12864016, -0.0060874363, 0.0407238, 0.022732554, -0.05388185, -0.032454077, -0.018763088, -0.018744709, 0.015197917, -0.06439359, 0.042451255, 0.0042933654, -0.019847339, 0.017357234, -0.091665305, -0.0076173353, 0.0073646493, -0.010640379, 0.06549622, 0.04083406, 0.01219325, 0.023394132, 0.08879847, -0.063842274, -0.09151829, -0.06884086, 0.10452932, 0.016052455, 0.07556691, -0.025838295, 0.10033933, 0.07229577, 0.00658362, 0.054910973, -0.02082133, -0.045171075, -0.058145355, -0.008862388, -0.044766776, -0.020288391, 0.006004739, -0.010327968, 0.015510328, 0.036791086, -0.037250515, 0.012156496, -0.04480353, -0.011256014, 0.06402605, 0.016245415, 0.03730565, 0.013718555, 0.026279347, -0.008830229, -0.017320478, -0.049434576, -0.01777072, 0.029881272, 0.01789936, -0.03351995, 0.034328546, -0.034604203, 0.001449499, 0.01426987, 0.031627104, -0.0012117444, -0.019553306, 0.047119055, -0.024864307, -0.002395923, -0.025139963, 0.0042474223, -0.012799696, 0.040356256, 0.053404044, 0.005747459, -0.00076035527, 0.052191153, 0.017026445, 0.012303513, -0.017972868, 0.029734256, 0.035780344, -0.061379734, -0.024680534, -0.0042014797, -0.023008212, -0.018560939, -0.009932858, 0.019608436, -0.01420555, -0.033428065, -0.0021007399, 0.0013013331, -0.009183989, -0.046457477, -0.027933292, -0.008439713, 0.035890605, -0.028117064, 0.032766487, -0.01809232, -0.005090475, -0.001694145, -0.033189163, 0.030506097, -0.021060232, -0.032270305, -0.03535767, -0.00447484, -0.050867997, 0.027014434, -0.016263792, 0.022401765, 0.0046723946, -0.0021868828, -0.008412148, 0.0047367145, -0.023963824, -0.023100099, -0.063143946, 0.03431017, -0.023743298, -0.012569982, 0.036680825, 0.0027290091, 0.04351713, 0.012992657, 0.034383677, 0.034475565, -0.01310292, 0.0087567195, 0.038812574, 0.015409254, 0.017320478, -0.0075392323, 0.00431404, 0.020949969, 0.021005102, -0.052117642, -0.034677714, 0.06509192, 0.0017320479, 0.033078898, -0.0074151866, 0.008049198, 0.013525594, 0.021115365, 0.001044627, -0.022089355, 0.007139529, 0.0371035, -0.0114214085, -0.013203994, -0.009455052, 0.018910104, -0.027970048, -0.0078057013, 0.0055499044, -0.06454061, -0.010346345, 0.026316103, -0.0005461464, -0.0098134065, -0.035229027, -0.005012372, 0.003167764, -0.04054003, 0.017228594, -0.007451941, -0.020012734, 0.024827551, 0.0333178, 0.0124780955, -0.0014701732, 0.024956191, 0.014766053, -0.020876462, -0.03618464, -0.036221396, 0.027087944, -0.015004956, -0.0031011468, -0.010383099, 0.01257917, -0.0250297, 0.064173065, 0.016649712, -0.016649712, -0.008752125, 0.00036151332, -0.029256448, 0.013645046, 0.02613233, 0.019112254, 0.0019330481, 0.0025796946, 0.029862896, -0.009675578, -0.044215463, 0.038298015, -0.010814962, -0.002377546, -0.033023767, 0.008595919, 0.008030822, 0.010622002, -0.00077643525, 0.0072865463, -0.0144168865, 0.0004192291, -0.015243859, 0.057042725, -0.019020367, 0.005623413, 0.009445864, -0.013369389, 0.017954491, -0.016934559, -0.04164266, -0.0057658358, -0.016741598, -0.012340267, 0.0134704625, -0.031039033, 0.015547083, 0.0028461637, -0.049581595, -0.004235937, 0.020582426, -0.028650003, -0.009868538, 0.0011164128, -0.0009481469, -0.017871793, -0.033630215, -0.008513222, 0.010015556, -0.013047788, -0.015969757, 0.012266759, 0.0076494953, -0.024312992, 0.016015701, 0.0009045011, 0.03184763, 0.025948558, -0.035964113, 0.024147596, 0.000910244, -0.010557682, -0.01913063, 0.0457959, -0.0146374125, 0.0024947003]": "Figure 10(b). Our method has a higher value than\nthe Hidden Trigger, which we think is because we use a lowerorder of magnitude perturbation, which makes the poisoned\npicture look more similar to the clean picture.\nSTRIP [47]:For a model with a backdoor, it is highly\nsensitive to the trigger, and once the trigger appears, it will\nbe misclassiﬁed regardless of which label the original imagebelongs to. STRIP uses this to detect whether an input sample\nis a poisoned sample. It makes several copies of an input\nsample, overlays each copy with other labels of pictures, andthe predicted distribution of these copies is used to detect\nbackdoor samples.\n3If the input sample is a clean image, then\nthe prediction results of the copied images should have a highentropy, because the copied images will be randomly classiﬁed\ninto various labels. For poisoned images, the existence of\ntriggers will cause these copied images to be mainly classiﬁedinto the label speciﬁed by the attacker, so the predicted r"}
{"[-0.05192941, 0.11528403, -0.024324635, 0.023734948, 0.03888256, -0.01763536, -0.07621719, -0.026591249, -0.027438926, 0.023532242, -0.07879708, 0.10201605, -0.014355221, -0.053182498, -0.033354234, -0.045737687, -0.007813368, 0.07441127, -0.014346006, 0.074632406, 0.039287973, 0.038514007, 0.033040963, 0.11218817, -0.06519739, -0.0782811, -0.05358791, 0.061769832, 0.01584787, 0.058084283, -0.008112819, 0.11764278, 0.08086099, -0.019422853, 0.022905698, -0.03152989, -0.06777728, -0.08181923, 0.02806547, -0.026793955, -0.019257003, 0.017985487, 0.0052749445, 0.018906876, 0.03134561, -0.040835902, 0.031235043, -0.051487144, -0.026738672, 0.038624573, -0.005445401, 0.050344624, 0.034865312, 0.037150353, -0.03316996, -0.00019766645, -0.003922808, -0.054767285, 0.0039343257, 0.00824642, -0.036044687, -0.015599094, -0.015405603, -0.02174475, 0.0020224461, 0.03149303, -0.012807289, -0.035178583, 0.05874768, -0.021560472, -0.008403056, -0.022610854, -0.0040448923, -0.02789962, 0.036155254, 0.01152656, 0.004252204, -0.016594192, 0.064718276, -0.020049397, 0.04717505, -0.010817092, 0.041425593, 0.022279155, -0.04529542, -0.018261904, -0.005790922, -0.01649284, -0.00044629717, -0.000525191, 0.007638304, 0.0004457213, -0.042899814, 0.014502643, 0.01592158, -0.035897266, -0.038698282, -0.03414663, -0.002196358, 0.052334823, -0.026720244, 0.028784152, -0.05867397, -0.01530425, 0.008435304, -0.0073895296, 0.018086841, -0.016299348, -0.05554125, -0.050823744, -0.00060523656, -0.014861984, 0.026738672, -0.017294448, 0.029631829, 0.007817974, -0.005219661, -0.007877865, 0.01870417, -0.018123696, 0.002179082, -0.05344049, 0.05948479, -0.024029791, 0.0031903049, 0.011213289, 0.025080174, 0.0118951155, 0.038440295, 0.013111347, 0.020639084, -0.022684565, -0.0040955683, 0.028268175, -0.005482257, -0.0007434447, 0.007804154, -0.001762154, 0.027420498, -0.0021836888, -0.061217, 0.002013232, 0.06261751, 0.0029138885, 0.036560666, -0.021155061, 0.001744878, 0.04201528, 0.027862765, -0.0003841035, -0.051671423, -0.018243477, 0.011452849, -0.015479313, 0.002108826, -0.012586156, 0.007974611, -0.013369336, -0.017828852, -0.024840612, -0.053219356, -0.014659278, 0.028599875, -0.012401879, 0.0009651536, -0.006836697, -0.011563416, -0.010549889, -0.04588511, 0.022776704, 0.013885313, -0.013654966, 0.031972155, 0.017534008, 0.023292681, 0.010190548, 0.032432847, 0.03136404, -0.016096644, -0.027678486, -0.013912954, 0.010853947, -0.012890214, -0.022463432, 0.0058001354, -0.008145067, -0.0021168883, 0.057236604, 0.016962748, -0.04102018, -0.0028309638, -0.007647518, -0.022039594, 0.0050630253, 0.019183293, 0.021542044, 0.0073112114, -0.029410696, 0.008103605, -0.010079982, -0.04735933, 0.0068827663, -0.019920403, -0.014346006, -0.017994702, 0.00018917241, 0.010513034, 0.026185839, 0.026204266, 0.006376003, -0.0029346198, 0.011849046, 0.010319542, 0.04850185, -0.016815325, -0.014152516, 0.0051920195, 0.005546754, 0.020159964, -0.024564195, -0.038034886, -0.03250656, -0.012669081, -0.004374288, 0.007030188, 0.014603995, 0.0021986614, 0.015884724, -0.03202744, -0.001115455, -0.013111347, -0.040467348, -0.0028263568, -0.0047543608, -0.008711721, -0.033575367, -0.026701815, 0.015737303, 0.0069426564, -0.006371396, -0.015903153, 0.03372279, 0.01566359, 0.0028885505, 0.0039826985, 0.004148548, 0.035233866, 0.011480491, -0.013922168, 0.024822185, -0.014908053, -0.014060376, -0.025890995, 0.036321104, -0.016787684, 0.008416877]": " randomly classiﬁed\ninto various labels. For poisoned images, the existence of\ntriggers will cause these copied images to be mainly classiﬁedinto the label speciﬁed by the attacker, so the predicted results\nwill have a lower entropy. As shown in Figure 11, the poisoned\n3We have repeatedly conﬁrmed with the author that the pixel value of the\noverlapped image needs to be limited to the interval of [0, 1]/[0, 255].\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6756 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nTABLE VI\nACCURACY AND ATTACK SUCCESS RATE(ASR) F OLLOWING THE\nUTILIZATION OF NAD ONTHREE DATASETS\nsamples of BadNet were successfully distinguished by STRIP,\nbecause the entropy distribution of the predicted results ofthese poisoned samples was obviously different from that of\nthe clean samples. For Hidden Trigger, there was a lot of\noverlap between poisoned data a"}
{"[-0.049508978, 0.13932025, 0.0003330602, 0.016222602, 0.043445144, -0.026011623, -0.053835005, -0.03423847, -0.017701585, -0.019226788, -0.033776287, 0.07195255, -0.041374568, -0.038601473, -0.013948664, -0.13015056, -0.057162717, 0.025715828, -0.023885585, 0.06962315, 0.044813205, 0.01596378, -0.008467182, 0.074208006, -0.032556128, -0.07439288, -0.036456946, 0.0633005, -0.005629381, 0.05461147, -0.0404502, 0.10463809, 0.08245333, -0.009872216, 0.059270266, 0.016971337, -0.034146033, -0.08311888, 0.01581588, -0.048140917, -0.024551127, 0.00090298883, -0.0074087833, -0.003752921, 0.029672109, 0.0017112303, 0.01814528, -0.05405685, -0.0293948, 0.06385512, -0.0038153154, 0.037122488, 0.025327595, 0.031816635, -0.0072562634, -0.0009584507, -0.0014778281, -0.013357071, 0.040598102, 0.0013530389, -0.0068079466, -0.0057726577, -0.01941166, -0.0075150854, 0.02440323, 0.024440205, -0.019300736, -0.06370722, 0.037621647, -0.009442386, -0.008365501, -0.010879774, -0.015649496, -0.017858727, 0.04026533, 0.027379684, 0.02002174, -0.042151034, 0.07235927, -0.01206296, 0.017923433, -0.0062302183, 0.030910758, 0.046735883, -0.04865856, -0.0130797615, 0.0027615398, -0.023774661, 0.01011255, 0.024236845, 0.022813322, -0.0076676058, -0.033554442, 0.018792335, 0.022499038, -0.020724257, -0.06119295, -0.020668795, -0.008652054, -0.010306667, -0.021611648, 0.043777917, -0.014993196, -0.025678853, 0.016878901, -0.026473807, 0.025549442, -0.02288727, -0.044406485, -0.041855235, -0.00666467, -0.048917383, 0.010805824, -0.002283181, 0.020742746, -0.0013091316, 0.028821694, -0.011406661, 0.011776407, -0.010676413, 0.008661298, -0.029856982, 0.060712278, -0.04026533, -0.009715074, 0.035698965, 0.017008312, 0.017701585, 0.031003194, 0.030060342, 0.03192756, -0.019522583, -0.018173011, 0.020243589, -0.020594846, 0.021352826, -0.005906691, -0.007986511, 0.0180436, 0.008383988, -0.049915697, -0.03675274, 0.06448369, -0.0060776984, 0.03849055, -0.011610022, 0.014771349, 0.016767977, -0.008078948, 0.0058419853, -0.043075398, -0.008176006, 0.015769662, -0.027915815, -0.017100748, -0.018237717, 0.010084819, -0.028729256, -0.03013429, -0.014845298, -0.047401424, -0.007838613, 0.025900701, -0.00990919, -0.0055646757, -0.040376253, 0.016721759, -0.0023941046, -0.042188007, 0.034848552, -0.018718386, -0.031335965, 0.032741, 0.05242997, 0.020391487, -0.013495726, 0.02199988, 0.002810069, -0.014170512, -0.025604904, -0.02070577, 0.040339276, -0.007478111, -0.008444072, 0.0041804397, -0.014817567, -0.00291406, 0.06559292, 0.013819253, -0.021389801, 0.008781465, -0.002138749, -0.025993137, 0.0047142603, 0.024994822, -0.010741118, 0.0038338029, -0.009650368, 0.024551127, -0.012460437, -0.053798027, 0.0053058537, 0.0035287624, -0.01490076, -0.013893202, 0.021408288, 0.0022993574, 0.02686204, 0.007339456, 0.011683971, -0.009613394, 0.01609319, -0.0146604255, 0.042594727, -0.019910816, 0.0016742557, 0.009594906, -0.00950247, 0.030633448, -0.023497352, -0.03340654, -0.023016682, -0.028784718, -0.0059113125, 0.011878087, -0.00038765548, 0.012691529, 0.0005855273, -0.05549886, 0.0137268165, -0.011970524, -0.06403999, 0.0015529328, -0.0016869657, 0.012432706, -0.007131474, -0.025383057, 0.011092377, 0.004295985, -0.012839426, -0.011628509, 0.02199988, -0.0038338029, 0.02747212, -0.00084232737, 0.02508726, 0.017849483, 0.0010872841, -0.035255272, 0.018653682, 0.007584413, -0.023682225, -0.02222173, 0.015141095, -0.0037667863, -0.0007331368]": "he entropy distribution of the predicted results ofthese poisoned samples was obviously different from that of\nthe clean samples. For Hidden Trigger, there was a lot of\noverlap between poisoned data and clean data. We think thereason may be that Hidden Trigger itself is only a binary\nclassiﬁcation model, so the entropy of the prediction result will\nnot change greatly. For Trojan and our method, the entropy\ndistribution of the predicted results of poisoned and clean\nsamples is similar, so our method can successfully bypass thisdetection strategy.\nNAD [50]:In addition to defensive testing on the input side,\nwe further investigate the efﬁciency of the NAD, a methodfor eliminating backdoor, across three distinct datasets, as\nshown in Table VI. We ﬁnd that although NAD can reduce\nthe ASR of our poisoning model, the accuracy of the modelalso shows a very signiﬁcant decline, from 80% to about\n10% (on the ResNet-18 model), which is unacceptable. This\nis because traditional backdoors are embedd"}
{"[-0.04591903, 0.1449033, -0.015126161, 0.008392225, 0.058745574, -0.023032809, -0.034008667, -0.044673022, -0.030783707, -0.018616814, -0.030783707, 0.07585985, -0.0396157, -0.02732054, 0.012267673, -0.10635038, 0.018030457, 0.05394478, -0.017581528, 0.09557608, 0.02076068, 0.012991457, 0.035364617, 0.08362907, -0.058342453, -0.063436426, -0.058085922, 0.08384895, 0.03607924, 0.03235954, -0.037160333, 0.10209929, 0.090298876, -0.036775537, 0.04053188, 0.019166522, -0.017554043, -0.084508605, 0.025414882, -0.06493896, -0.0119195245, 0.020082705, -0.011818745, -0.0047916304, 0.042364243, 0.0031745697, 0.007732574, -0.048630927, -0.06699121, 0.05467773, 0.021163799, 0.05438455, 0.050023526, 0.042877305, 0.004067847, 0.025781354, -0.008190665, -0.009390863, 0.035914324, 0.0044182865, -0.003740312, 0.012909001, -0.028218398, -0.026587594, 0.040898353, 0.014109199, -0.0060422188, -0.04001882, 0.020229293, 0.01446651, 0.025964592, -0.047348272, -0.006326235, -0.035272997, 0.0255065, 0.03371549, -0.0012620403, -0.012624985, 0.04562585, -0.011708803, 0.022336511, -0.013284636, 0.015263588, 0.023472577, -0.05676662, -0.010288721, -0.01829615, -0.0014246627, -0.0061338367, 0.027705336, 0.040092114, -0.00079650554, -0.034228552, 0.031095209, -0.0009877585, -0.0006063978, -0.100193635, -0.025488177, 0.004768726, 0.017535718, -0.020595767, 0.036977097, -0.03320243, -0.020394206, 0.0120844375, -0.031461682, 0.018616814, -0.041191533, -0.03351393, -0.04819116, 0.0043999627, -0.036464036, 0.03613421, -0.009033552, 0.0010959824, -0.006165903, 0.016619537, -0.011626347, 0.0017831187, 0.0073202923, 0.0053046923, 0.002631732, 0.029610995, -0.047604803, -0.01920317, 0.032909248, 0.012121085, 0.014979572, 0.022189923, 0.039285872, 0.039982174, -0.018268663, -0.01793884, 0.010939211, 0.014677232, 0.003870868, -0.01144311, -0.011159094, 0.0099497335, 0.022776278, -0.048887458, 0.00034671754, 0.048887458, -0.0021919648, 0.032689366, 0.014429863, 0.012460072, 0.033294044, 0.006188808, 0.012624985, -0.045699146, 0.008877802, 0.019862821, -0.003538752, 0.011598861, -0.031425033, 0.01865346, 0.006820973, -0.024168875, -0.026844125, -0.049766995, -0.009157237, 0.04137477, -0.019587966, 0.007393587, -0.03140671, 0.013971772, -0.0016766127, -0.040605176, 0.025799679, 0.0091297515, -0.034210227, 0.03126012, 0.03987223, 0.021347035, -0.037929926, -0.0056665842, 0.006779745, 0.0048007923, -0.031498328, -0.011250712, 0.015886592, -0.012157732, -0.00058320694, 0.0007615761, -0.005181008, -0.016106475, 0.03946911, 0.011507243, -0.03483323, 0.0007541321, -0.019111551, -0.01869927, -0.0017773926, 0.01103999, -0.011324006, 0.00458778, -0.018332796, 0.005529157, -0.023417605, -0.05357831, -0.0081219515, 0.0008549121, -0.025927944, -0.021072181, -0.008186084, 0.010765135, 0.028273368, -0.002666089, 0.019936115, 0.0023213755, 0.023161074, -0.029867526, 0.03206636, -0.01406339, 0.004496162, 0.016995171, -0.017150922, 0.028804755, -0.019441377, -0.035364617, -0.032652717, -0.010068838, 0.0020178903, 0.015767489, -0.022373158, 0.0034792002, 0.03987223, -0.024407081, -0.0027989352, 0.0017212764, -0.040311996, -0.0056207753, -0.031168504, 0.013541167, -0.011470595, -0.03771004, -0.0033578062, -0.007792126, -0.011195741, -0.024498701, 0.024480376, -0.010270397, 0.013880154, 0.020247618, 0.01672948, 0.034540053, 0.009629071, -0.030490529, 0.0496937, -0.0008337254, -0.028035162, -0.008735793, 0.029556023, -0.015740003, 0.02666089]": " poisoning model, the accuracy of the modelalso shows a very signiﬁcant decline, from 80% to about\n10% (on the ResNet-18 model), which is unacceptable. This\nis because traditional backdoors are embedded throughoutthe entire model. When performing knowledge distillation,\nthe adjustment of each parameter will not be too large, thus\nensuring the stability of ACC. However, for our method, thebackdoor focuses on the backdoor layers of the model. If we\nwant to erase the backdoor, the parameters of the second half\nof the model will be changed across orders of magnitude,\nresulting in the model also performing poorly on the clean\ndata set. Therefore, it is reasonable to believe that our methodbypasses NAD detection.\nVI. C\nONCLUSION\nIn this paper, we show that static triggers are difﬁcult\nto inject backdoors into transfer learning, with only very\nlow ASR. To this end, we propose an efﬁcient and coveredbackdoor attack method - an invisible computable Trigger\nBackdoor attack (ICT). In order to inj"}
{"[-0.07409359, 0.1694417, -0.008746128, 0.009698308, 0.029838089, -0.011844198, -0.0351703, -0.04525877, -0.020920105, 0.02640095, 0.0022248514, 0.06573298, -0.010264971, -0.0698947, 0.0010143046, -0.098618045, 0.007380561, 0.0013202797, -0.005295053, 0.08442359, 0.0141573, -0.0016558653, 0.073313266, 0.058375638, -0.028611867, -0.053136323, -0.07204988, 0.023038127, 0.0022085945, 0.049309023, -0.055477295, 0.107684664, 0.077809416, -0.013284081, 0.0330337, 0.03147305, -0.040836938, -0.04574183, 0.003764597, -0.047339633, -0.027571434, 0.011844198, -0.0010346256, -0.0020413822, 0.05536582, -0.0073480476, 0.031231524, -0.05361938, -0.03494735, 0.051575676, -0.0025639206, 0.009140934, 0.042806324, 0.046447836, -0.032977965, 0.06484118, -0.022499332, -0.004844509, 0.01072945, 0.03539325, -0.03537467, 0.031380158, -0.002138923, -0.0028193835, 0.051204093, 0.040874094, -0.02469167, -0.054585498, 0.03987082, 0.0034162384, 0.035987783, -0.037288323, -0.002484959, -0.006386577, 0.016804827, 0.033776864, 0.018161103, -0.009015525, 0.051872943, 0.019489512, 0.012903209, -0.040093772, 0.022685124, 0.009489293, -0.038941864, -0.03411129, 0.020009728, -0.02853755, 0.0024176098, 0.008035475, 0.027348485, 0.012810313, -0.042397585, 0.010664423, 0.011036006, 0.017111383, -0.041468628, -0.042620532, -0.0060986006, 0.0045124074, -0.019340878, 0.01351632, -0.025026094, -0.040799778, 0.012150753, -0.054622654, 0.029002028, -0.01673051, -0.022908073, -0.032792173, -0.0021842094, -0.048157115, 0.008983011, 0.005671281, 0.029522244, 0.020511365, 0.012011411, -0.016219584, 0.010683002, 0.022573648, 0.009689018, -0.024617353, 0.032327693, -0.04013093, -0.014751833, 0.014723964, 0.0075663524, 0.037678484, -0.0010375285, 0.040428195, 0.0231496, -0.036545157, -0.052504633, -0.00934066, -0.009164158, 0.0133212395, 0.0026126907, 0.01008847, 0.026976902, 0.027812963, -0.04525877, -0.0321419, 0.0772892, -0.01607095, 0.022425015, -0.0073759165, 0.016972039, 0.03476156, -0.007817171, 0.028574709, -0.03845881, 0.021737587, 0.008750772, -0.003890006, -0.0052300263, -0.026308054, -0.0114633255, -0.031138629, -0.012643101, -0.0025174727, -0.040056612, -0.037065372, 0.018811373, -0.034297083, -0.011361141, -0.046745103, 0.028407495, 0.01778952, -0.03002388, 0.0015850323, -0.023632659, -0.03440856, 0.039387763, 0.03494735, 0.019991148, -0.021811904, 0.009322081, -0.0059964154, 0.010487922, -0.018504817, -0.022146327, 0.025824996, -0.013841455, -0.020046886, -0.0030446555, -0.018504817, -0.0013899514, 0.048640173, -0.009215251, -0.011101033, -0.016154557, -0.01930372, -0.010460053, -0.006419091, 0.0048166406, -0.027850121, 0.028240284, -0.015179153, 0.011974252, -0.021644691, -0.064655386, -0.006637396, 0.011621248, -0.016591167, -0.03046978, 0.029169241, 0.00048886344, 0.025044672, -0.010645844, 0.024097137, -0.0028913778, 0.029763773, -0.0386446, 0.030061038, 0.0178081, 0.019247983, -0.012587364, -0.000785549, 0.027924439, -0.016488982, -0.02080863, -0.037381217, 0.0069857542, -0.0010630748, 0.036229312, -0.038867548, 0.027868701, 0.013878613, -0.04696805, 0.0028286732, 0.012364414, -0.052393157, -0.0034650085, -0.009456779, 0.012122885, -0.016600456, -0.027794385, 0.00074606837, 0.0027125536, -0.025787838, -0.020437047, 0.021514637, 0.026549583, 0.025267622, 0.0390905, 0.003260638, 0.023223918, -0.0036507999, -0.053062007, 0.03353534, 0.015374234, -0.020269835, -0.014268775, 0.020882947, 0.0067442255, 0.020957263]": "backdoors into transfer learning, with only very\nlow ASR. To this end, we propose an efﬁcient and coveredbackdoor attack method - an invisible computable Trigger\nBackdoor attack (ICT). In order to inject backdoors into the\nlast layer, we propose to use a neuron selection algorithm togenerate more targeted computable triggers. It can be more\neasily perceived by the model, thus reducing the difﬁculty\nof injecting backdoors. In order to be invisible, we use the\nPGD algorithm to carefully calculate a tiny disturbance, so\nthat after it is added to the image data, the change can notbe detected by people or common defense methods. We have\nconducted extensive experiments to verify the effectiveness of\nour approach against attacks and robustness against defensemethods. The work in this paper contributes to the study of\ninvisible triggers of clean labels in transfer learning. It is alsohoped that the work of this paper can provide new ideas and\nideas for the defense of backdoor attacks. In futur"}
{"[-0.07049729, 0.13464613, -0.017762734, 0.018214876, 0.019598985, 0.030561129, -0.0674338, -0.028863288, -0.037795406, 0.040452894, -0.01865779, 0.06529304, -0.040452894, -0.06688015, 0.005171954, -0.078691214, -0.031207047, 0.00017993418, -0.04728117, 0.085482575, 0.024231136, 0.020632453, 0.070312746, 0.07906031, -0.059645876, -0.06256173, -0.06868872, 0.08090579, 0.020300267, 0.027442269, -0.017292136, 0.113460034, 0.07573845, 0.0014198653, 0.024101954, 0.039714705, -0.010399273, -0.03260961, 0.003167303, -0.01840865, -0.04255674, 0.028309645, 0.005910146, 0.013416631, 0.056324013, 0.021204552, -0.010076314, -0.041154176, -0.032019056, 0.049938656, -0.024987783, 0.0028097415, 0.032055967, 0.034898005, -0.03834905, 0.033606168, -0.018989976, -0.03978852, 0.006473017, 0.007774079, -0.010989826, 0.04960647, -0.010574593, 0.012383163, 0.054183256, 0.008558408, 0.002814355, -0.040305257, 0.028881744, 0.013352039, 0.03144696, -0.020946184, -0.031852964, -0.009965586, 0.03827523, 0.045620237, 0.017762734, -0.02740536, 0.032277424, 0.027073175, -0.024212683, -0.0014763831, 0.056360923, 0.02797746, -0.015428203, -0.03388299, -0.0044383765, 0.0011055572, 0.007538781, 0.011866429, 0.03539628, 0.015077562, -0.040342167, -0.022293383, 0.020761637, 0.022348749, -0.057652757, -0.052780695, 0.014680784, 0.023179214, -0.012410845, 0.02262557, -0.020152628, -0.06034716, 0.0064453348, -0.025153875, 0.028900199, -0.004982793, -0.029435387, -0.038127594, -0.021924289, -0.02906629, 0.04292584, -0.0087014325, 0.017550504, 0.019488256, 0.0016609309, -0.03774004, 0.024526414, 0.0027036264, 0.004069281, -0.01915607, 0.024304956, -0.033864535, 0.024784781, 0.04506659, 0.039382517, 0.0117557, 0.025430698, 0.031705327, 0.028918654, -0.009342737, -0.035986837, 0.010925234, -0.00061535183, 0.0048167, 0.0021845854, 0.010639185, 0.017190635, -0.014745376, -0.048240814, -0.008064742, 0.06953764, 0.010814506, 0.011681881, -0.007511099, 0.00018988247, 0.03537783, -0.014791513, 0.007972469, -0.028586466, 0.01476383, 0.003933177, 0.009250462, -0.01480074, -0.023105394, -0.024046589, -0.013628861, -0.013536587, 0.0131398095, -0.07068184, -0.02262557, 0.019174526, -0.016849222, -0.005559505, -0.043331843, 0.02875256, -0.005988579, -0.017070679, -0.014284006, -0.0047936314, -0.027719092, 0.018989976, 0.047465716, 0.019912716, -0.007109707, 0.008360019, -0.0026736374, 0.00812472, -0.015372839, -0.030321216, 0.009707218, -0.0025675225, -0.025910523, 0.005301138, -0.002588284, -0.020189539, 0.038865782, -0.0054902993, -0.028623376, 0.001408331, -0.023068486, -0.017042996, 0.0111282375, 0.00030363892, -0.03187142, -0.005314979, 0.010666868, 0.013997957, -0.03129932, -0.04359021, 0.0067682937, 0.0043437956, -0.010371591, -0.021536738, 0.020171084, 0.005162727, 0.010325454, 0.00063438335, 0.028401919, -0.0076356684, 0.011478879, 0.0011972544, 0.022736298, 0.009568808, 0.015299019, 0.0124293, 8.347908e-05, 0.0248586, -0.021555193, -0.04440222, -0.012272434, 0.0036425139, -0.002968914, 0.011155919, -0.009845629, 0.038385957, 0.0152344275, -0.038791966, 0.028900199, -0.020318722, -0.05835404, -0.02797746, -0.00072146684, 0.01632326, 0.004131566, -0.04196619, 0.008539953, 0.0091581885, -0.027165448, -0.022717845, 0.019174526, 0.011183602, 0.017568959, 0.017439775, 0.023363762, 0.0031257798, 0.009974813, -0.042040005, 0.04979102, 0.025504516, -0.017661233, -0.014948378, 0.040305257, -0.004678289, -0.009079755]": "butes to the study of\ninvisible triggers of clean labels in transfer learning. It is alsohoped that the work of this paper can provide new ideas and\nideas for the defense of backdoor attacks. In future work, wewill try to evaluate our approach to more real-world data in\nthe physical world.\nA\nCKNOWLEDGMENT\nThe author sincerely thanks Dr. Zhen Li from the School\nof Cyberspace Security, Huazhong University of Science and\nTechnology. She is thanked for her comments and suggestions\non the ﬁrst draft of this article.\nREFERENCES\n[1] F. Schroff, D. Kalenichenko, and J. Philbin, “FaceNet: A uniﬁed\nembedding for face recognition and clustering,” in Proc. IEEE Conf.\nComput. Vis. Pattern Recognit. (CVPR) , 2015, pp. 815–823.\n[2] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look\nonce: Uniﬁed, real-time object detection,” in Proc. IEEE Conf. Comput.\nVis. Pattern Recognit. (CVPR) , 2016, pp. 779–788.\n[3] L. Qi, Y . Zhang, and T. Liu, “Bidirectional transformer with absolute-\nposition"}
{"[-0.0692028, 0.114121385, -0.0003963803, -0.005447688, 0.03095154, -0.0019118855, -0.047520462, -0.04672544, -0.05214603, 0.033408873, -0.04806252, 0.062625825, -0.010010013, -0.040040053, -0.007480407, -0.085717514, 0.029198885, 0.019152734, -0.014156761, 0.0491105, -0.009504092, 0.0114916405, 0.055579066, 0.10696621, -0.053736065, -0.0067938, -0.049688697, 0.027590778, 0.020923458, 0.015638387, 0.04741205, 0.12799808, 0.07993556, 0.009305337, 0.034402646, 0.0071596894, -0.013560496, -0.038450018, 0.0438706, -0.015575147, -0.04090735, 0.009684779, 0.0148614375, 0.03711294, 0.07184082, -0.020941526, 0.04365378, -0.06941962, -0.02585619, 0.018167993, -0.02990356, -0.016379202, 0.003663412, 0.045822013, 0.019658655, 0.004117386, -0.03812478, -0.019748999, 0.059987806, 0.017662073, -0.008320598, -0.0072997212, 0.01337981, -0.08506705, 0.02703065, 0.033408873, -0.011356126, -0.03145746, 0.011970459, 0.019188872, 0.019875478, -0.010362351, 0.006179467, 4.764186e-06, 0.036932252, 0.012196316, -0.006640217, 0.020435605, 0.034583334, -0.0057187174, 0.043834463, -0.005890369, 0.038522292, 0.037691135, -0.034149684, -0.050230753, 0.022043712, -0.051134184, -0.021447448, 0.01168136, 0.04885754, -0.005447688, -0.022766456, 0.027211336, 0.037149075, 0.0040789903, -0.047990244, -0.03279454, 0.014572339, 0.022387017, 0.0043703467, 0.04585815, -0.019477969, 0.0030242347, 0.028512277, -0.0069112456, -0.007150655, -0.009766087, -0.027337817, -0.058578454, -0.0051179356, -0.024049329, 0.02518765, -0.01591845, 0.01077793, 0.033950932, -0.01692126, -0.03812478, -0.011012821, 0.0151686035, 0.02572971, -0.011572949, 0.031204501, -0.04141327, -0.016821882, 0.038739115, -0.016767677, 0.011563915, 0.01958638, 0.00028655695, 0.04715909, -0.014147727, -0.021393241, 0.038739115, -0.00046893707, 0.023706025, 0.011265783, 0.008243807, 0.01742718, 0.00021625875, -0.03566745, -0.023489201, 0.039100487, 0.00040117974, -0.010570141, -0.0287291, 0.0016137533, 0.03830547, 0.034131616, 0.005239899, -0.017987307, 0.040979624, 0.0013574049, -0.023019418, 0.019550243, -0.010064219, 0.017996343, -0.007905019, 0.0008164756, 0.010985719, -0.062264454, -0.025693573, 0.008433526, -0.017887931, 0.0071461378, -0.03498084, -0.00630143, -0.01117544, -0.009120135, -0.006775731, 0.0022709991, -0.004426811, -0.024392633, 0.03881139, 0.0009186762, 0.0020338485, -0.002141131, 0.022929074, -0.010705655, -0.029668668, -0.042894896, 0.0314936, 0.005804543, -0.0051405216, 0.019116595, 0.0013427241, 0.006802834, 0.036155302, 0.019550243, -0.01065145, -0.017987307, -0.021664271, -0.021917231, -0.012512517, 0.017616902, 0.001823801, 0.014780128, 0.008862657, 0.0244107, -0.029325364, -0.0296506, 0.028765237, -0.018231234, -0.01906239, -0.026145289, -0.002214535, 0.004614273, -0.0015324445, 0.043906737, 0.043256268, 0.017933102, 0.006116227, 0.022802593, 0.04101576, -0.019477969, 0.021320967, 0.02088732, 0.016848985, -0.010795998, 0.012214385, -0.012033699, -0.030264933, 0.0057955086, -0.023615682, -0.0014308086, -0.033372734, -0.0010293465, 0.02036333, -0.05915665, 0.044195835, -0.02820511, -0.05456722, -0.015954588, 0.0031529735, 0.0019875478, -0.004144489, -0.022784526, 0.0049056294, 0.02560323, -0.016270788, -0.02493469, 0.035197664, 0.0182222, 0.019785136, -0.0015121173, 0.015972657, 0.014138692, -0.0007538001, -0.013822491, 0.012982301, 0.025820052, -0.00885814, -0.032866813, 0.022152124, 0.016451476, -0.002196466]": "Uniﬁed, real-time object detection,” in Proc. IEEE Conf. Comput.\nVis. Pattern Recognit. (CVPR) , 2016, pp. 779–788.\n[3] L. Qi, Y . Zhang, and T. Liu, “Bidirectional transformer with absolute-\nposition aware relative position encoding for encoding sentences,” Front.\nComput. Sci. , vol. 17, no. 1, 2023, Art. no. 171301.\n[4] H. Zhao, W. Min, J. Xu, Q. Wang, Y . Zou, and Q. Fu, “Scene-adaptive\ncrowd counting method based on meta learning with dual-input network\nDMNet,” Front. Comput. Sci. , vol. 17, no. 1, 2023, Art. no. 171304.\n[5] Z. Guo, J. Chen, T. He, W. Wang, H. Abbas, and Z. Lv, “DS-CNN: Dual-\nstream convolutional neural networks-based heart sound classiﬁcation\nfor wearable devices,” IEEE Trans. Consum. Electron. , vol. 69, no. 4,\npp. 1186–1194, Nov. 2023.\n[6] P. Chanak and I. Banerjee, “Congestion free routing mechanism for IoT-\nenabled wireless sensor networks for smart Healthcare applications,”IEEE Trans. Consum. Electron. , vol. 66, no. 3, pp. 223–232, Aug. 2020.\n[7] X. Zhou et "}
{"[-0.06574712, 0.10469333, -0.0032255219, 0.010059567, 0.048692, -0.015033977, -0.034756266, -0.028351368, -0.06822048, -0.0067740576, -0.049024243, 0.08077187, -0.01591073, -0.08306065, -0.01579998, -0.08793354, 0.016944373, 0.09192045, 0.004166876, 0.06973403, 0.02087591, -0.008716754, 0.07560365, 0.10469333, -0.051940594, -0.032670524, -0.043376118, 0.02584109, 0.033630334, -0.009708867, 0.0097734695, 0.1297961, 0.116949394, -0.01731353, 0.00048855814, 0.028978938, 0.009288949, -0.026671698, 0.028499031, -0.04164107, -0.04149341, 0.011490056, 0.009699638, 0.015006291, 0.07320412, -0.010198002, 0.060246658, -0.09192045, -0.015763065, 0.011849986, -0.030012581, -0.013566573, 0.023847636, 0.06467656, 0.00568504, -2.058491e-05, -0.0099211335, -0.007955365, 0.05179293, 0.040164437, 0.0096904095, -0.015707692, 0.019140866, -0.04976256, 0.04105042, 0.016538298, -0.03331655, -0.024807448, -0.0075631337, 0.015375449, -0.0018365632, -0.02460441, 0.025361186, -0.0010728667, 0.008236848, 0.011840757, 0.020303715, -0.012496013, 0.0568504, -0.014978603, 0.03643594, -0.0403121, 0.016289117, 0.050574705, -0.033888746, -0.03643594, 0.021485021, -0.048802745, 0.0076231216, -0.005426629, 0.02150348, 0.011822299, -0.005491232, 0.026597865, 0.03241211, 0.0041414965, -0.07892607, -0.0097734695, -0.028462116, 0.01128702, -0.0072585777, 0.03473781, -0.016538298, -0.02584109, 0.015117038, 0.0013001299, 0.02833291, -0.013917273, -0.021208152, -0.076341964, 0.00019568282, -0.008804428, 0.02486282, 7.076738e-05, 0.020192968, 0.03348267, -0.021688059, -0.04300696, -0.024106046, -0.0023695359, 0.0068294313, -0.015089352, 0.03322426, -0.039942943, -0.026782446, 0.034405567, -0.024567494, 0.03189529, 0.010354894, -0.003216293, 0.018919371, -0.023496935, -0.04289621, 0.03047403, -0.012237602, 0.010170315, 0.007364711, -0.007097071, 0.0014051093, 0.0008582934, -0.03676818, 0.0034008722, 0.039647616, 0.008689066, 0.014849398, -0.028222162, -0.0047806017, 0.045258824, -0.0037561872, 0.0012505242, -0.03171071, 0.034331735, -0.022703243, -0.00023807836, 0.02257404, -0.014941688, 0.00599421, -0.0017131259, -0.016039934, -0.0028886648, -0.04994714, -0.011490056, 0.0033939504, -0.022426376, 0.045591068, -0.040570512, 0.019417735, -0.029864918, -0.022592496, -0.003659283, 0.018522525, 0.009791927, 0.0035208487, 0.036454394, -0.0064741164, 0.0052282065, 0.0014489469, 0.0077938577, -0.008924405, -0.025527306, -0.04795368, 0.011323935, -0.0010532552, -0.0032947392, 0.0055927504, -0.0056896545, 0.00058286655, 0.02851749, 0.016990518, -0.05116536, -0.0040284414, -0.020931283, -0.015338534, -0.0072724214, 0.00941354, -0.004579872, 0.019048575, -0.010271833, 0.022463292, -0.025933381, -0.03231982, 0.028554406, -0.018974744, -0.041419577, 0.010161086, 0.00031955278, 0.00042597423, 0.008453729, 0.011563888, 0.040570512, -0.0025610367, 0.0130682085, 0.0008531021, 0.022961656, -0.0038138682, 0.0138249835, 0.012117626, -0.015292388, 0.00697248, -0.007230891, -0.023035487, -0.032818187, -0.0073970123, -0.012939003, 0.0025056629, 0.010170315, 0.015827669, 0.029255807, -0.012394494, 0.017894955, -0.04344995, -0.03580837, -0.017073577, -0.014498698, -0.0019507717, -0.011969962, -0.029458843, -0.013252788, 0.011333164, -0.029255807, -0.01607685, 0.034276363, 0.02968034, 0.011028608, 0.018937828, 0.04271163, -0.008739826, 0.003659283, 0.01723047, 0.016418321, 0.035051595, -0.010668679, -0.002299165, 0.017304301, -0.0040007546, 0.005675811]": " “Congestion free routing mechanism for IoT-\nenabled wireless sensor networks for smart Healthcare applications,”IEEE Trans. Consum. Electron. , vol. 66, no. 3, pp. 223–232, Aug. 2020.\n[7] X. Zhou et al., “Hierarchical federated learning with social context\nclustering-based participant selection for Internet of Medical Thingsapplications,” IEEE Trans. Comput. Social Syst. , vol. 10, no. 4,\npp. 1742–1751, Aug. 2023.\n[8] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang, “Domain adaptation\nvia transfer component analysis,” IEEE Trans. Neural Netw. , vol. 22,\nno. 2, pp. 199–210, Feb. 2011.\n[9] X. Zhou et al., “Spatial–temporal federated transfer learning with multi-\nsensor data fusion for cooperative positioning,” Inf. Fusion , vol. 105,\nMay 2024, Art. no. 102182.\n[10] A. Nguyen, J. Yosinski, and J. Clune, “Deep neural networks are easily\nfooled: High conﬁdence predictions for unrecognizable images,” in Proc.\nIEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2015, pp. 427–436.\n[11] Y . Che"}
{"[-0.015946051, 0.12333075, 0.031179737, 0.011516592, 0.0106581, -0.0026028778, -0.058158338, -0.06327277, -0.0718577, 0.031070143, -0.022978388, 0.08044262, -0.02367249, -0.05666054, -0.013370573, -0.10309223, 0.017617373, 0.0026622417, 0.008708225, 0.059875324, 0.0057308977, 0.033371635, 0.050413635, 0.10981405, -0.042741995, -0.057427704, -0.032275684, 0.04895237, 0.0440206, 0.01427473, -0.0068953433, 0.13180608, 0.08570318, -0.02257654, 0.024896298, 0.015288482, -0.012986991, -0.07021377, 0.01672235, -0.030449105, -0.023855148, -0.017334253, -0.028585993, 0.024348324, 0.052642062, 0.005137259, 0.041280728, -0.037810225, -0.028019752, 0.036422025, -0.015352413, 0.026887272, 0.025462538, 0.058852438, -0.026302766, 0.018211013, -4.181158e-05, -0.018722454, 0.06093474, 0.04033091, -0.0014110338, -0.015434609, -0.038212072, -0.0074935486, 0.046577815, 0.019654011, -0.012685604, -0.053555354, 0.056587476, -0.0065848245, 0.0111512765, -0.07832379, 0.004025328, -0.026942069, 0.041098073, 0.008689959, 0.04599331, -0.035508733, 0.046614345, -0.0017752084, 0.009854404, -0.026302766, 0.03857739, 0.04270546, -0.0646975, -0.046395157, 0.04515308, -0.032421812, 0.0026394094, -0.00016667551, 0.021864174, 0.016996335, -0.009032443, 0.0028083683, 0.03536261, 0.018941645, -0.063711144, -0.0326958, -0.022978388, 0.022740932, 0.006863378, 0.016959805, -0.00075175223, -0.01578166, 0.03536261, -0.052094087, 0.024914565, -0.020932619, -0.04036744, -0.07214995, -0.008320076, -0.014320395, 0.013808952, 0.024056071, 0.009078108, 0.016293103, -0.0036759942, -0.0018094567, -0.013626294, 0.006598524, 0.022174694, 0.0073017576, 0.04781989, -0.044422448, -0.029371422, 0.026302766, -0.00362348, 0.0269786, 0.008009558, 0.026375828, 0.014630914, -0.007237827, -0.039454147, 0.036148038, 0.0033426431, 0.005881591, 0.022996655, -0.009388627, 0.018384537, 0.018530663, -0.035709657, -0.027380448, 0.043436095, -0.0036052142, -0.012247225, -0.021206604, -0.017507778, 0.025919184, 0.03587405, 0.012959592, -0.013233579, 0.042559337, -9.668036e-05, 0.0038677852, 0.03103361, -0.007721871, 0.016083045, -0.013772421, -0.02392821, 0.0026622417, -0.059656136, -0.0255904, 0.0055847713, -0.028933043, -0.004411193, -0.045262676, 0.0262845, 0.025553867, -0.01270387, -0.00059991766, 0.008607763, -0.008895449, 0.012968725, 0.02383688, 0.011123878, 0.0059683532, 0.0053747143, 0.020914352, -0.0033426431, -0.027234321, -0.030978814, 0.015188021, -0.004210269, 0.0010046195, -0.0010263101, 0.011863643, -0.0035047522, 0.04084235, 0.030412573, -0.011105612, -0.005945521, -0.025773058, -0.046760473, -0.010932087, -0.0025868954, -0.031198002, 0.0047582434, -0.004018478, 0.009735676, -0.0021416661, -0.052751657, 0.030631762, -0.01943482, -0.012247225, -0.019124303, 0.014667445, 0.018850315, 0.00046435112, 0.018941645, 0.015608135, -0.002653109, -0.010831625, -0.015580735, 0.054432113, -0.0025709127, 0.0009509637, 0.03046737, 0.0073930863, 0.013133117, -0.023069717, -0.01619264, -0.040111717, 0.008046089, 0.013662825, 0.005694366, -0.010612436, 0.01861286, 0.019982796, -0.01506016, 0.018621992, -0.012685604, -0.06261519, -0.019982796, 0.010174056, -0.01087729, -0.01663102, -0.02968194, 0.0085666645, 0.017407317, -0.028695587, -0.022887059, 0.030266447, 0.0010725455, 0.021389263, 0.038613923, -0.00054141, 0.008941114, 0.00029082593, -0.014183401, 0.020676896, 0.018740721, -0.01575426, -0.00073919445, 0.027362183, 7.15292e-05, 0.019361759]": "nd J. Clune, “Deep neural networks are easily\nfooled: High conﬁdence predictions for unrecognizable images,” in Proc.\nIEEE Conf. Comput. Vis. Pattern Recognit. (CVPR) , 2015, pp. 427–436.\n[11] Y . Chen, X. Gong, Q. Wang, X. Di, and H. Huang, “Backdoor\nattacks and defenses for deep neural networks in outsourced cloud\nenvironments,” IEEE Netw. , vol. 34, no. 5, pp. 141–147, Sep./Oct. 2020.\n[12] T. Gu, B. Dolan-Gavitt, and S. Garg, “BadNets: Identifying vul-\nnerabilities in the machine learning model supply chain,” 2017,arXiv:1708.06733 .\n[13] X. Qi, J. Zhu, C. Xie, and Y . Yang, “Subnet replacement: Deployment-\nstage backdoor attack against deep neural networks in gray-box setting,”2021, arXiv:2107.07240 .\n[14] Y . Liu et al., “Trojaning attack on neural networks,” in Proc. 25th Annu.\nNetw. Distrib. System Secur. Symp. (NDSS) , 2018, pp. 1–15.\n[15] J. Xu, K. Xue, Q. Yang, and P. Hong, “PSAP: Pseudonym-based secure\nauthentication protocol for NFC applications,” IEEE Trans. Consum.\nElectro"}
{"[-0.040176205, 0.09521906, -0.00484979, 0.0005164233, 0.040139943, -0.0010725062, -0.076218754, -0.033758163, -0.07150494, 0.0022413284, 0.037420437, 0.072375186, -0.02556338, -0.07357177, -0.016054165, -0.07201259, -0.026578663, 0.0383632, -0.024983218, 0.034592148, 0.03879832, -0.0011705218, 0.027956547, 0.14112437, -0.030259065, -0.02538208, -0.015047947, 0.08861972, 0.025998501, 0.027992807, -0.025200779, 0.12582259, 0.07781421, -0.040720105, 0.029697033, 0.019852411, -0.00041897426, -0.06755259, -0.00055325, -0.009472955, -0.088039555, 0.012391893, -0.002909874, 0.021103386, 0.040973928, -0.0076372866, -0.0009331313, -0.055550493, 0.0074695833, 0.014014534, -0.06142463, -0.0038073119, 0.030893616, 0.019997451, -0.012455349, 0.0034855034, -0.009355109, -0.021411598, 0.023659725, 0.056203175, -0.016969733, 0.008049745, -0.028391669, -0.01948981, 0.07281031, 0.020215012, -0.010841774, -0.057073418, 0.055477973, 0.0053211716, 0.0162264, -0.021393467, -0.0078095216, -0.027358256, 0.029026221, 0.01901843, 0.038471982, 0.005244119, 0.019054689, -0.0012407757, 0.030984268, -0.0010980016, 0.02565403, 0.040720105, -0.055840574, -0.053592447, 0.030422235, -0.026379231, -0.018365748, 0.025128258, 0.01916347, 0.016996928, -0.016643392, 0.0058333455, 0.018855259, -0.006662796, -0.07897453, -0.032579713, -0.020650133, 0.020958345, 0.020849565, 0.034247678, -0.028047197, 0.00082831696, 0.01467628, -0.03575247, 0.00822198, -0.013370916, -0.04507132, -0.049277492, -0.015909124, -0.037075967, 0.04111897, 0.0025857994, 0.037239134, 0.013352787, -0.011739211, -0.014023598, -0.013697257, -0.004233368, 0.029715162, 0.001269104, 0.0512718, -0.043439616, -0.008167591, 0.033359304, 0.004532514, 0.011739211, 0.02282574, 0.01909095, -0.0019081885, 0.008534724, -0.021629158, 0.059394065, 0.009563604, -0.0024974153, 0.00059035997, -0.001159757, 0.0038888971, 0.009790231, -0.033341173, 0.0031319673, 0.04822595, -0.0095908, 0.01130409, -0.020650133, 0.012473479, 0.0075466363, 0.019852411, 0.0065358854, -0.019997451, 0.022771351, 0.007333608, 0.0070843194, -0.008648037, -0.009391369, 0.004781802, -0.015057012, -0.028065328, -0.00044361982, -0.08144021, -0.018519852, 0.0031387662, -0.020994605, -0.002529143, -0.03858076, 0.023278993, 0.0025540716, -0.04162661, 0.0035512247, 0.012827015, -0.0017801449, 0.016262662, 0.031219957, 0.0012577727, 0.0010509767, 0.020994605, 0.004634496, 0.0086752325, -0.02920752, -0.030259065, 0.02222745, -0.0052667814, 0.0034877695, -0.021592896, -0.008357956, 0.0009285988, 0.029098742, 0.030621666, -0.029769553, -0.0037234602, -0.040865146, -0.028391669, -0.015963515, -0.0026651183, -0.01267291, 0.012011163, 0.009092223, 0.04775457, 0.0042197704, -0.030984268, 0.015392418, -0.0121924635, -0.0324528, -0.005017493, -0.00024673872, 0.03821816, -0.01896404, 0.0003611847, 0.023260862, 0.0052758465, -0.008090538, 0.021012735, 0.05801618, -0.02219119, 0.008435009, 0.04093767, 0.0033110017, 0.016987864, -0.0065177553, -0.03230776, -0.016462091, -0.0021484117, 0.00724749, -0.014359005, 0.0059103984, 0.028065328, 0.014585631, -0.06621097, 0.004013541, 0.015356158, -0.043330833, -0.0014209432, -0.023496553, -0.015084207, -0.006073569, -0.00975397, -0.010107506, 0.016507417, -0.0090604955, -0.036767755, 0.0068486286, 0.0023342448, 0.018021276, 0.017422985, 0.028210368, 0.0256359, 0.00066514645, -0.00013505475, 0.017123839, -0.0030209208, -0.016661521, -0.018311357, 0.022934522, 0.014630956, 0.01294486]": "Distrib. System Secur. Symp. (NDSS) , 2018, pp. 1–15.\n[15] J. Xu, K. Xue, Q. Yang, and P. Hong, “PSAP: Pseudonym-based secure\nauthentication protocol for NFC applications,” IEEE Trans. Consum.\nElectron. , vol. 64, no. 1, pp. 83–91, Feb. 2018.\n[16] D. Sethia, D. Gupta, and H. Saran, “NFC secure element-based mutual\nauthentication and attestation for IoT access,” IEEE Trans. Consum.\nElectron. , vol. 64, no. 4, pp. 470–479, Nov. 2018.\n[17] P. Paikrao, S. Routray, A. Mukherjee, A. R. Khan, and R. V ohnout,\n“Consumer personalized gesture recognition in UA V-based indus-try 5.0 applications,” IEEE Trans. Consum. Electron. , vol. 69, no. 4,\npp. 842–849, Nov. 2023.\n[18] F. A. Yerlikaya and ¸ S. Bahtiyar, “Data poisoning attacks against\nmachine learning algorithms,” Expert Syst. Appl. , vol. 208, Nov. 2022,\nArt. no. 118101.\n[19] S. Alfeld, X. Zhu, and P. Barford, “Data poisoning attacks against\nautoregressive models,” in Proc. AAAI Conf. Artif. Intell. (AAAI) , 2016,\npp. 1452–1458.\nAuthorized l"}
{"[-0.046453312, 0.108193174, -0.024042929, 0.04192671, 0.057213265, -0.019163847, -0.073464505, -0.036453977, -0.051907495, 0.03435764, -0.003376399, 0.08162723, -0.010936193, -0.062185105, -0.009475251, -0.09320345, 0.01096402, 0.03591598, -0.030202072, 0.079697855, 0.045562834, 0.017753921, 0.012689323, 0.06767639, -0.047751926, -0.026899882, 0.0209077, 0.050126538, 0.008440997, 0.04137016, -0.013236596, 0.15954413, 0.075616494, -0.011455639, 0.061665658, 0.024877751, -0.02046246, -0.07298216, 0.021408595, -0.016770685, -0.011548397, 0.0119287055, -0.014683625, 0.01735506, 0.057584297, -0.017484922, 0.010834159, -0.059402358, -0.00472835, 0.016798511, -0.005862319, 0.0090346495, 0.013477768, 0.027029742, -0.0429285, 0.04949578, -0.029608421, 0.013097459, 0.051388048, -0.0018470478, 0.015898757, 0.010314713, -0.022966933, -0.025118923, 0.0689379, 0.03420923, -0.014609418, -0.04114754, 0.028291253, 0.0012046973, 0.035452187, -0.054727342, -0.0017426949, -0.027771808, 0.010713574, -0.016974753, 0.010138473, 0.002274895, 0.062073793, -0.003680182, 0.028402563, -0.00019566185, 0.023987273, 0.015870929, -0.040145755, -0.03220565, 0.01180812, -0.010574436, -0.012077119, 0.0050645983, 0.026528848, 0.008362153, -0.045637038, 0.014498108, 0.04166699, -0.024376858, -0.057584297, -0.03537798, -0.005597958, 0.038921345, 0.018996881, 0.032057237, -0.053502936, 0.0022737356, -0.006929038, -0.038550314, 0.042075124, -0.05298349, -0.018700056, -0.0757649, -0.016612995, -0.038142174, 0.03691777, 0.0073835533, 0.024265548, 0.012744978, 0.007443846, 0.0062890067, -0.004141654, -0.010277609, 0.0045103678, -0.028254151, 0.053651348, -0.048865024, -0.017327234, 0.04021996, 0.00435036, 0.020147083, 0.0065209023, 0.01400649, 0.05298349, -0.015045381, -0.06248193, 0.021297285, -0.007193399, 0.012531634, 0.005491286, -0.00599218, 0.006043197, 0.00047886427, -0.04137016, -0.012104946, 0.03730735, 0.00233055, 0.0052130115, 0.0010168619, -0.017948713, 0.027029742, 0.0076525523, 0.0050924257, -0.041963816, 0.008696082, 0.0084502725, -0.012568737, -0.008107067, -0.020740736, 0.0078519825, -0.011195916, -0.0186444, -0.027066845, -0.04474656, -0.041704092, 0.021835282, -0.035544947, 0.020054325, -0.038698725, 0.018431056, -0.007360364, -0.045933865, 0.0074113808, 0.006673953, -0.018700056, 0.0074809496, 0.031463586, 0.014488832, -0.02767905, 0.018393952, 0.0073232604, 0.0068316422, -0.011242295, -0.018792814, 0.0130789075, -0.018672228, -0.0101477485, -0.010667194, 0.0055654924, -0.00043277504, 0.052278526, 0.018162057, -0.0161121, 0.0042065848, -0.037715487, -0.016195584, -0.002798979, 0.0018389315, -0.0011635358, 0.0132737, 0.0022690976, 0.016167756, -0.009424234, -0.031092552, 0.018162057, 0.013885904, -0.023412172, -0.014461005, 0.014507384, 0.008547669, 0.029793937, -0.0031862445, 0.020647977, 0.020295497, 0.015499896, -0.0036523545, 0.05231563, 0.001478334, -0.0065394538, 0.01513814, -0.005533027, 0.027512085, -0.0060292836, -0.032149997, -0.015537, -0.0017508112, 0.00071655714, -0.014869141, 0.017633336, 0.0053753383, 0.022614451, -0.051907495, 0.014934071, -0.00799112, -0.05866029, -0.015240174, -2.5236755e-05, -0.009980784, 0.009693233, -0.025341542, -0.006168421, 0.05524679, -0.01440535, -0.032799304, 0.041778296, 0.0007675742, 0.0060153697, 0.0015676138, 0.006952228, 0.022540245, -0.020610875, -0.010843434, 0.0043202136, 0.0034784328, -0.01735506, -0.019163847, 0.032279857, -0.007462398, 0.0064652474]": "ov. 2022,\nArt. no. 118101.\n[19] S. Alfeld, X. Zhu, and P. Barford, “Data poisoning attacks against\nautoregressive models,” in Proc. AAAI Conf. Artif. Intell. (AAAI) , 2016,\npp. 1452–1458.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. CHEN et al.: ICT BACKDOOR ATTACKS IN TRANSFER LEARNING 6757\n[20] A. Shafahi et al., “Poison frogs! targeted clean-label poisoning attacks\non neural networks,” in Proc. Adv. Neural Inf. Process. Syst. (NeurIPS) ,\nvol. 31, 2018, pp. 6106–6116.\n[21] X. Chen, C. Liu, B. Li, K. Lu, and D. Song, “Targeted back-\ndoor attacks on deep learning systems using data poisoning,” 2017,\narXiv:1712.05526 .\n[22] M. Barni, K. Kallas, and B. Tondi, “A new backdoor attack in CNNs\nby training set corruption without label poisoning,” in Proc. IEEE Int.\nConf. Image Process. (ICIP) , 2019, pp. 101–105.\n[23] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing\nadversarial"}
{"[-0.049267363, 0.11023527, -0.011433781, 0.026988506, 0.040326383, -0.015628314, -0.045919094, -0.03751163, -0.047096506, 0.02457849, -0.035487954, 0.058981016, -0.020715104, -0.062623635, -0.018967383, -0.11420903, 0.032783583, 0.03250763, -0.022591606, 0.10331796, 0.020163191, 0.0036403209, 0.062439665, 0.098166786, -0.030410362, -0.06295478, -0.04897301, 0.068805054, 0.02645499, 0.041319825, -0.0226284, 0.12171504, 0.0666342, -0.01093706, 0.05563275, 0.0061952146, -0.015002813, -0.09183819, -0.00459007, -0.034457717, -0.035653528, 0.015812285, -0.021450987, 0.024412917, 0.029361729, -0.016309006, 0.021450987, -0.0622189, -0.014450901, 0.039958443, 0.0049442137, 0.027687596, 0.05795078, 0.028129125, -0.032691598, 0.036886133, -0.01169134, -0.024909638, 0.02822111, 0.038008355, -0.030336773, 0.013595437, -0.030851891, -0.005519122, 0.042644415, 0.028478669, -0.0182223, -0.058502693, 0.04658139, 0.00048033608, 0.049561717, -0.047059715, -0.010394346, -0.012896349, 0.013475856, 0.017302448, 0.017192066, -0.022977944, 0.056846958, -0.014745254, 0.016272211, 0.015766291, 0.013521849, 0.029527303, -0.03797156, -0.028018743, 0.041650973, 0.00038058945, -0.00810851, 0.0048384303, 0.023529857, 0.000609978, -0.016860917, -0.0064573726, 0.021690149, 0.006494167, -0.06335952, -0.030962273, 0.0010975004, 0.037070103, 0.010099993, 0.020715104, -0.01904097, -0.015398351, 0.009538882, -0.050996687, 0.028754625, -0.03230526, -0.039774474, -0.053093955, 0.0010911764, -0.024744064, 0.02005281, -0.0077773626, 0.016060645, 0.007059877, 0.0055605154, -0.016299807, -0.015499534, 0.018691426, 0.008770805, 0.007869348, 0.049083393, -0.03381382, -0.02356665, 0.043785036, 0.0071886564, 0.028644243, 0.011084236, 0.021083046, 0.04091509, -0.01678733, -0.040767916, 0.02351146, 0.006135424, 0.0006571205, 0.007285241, 0.0009859682, 0.016207822, 0.02733805, -0.059385754, -0.021910915, 0.057214897, 0.0006295249, 0.016989697, 0.01992403, 0.017210461, 0.029508905, 0.008002727, 0.0020662213, -0.01628141, 0.036352616, 0.010504729, 0.01552713, -0.010256369, -0.012528406, -0.010348354, -0.023143519, -0.013540246, 0.00017031665, -0.07016644, -0.03594788, 0.017964741, -0.036812544, 0.0015419048, -0.02972967, 0.02582949, 0.01377021, -0.027135683, 0.0009934419, -0.013301084, -0.030336773, 0.018516654, 0.026326211, 0.0070874724, -0.024983225, 0.0073680277, 0.0030355172, 0.01357704, -0.022223664, -0.018967383, 0.022573208, -0.005946854, -0.018636236, 0.0053213537, 0.0066367444, 0.0061124275, 0.047722008, 0.025259182, -0.022646798, 0.0133102825, -0.007860149, -0.021211825, -0.0023870203, -0.0013728816, 0.0024997024, 0.01904097, -0.010026405, 0.017955543, 0.012289245, -0.05776681, 0.015122394, -0.01608824, -0.020071207, -0.013724216, 0.009695258, 0.015269571, 0.007929139, 0.015333961, 0.01577549, 0.011847715, 0.016079042, -0.015757093, 0.035506353, -0.0039438726, 0.0011900606, 0.009704456, 0.018571846, 0.024026578, 0.010054001, -0.027190873, -0.011203818, 0.0099712135, -0.004502684, 0.0003846138, -0.01521438, 0.030796701, 0.003387361, -0.059827283, 0.004192233, -0.012537605, -0.048016362, -0.011360193, 0.021763738, 0.007115068, -0.0021133637, -0.027834771, 0.0034172563, 0.019813647, -0.02275718, -0.02803714, 0.011590156, 0.012473215, 0.016814925, 0.017201263, -0.009603272, 0.035120014, -0.015140791, -0.030686319, 0.015260372, 0.0044037993, -0.025056813, -0.011148626, 0.029582493, -0.015379953, 0.0009945917]": "ng set corruption without label poisoning,” in Proc. IEEE Int.\nConf. Image Process. (ICIP) , 2019, pp. 101–105.\n[23] I. J. Goodfellow, J. Shlens, and C. Szegedy, “Explaining and harnessing\nadversarial examples,” 2014, arXiv:1412.6572 .\n[24] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and\nA. Swami, “Practical black-box attacks against machine learning,”inProc. ACM Asia Conf. Comput. Commun. Secur. (CCS) , 2017,\npp. 506–519.\n[25] Y . Li, T. Zhai, B. Wu, Y . Jiang, Z. Li, and S. Xia, “Rethinking the trigger\nof backdoor attack,” 2020, arXiv:2004.04692 .\n[26] A. Saha, A. Subramanya, and H. Pirsiavash, “Hidden trigger back-\ndoor attacks,” in Proc. AAAI Conf. Artif. Intell. (AAAI) , 2020,\npp. 11957–11965.\n[27] K. Doan, Y . Lao, W. Zhao, and P. Li, “Lira: Learnable, imperceptible\nand robust backdoor attacks,” in Proc. IEEE Int. Conf. Comput. Vis.\n(ICCV) , 2021, pp. 11966–11976.\n[28] X. Gong, Y . Chen, J. Dong, and Q. Wang, “ATTEQ-NN: Attention-based\nQoE-aware evasive backdoor"}
{"[-0.04483031, 0.10790167, 0.009235449, 0.017248087, 0.035268474, -0.01612641, -0.019583382, -0.05332564, -0.073773265, 0.026000846, -0.034588113, 0.07318484, -0.009092941, -0.04089525, -0.0077368147, -0.117831275, 0.03124147, 0.0011314459, -0.0070840353, 0.07590629, 0.0026639835, -0.00203304, 0.0487286, 0.068293594, -0.03271252, -0.050971955, -0.010021542, 0.051302943, 0.031756338, 0.011878746, -0.016567724, 0.12018496, 0.07211833, -0.018121524, 0.05520123, 0.016291901, -0.011713252, -0.076347604, 0.018029582, 0.0023789671, -0.03787959, 0.0148116555, -0.017772147, 0.014103712, 0.04534518, -0.015124254, 0.03302512, -0.072853856, -0.028887786, 0.03609594, 0.0058842083, 0.020741835, 0.0039626467, 0.040417157, -0.038762223, 0.020521177, -0.036132716, -0.01919723, 0.018728333, 0.02804193, -0.018461704, 0.006826601, -0.03787959, -0.011602923, 0.06255649, 0.037162453, -0.026184727, -0.08061366, 0.04854472, 0.01849848, 0.050309982, -0.054943796, -0.013055587, -0.048471168, 0.0043533947, 0.017882477, 0.014508251, 0.0066565108, 0.038799, -0.0060405075, -0.0021594586, -0.023205847, 0.04497742, 0.017018234, -0.03710729, -0.036518868, 0.04277084, -0.005341758, -0.004176409, 0.011235161, 0.03063466, 0.007814964, -0.01617238, 0.014554221, 0.009865243, 0.02456657, -0.06785228, -0.05578965, 0.0013446335, -0.0023766686, 0.0071024233, 0.052259125, -0.0148484325, -0.02237838, 0.022304827, -0.06428497, 0.024088478, -0.02475045, -0.05501735, -0.047294326, -0.0058796112, -0.029402653, 0.014305982, -0.013441739, 0.02456657, 0.015096672, -0.006932333, -0.00020183869, -0.012595884, -0.009423927, 0.009892825, -0.0050889207, 0.06616057, -0.0342939, -0.021367032, 0.01631029, 0.005488863, 0.03282285, 0.0063393153, 0.011455818, 0.032969955, -0.026203115, -0.07958392, 0.03133341, 0.0028915368, 0.0022088767, 0.005920985, -0.012081015, 0.012090209, 0.013901442, -0.043212157, -0.024125254, 0.051229388, -0.007175976, 0.015758645, -0.012467166, -0.003473062, 0.02197384, 0.008081593, -0.0050797267, -0.007865531, 0.041888207, -0.005180862, 0.005603789, 0.006619734, -0.025706636, 0.0049234275, -0.036978573, -0.008288459, 0.009281419, -0.05339919, -0.029733641, 0.017367609, -0.040784918, -0.0019985621, -0.037732486, 0.015207001, 0.006831198, -0.0140393535, -0.0025099826, -0.008761954, -0.028244201, 0.009635392, 0.04107913, 0.011851164, -0.018480092, 0.004633814, 0.01243039, -0.0014377235, -0.022341603, -0.041520447, 0.0015411569, -0.024676898, 0.0021284285, -0.012788959, 0.008499923, 0.018176688, 0.043212157, 0.014692132, -0.02475045, 0.009423927, -0.027913213, -0.017183727, -0.023702327, 0.0029444026, -0.014673744, 0.050861627, 0.005355549, 0.005594595, 0.0054658777, -0.053656626, -0.026331833, -0.014002577, -0.019270783, -0.016144797, 0.013745143, 0.023849431, 0.0061692246, 0.024143642, 0.0017813521, 0.028244201, 0.010701904, -0.032087322, 0.024382688, 0.0009314748, 0.017992806, -0.0004137334, 0.00017454378, 0.033539988, 0.023849431, -0.024529794, -0.01795603, 0.0020341892, 0.012825736, 0.01213618, -0.017836507, 0.028722292, 0.014388728, -0.042219196, -0.005852029, -0.010867397, -0.040343605, -0.0045257835, -0.010352529, 0.005203847, 0.0048958454, -0.036022387, -0.0045372765, 0.0031466724, -0.027986767, -0.034643278, -0.004323514, 0.0026157144, 0.016907904, 0.0293291, 0.010389306, 0.025725024, -0.014112906, -0.030211732, 0.020392459, -0.0040155123, -0.013809501, -0.014030159, 0.026791535, -0.005498057, 0.0025214753]": "\nand robust backdoor attacks,” in Proc. IEEE Int. Conf. Comput. Vis.\n(ICCV) , 2021, pp. 11966–11976.\n[28] X. Gong, Y . Chen, J. Dong, and Q. Wang, “ATTEQ-NN: Attention-based\nQoE-aware evasive backdoor attacks,” in Proc. Annu. Netw. Distrib.\nSystem Secur. Symp. (NDSS) , 2022, pp. 1–18.\n[29] E. Bagdasaryan and V . Shmatikov, “Blind backdoors in deep learning\nmodels,” in Proc. 30th USENIX Secur. Symp. (USENIX Security) , 2021,\npp. 1505–1521.\n[30] Y . Li, Y . Li, B. Wu, L. Li, R. He, and S. Lyu, “Invisible backdoor attack\nwith sample-speciﬁc triggers,” in Proc. IEEE Int. Conf. Comput. Vis.\n(ICCV) , 2021, pp. 16463–16472.\n[31] E. Wenger, J. Passananti, A. N. Bhagoji, Y . Yao, H. Zheng, and\nB. Y . Zhao, “Backdoor attacks against deep learning systems in the\nphysical world,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit.\n(CVPR) , 2021, pp. 6206–6215.\n[32] P. Xia, Z. Li, W. Zhang, and B. Li, “Data-efﬁcient backdoor attacks,”\n2022, arXiv:2204.12281 .\n[33] S. Wang, S. Nepal, C. Rudolph, M. G"}
{"[-0.049374603, 0.11598061, -0.008339558, 0.025184361, 0.026399396, 0.009264641, -0.06266635, -0.050295085, -0.058027126, 0.042010754, -0.029934043, 0.08718796, 0.0010827158, -0.05714346, -0.01213194, -0.10397754, 0.016136032, 0.007819487, 0.011137821, 0.06778422, 0.0024139616, -5.0159026e-05, 0.030283825, 0.083579674, -0.04746, -0.041900296, -0.03208797, 0.04385172, 0.0050488384, 0.014212227, -0.009039124, 0.1477188, 0.07503761, -0.018253138, 0.047865015, 0.006277681, -0.020729233, -0.08291693, -0.0024346723, -0.012187169, -0.039028395, -0.01238047, -0.014727697, 0.012279217, 0.061377674, -0.022330869, 0.033560738, -0.083579674, -0.030265417, 0.03247457, 0.0054032234, -0.00933828, 0.018418826, 0.043925356, -0.019201234, 0.016384562, -0.012408084, -0.0064019454, 0.024153423, 0.01988239, -0.013448228, 0.023048844, -0.035751484, -0.028461274, 0.057658933, 0.03398416, -0.037739724, -0.064249575, 0.03602763, 0.005260549, 0.02671236, -0.028313996, 0.004952188, -0.036948107, 0.01213194, -0.0048739472, 0.03151727, -0.0064203553, 0.03921249, 0.0036197917, -0.010254159, -0.008670932, 0.032308884, 0.031719778, -0.025000265, -0.045839954, 0.013457432, -0.016062394, -0.03160932, 0.0016936851, 0.015482491, 0.009554593, -0.01701049, 0.015602154, 0.022330869, -0.012371265, -0.08740888, -0.04602405, -0.0020250583, 0.013521866, -0.005656356, 0.04845412, -0.03685606, -0.009352087, 0.032732304, -0.042489406, 0.031995922, -0.021612894, -0.04116391, -0.06690056, -0.018685766, -0.02569983, 0.037574034, 0.01067758, -0.0074328845, 0.017857332, -0.009080545, -0.008201486, -0.015924321, 0.0040593212, 0.008790594, -0.015224757, 0.04385172, -0.023987737, -0.0013093842, 0.0053710067, 0.0022310158, 0.021999497, 0.024650482, 0.014285865, 0.05294607, -0.020913329, -0.04517721, 0.031277947, 0.0064709815, 0.0045241644, 0.009186401, -0.021060606, 0.003102021, -0.0066734874, -0.048233207, -0.021631304, 0.054639753, 0.008707751, 0.0218154, -0.019974438, -0.0104566645, 0.018740993, 0.012058302, 0.004024803, -0.03201433, 0.03350551, 0.002152775, 0.00023759916, -0.0051961155, -0.017378682, -0.005085658, -0.030173369, -0.01140476, -0.0074927155, -0.05629662, -0.04020661, 0.006254669, -0.017369477, 0.00077090284, -0.026491445, 0.008832015, 0.0013657637, -0.011966254, -0.0004372285, -0.007943751, -0.004250321, 0.009729484, 0.026638722, 0.00279366, -0.0109077, -0.00095097197, 0.024668891, 0.009665051, -0.022036316, -0.04514039, 0.02862696, -0.0011120562, 0.0017868838, -0.0014290469, -0.004452827, 0.005509079, 0.043814898, 0.025258, -0.0149670215, -0.0041513694, -0.04164256, -0.018694969, -0.019532608, 0.0068161623, -0.012813096, 0.02185222, 0.0036405025, 0.006645873, -0.019274874, -0.06874152, -0.001425595, 0.00087215577, -0.012849915, -0.015942732, 0.003840707, 0.0056425487, 0.014838154, 0.015657382, 0.032861173, 0.007419077, 0.0029340333, -0.022422917, 0.026141662, -0.009402714, 0.010769628, 0.0013853239, -0.008302739, 0.0069450294, 0.0021826907, -0.022883158, -0.03345028, 0.0012299928, 0.013982107, -0.006029151, -0.010364616, 0.019164415, 0.012233193, -0.05195195, 0.008288932, -0.016633091, -0.054087464, 0.0014969322, 0.011791362, -0.0009722581, -0.0023679375, -0.015151118, -0.007828691, 0.02818513, -0.029915633, -0.029473802, 0.015261576, 0.026454626, 0.020600365, 0.016633091, 0.021760171, 0.037629265, -0.006783945, -0.016577864, 0.023251351, 0.011008953, 0.002568142, -0.035143968, 0.023619544, 0.009425726, 0.010705194]": "omput. Vis. Pattern Recognit.\n(CVPR) , 2021, pp. 6206–6215.\n[32] P. Xia, Z. Li, W. Zhang, and B. Li, “Data-efﬁcient backdoor attacks,”\n2022, arXiv:2204.12281 .\n[33] S. Wang, S. Nepal, C. Rudolph, M. Grobler, S. Chen, and T. Chen,\n“Backdoor attacks against transfer learning with pre-trained deeplearning models,” IEEE Trans. Services Comput. , vol. 15, no. 3,\npp. 1526–1539, Jun. 2020.\n[34] C. Xie, K. Huang, P.-Y . Chen, and B. Li, “DBA: Distributed backdoor\nattacks against federated learning,” in Proc. Int. Conf. Learn. Represent.\n(ICLR) , 2019, pp. 1–19.\n[35] P. Lv et al., “A data-free backdoor injection approach in neural\nnetworks,” in Proc. 32nd USENIX Secur. Symp. (USENIX Security) ,\n2023, pp. 2671–2688.\n[36] A. Nguyen and A. Tran, “WaNet–imperceptible warping-based backdoor\nattack,” 2021, arXiv:2102.10369 .\n[37] X. Gong, Z. Wang, Y . Chen, M. Xue, Q. Wang, and C. Shen,\n“Kaleidoscope: Physical backdoor attacks against deep neural networkswith RGB ﬁlters,” IEEE Trans. Depend. Secure C"}
{"[-0.05956584, 0.11104879, -0.012224468, 0.02940062, 0.033587705, 0.004865211, -0.009757729, -0.039722696, -0.06662927, 0.052757274, -0.033041563, 0.0787172, 0.005843715, -0.047441497, -0.004394164, -0.1103206, 0.048169687, 0.0243033, -0.016575396, 0.06619236, -0.0018250231, 0.018659838, 0.044492334, 0.06033044, -0.058692012, -0.05377674, -0.014864153, 0.072564006, 0.026961189, 0.02326563, -0.00879743, 0.13325854, 0.08272224, -0.013162011, 0.061277084, 0.03418846, 0.00038144575, -0.07187223, 0.02164541, -0.023302041, -0.027671173, 0.013990327, -0.018896498, 0.02064415, 0.050026566, -0.04929838, 0.024285095, -0.06957843, -0.024503551, 0.037610948, -0.020280058, -0.002257385, -0.0024644637, 0.054395698, -0.022883331, 0.014527366, -0.023702543, -0.0039367704, 0.014399933, 0.02874525, -0.006503636, -0.00046194473, -0.03036547, -0.00266244, 0.054104425, 0.035626635, -0.023757158, -0.04664049, 0.044310287, 0.012797917, 0.02171823, -0.04529334, -0.0030948021, -0.011159493, 0.009866958, -0.0027648418, 0.017330892, -0.024376119, 0.032149535, 0.008237636, 0.0021629483, -0.02974651, 0.023119994, 0.0143271135, -0.03826632, -0.046167165, 0.040414475, -0.005347636, 0.01037669, 0.0052065495, 0.02326563, 0.003722865, -0.014199681, -0.007418423, 0.02716144, -0.01103206, -0.08330479, -0.04656767, -0.0002679507, 0.016247712, 0.016875774, 0.03757454, -0.0021481568, -0.0041347467, 0.028872684, -0.057199225, 0.0089976825, -0.025104307, -0.038484775, -0.052902915, -0.0030583928, -0.02009801, 0.035826888, -0.0026829205, 0.018486893, 0.028271928, 0.0041142665, -0.027634762, -0.02291974, 0.004715022, 0.018750861, -0.014709413, 0.03888528, -0.03644585, -0.007240927, 0.022937946, -0.0158199, 0.023192812, 0.017613066, 0.02399382, 0.03457076, -0.03611816, -0.03957706, 0.02943703, 0.0014734444, -0.0111868, -0.0014688933, -0.007245478, 0.010595147, 0.026396843, -0.045693845, -0.030037787, 0.063643694, -0.007973667, 0.01408135, -0.011259618, 0.0047741877, 0.018313946, 0.027652968, 0.0047787386, -0.013817381, 0.044201057, 0.0067721554, 0.0113688465, -0.0043964395, 0.004312243, -0.00806014, -0.033150792, -0.017212562, 0.009307163, -0.07900848, 0.0010342556, 0.0076823914, -0.029455235, -0.016329633, -0.039212964, 0.017449223, 0.014418137, -0.004209841, -0.0047241244, -0.005707179, -0.029036526, 0.020170828, 0.0381935, -0.0033519438, -0.02399382, 0.00023424353, 0.007013368, -0.00391629, -0.029546259, -0.047550727, 0.01242472, -0.004371408, 0.010039902, -0.00929806, 0.016903082, 0.012033319, 0.039759107, -0.0049289274, -0.016985003, -0.004075581, -0.020462103, -0.022155143, -0.008415131, 0.0041597784, -0.01249754, 0.024103047, -0.0015678814, 0.018878294, 0.0043031406, -0.05046348, 0.0032700226, -0.0016850743, -0.034934856, -0.0019786253, -0.0067220926, 0.021663615, 0.0077825175, 0.018969318, 0.029072937, 0.0019604207, 0.007372911, -0.020662356, 0.02819911, -0.018914703, 0.005638912, 0.0058346125, -0.0055888486, 0.0021162985, -0.010349383, -0.044455923, -0.05446852, 0.0022050466, -0.003151692, 0.008984028, -0.0105587365, 0.03591791, 0.022519236, -0.05060912, 0.013744563, -0.01847779, -0.03715583, 0.00029668002, -0.0013164288, 0.0082467375, 0.00027335522, -0.0393586, 0.0074047693, 0.03016522, -0.02940062, -0.034425125, 0.018304845, 0.010731682, 0.012397413, 0.029036526, -0.0042917626, 0.017076027, -0.0038594003, -0.020789789, 0.026105566, 0.009393635, -0.017558452, -0.028690636, 0.021536183, 0.01292535, 0.010367587]": "1, arXiv:2102.10369 .\n[37] X. Gong, Z. Wang, Y . Chen, M. Xue, Q. Wang, and C. Shen,\n“Kaleidoscope: Physical backdoor attacks against deep neural networkswith RGB ﬁlters,” IEEE Trans. Depend. Secure Comput. , vol. 20, no. 6,\npp. 4993–5004, Dec. 2023.\n[38] K. Chen, X. Lou, G. Xu, J. Li, and T. Zhang, “Clean-image backdoor:\nAttacking multi-label models with poisoned labels only,” in Proc. 11th\nInt. Conf. Learn. Represent. (ICLR) , 2023, pp. 1–18.\n[39] A. Turner, D. Tsipras, and A. Madry, “Clean-label backdoor attacks,”\ninProc. ICLR , 2018, pp. 1–20.\n[40] Y . Wang, K. Chen, Y .-a. Tan, S. Huang, W. Ma, and Y . Li, “Stealthy\nand ﬂexible trojan in deep learning framework,” IEEE Trans. Depend.\nSecure Comput. , vol. 20, no. 3, pp. 1789–1798, Jun. 2023.\n[41] Y . Li, Y . Jiang, Z. Li, and S.-T. Xia, “Backdoor learning: A survey,”\nIEEE Trans. Neural Netw. Learn. Syst. , vol. 35, no. 1, pp. 5–22,\nJan. 2024.\n[42] Y . Li et al., “Reconstructive neuron pruning for backdoor defense,” in\nProc. 40th In"}
{"[-0.041608367, 0.11927732, -0.0038962222, -0.008321674, 0.02598698, -0.0009090425, -0.020183709, -0.015840378, -0.05941967, 0.029490843, -0.03489263, 0.07277814, -0.015876876, -0.060843114, -0.0040399353, -0.12453312, 0.009927611, 0.011862035, 0.009015147, 0.077887945, -0.0008582866, 0.019818723, 0.052740432, 0.09496927, -0.059529163, -0.049090575, -0.03898047, 0.07562503, 0.03262972, 0.031808503, -0.015338523, 0.120445274, 0.06744935, -0.015539265, 0.058470707, 0.017519312, 0.0027738912, -0.06971227, 0.0023769692, -0.0305858, -0.023048846, 0.0061500086, -0.018632518, 0.021625401, 0.0369913, -0.017738303, 0.03952795, -0.07259565, -0.038104504, 0.055587318, -0.0010481932, 0.006168258, 0.026114725, 0.070369236, -0.02397956, 0.02828639, -0.0027214244, -0.01936249, 0.019216496, 0.03523937, -0.004863434, 0.013659589, -0.022300625, 0.0139698265, 0.058726195, 0.041608367, -0.01619624, -0.06255855, 0.047813125, 0.0068434817, 0.03879798, -0.050842505, 0.0006296003, -0.019289494, 0.022483118, 0.01594075, 0.023103593, -0.01566701, 0.059821155, -0.00642831, -0.00061420246, -0.012810998, 0.041681364, 0.046718165, -0.032027494, -0.040403914, 0.030768292, -0.018167162, 0.015539265, 0.017975545, 0.0458787, 0.007089847, -0.006619928, 0.0117616635, 0.019563232, -0.016013747, -0.062339555, -0.032556724, -0.0011725165, 0.009763367, 0.025567247, 0.027738912, -0.03974694, -0.026826447, 0.01963623, -0.05153598, 0.04383478, -0.049674552, -0.04690066, -0.028833868, 0.008791593, -0.012236145, 0.017327696, 0.015502767, 0.0028240767, 0.0144534325, -0.00040262484, -0.014499056, -0.0071993424, 0.017026583, 0.008882839, -0.015849503, 0.052010458, -0.028377637, -0.024764279, 0.041097388, 0.010922196, 0.042922314, 0.007774195, 0.02828639, 0.024052557, -0.03137052, -0.06741285, 0.036425572, -0.0069986004, 0.003921315, 0.0068252324, 0.02089543, 0.019964717, 0.008800717, -0.042119347, -0.022227628, 0.06175558, -0.0012649035, 0.01961798, 0.010840075, 0.0037456655, 0.024107303, 0.015539265, 0.004945556, -0.03335969, 0.04514873, -0.002193336, -0.0038255062, 0.0012329672, -0.0076099513, -0.0015831254, -0.023833565, -0.01808504, -0.006236693, -0.07201167, -0.005725713, 0.013814708, -0.01668897, -0.01185291, -0.038432993, 0.021333413, 0.0057622115, -0.012081026, 0.009339071, -0.008225865, -0.030476304, 0.014617677, 0.029016363, 0.0032050305, -0.019216496, 0.005753087, 0.023523327, 0.010155726, -0.028450634, -0.043798283, 0.023687571, -0.018139789, -8.643459e-06, -0.0021556967, -0.005146298, 0.0018671298, 0.045075733, -6.3801206e-05, -0.022045135, -0.0025252446, -0.024581786, -0.034107912, -0.011843786, 0.0022697547, -0.018650768, 0.013522719, -0.00070316775, 0.023048846, -0.0094166305, -0.05814222, 0.010256098, -0.015876876, -0.010986069, 0.0029791957, 0.012236145, 0.010949571, 0.012975241, 0.0130026145, 0.029764581, 0.010584584, 0.016460855, -0.028268142, 0.029582089, -0.0038004133, 0.0057895854, 0.020530444, -0.0064876205, 0.0070168497, -0.006455684, -0.029271852, -0.033542182, -0.0050231153, -0.004459669, 0.019198246, -0.007007725, 0.029618587, 0.017418941, -0.05836121, 0.020475697, -0.013869456, -0.051681973, -0.013823832, -0.012071901, 0.0149370385, 0.01159742, -0.045221727, -0.0023290648, -0.0076008267, -0.017765678, -0.036005836, 0.015183404, 0.017090455, 0.0116977915, 0.023067094, -0.0035426423, 0.017345944, 0.006989476, -0.02115092, 0.019070502, 0.0069849133, -0.02828639, -0.03259322, 0.030622298, -0.011825536, 0.01670722]": ", “Backdoor learning: A survey,”\nIEEE Trans. Neural Netw. Learn. Syst. , vol. 35, no. 1, pp. 5–22,\nJan. 2024.\n[42] Y . Li et al., “Reconstructive neuron pruning for backdoor defense,” in\nProc. 40th Int. Conf. Mach. Learn. (ICML) , 2023, pp. 1–18.\n[43] J. Xia, T. Wang, J. Ding, X. Wei, and M. Chen, “Eliminating\nBackdoor triggers for deep neural networks using attention relation\ngraph distillation,” in Proc. Int. Joint Conf. Artif. Intell. (IJCAI) , 2022,\npp. 1481–1487.\n[44] K. Liu, B. Dolan-Gavitt, and S. Garg, “Fine-pruning: Defending against\nbackdooring attacks on deep neural networks,” in Proc. Int. Symp. Res.\nAttacks, Intrusions, Defenses , 2018, pp. 273–294.\n[45] B. Wang et al., “Neural cleanse: Identifying and mitigating backdoor\nattacks in neural networks,” in Proc. IEEE Symp. Security Privacy (SP) ,\n2019, pp. 707–723.[46] W. Chen, B. Wu, and H. Wang, “Effective backdoor defense by\nexploiting sensitivity of poisoned samples,” in Proc. 36th Conf. Neural\nInf. Process. Syst. (NeurIP"}
{"[-0.060511783, 0.11004139, -0.0025968268, 0.023007656, 0.0434162, -0.00028971204, -0.07438593, -0.029175978, -0.06937074, 0.015850939, -0.023227299, 0.089760974, -0.01424022, -0.063001074, -0.010185967, -0.1131164, 0.016217012, 0.02029872, -0.016162101, 0.06428233, 0.02095765, -0.00565582, 0.028571958, 0.07493504, -0.055826053, -0.023410335, -0.013526378, 0.07790022, 0.011430614, 0.032434024, -0.02130542, 0.14979686, 0.079657376, -0.027400525, 0.046784066, 0.0014997532, -0.0050060414, -0.08771097, 0.030658571, -0.037101448, -0.036241177, -0.0028164703, -0.008694221, 0.036900107, 0.034978226, -0.009609403, 0.033001434, -0.0636234, -0.042134944, 0.06431894, -0.016235314, -0.0074861823, 0.0318117, 0.030512143, -0.016491566, 0.025442038, -0.005449904, -0.030695178, 0.031335805, 0.043050125, -0.00010674731, 0.031097857, -0.020921042, -0.02308087, 0.067430556, 0.043855485, -0.025570164, -0.052751046, 0.025130877, 0.005852584, 0.006474907, -0.040011723, -0.011522132, -0.004095436, 0.025259001, 0.012290884, 0.040377796, -0.024252303, 0.04180548, -0.012263428, 0.019017465, 0.012162758, 0.017306076, 0.020115683, -0.040267974, -0.04070726, 0.061024286, -0.029963033, -0.01373687, 0.029779997, 0.038510825, 0.002198723, -0.009984627, 0.016098037, 0.038254574, -0.011384854, -0.06622251, -0.043745663, -0.010780835, -0.013645352, 0.011421462, 0.0031733909, -0.020207202, -0.02762017, -0.018779518, -0.06106089, 0.02796794, -0.04883407, -0.04887068, -0.052384973, -0.018504964, -0.020243809, 0.02913937, -0.01808398, 0.011064541, -0.00044529286, 0.015731966, -0.018459205, -0.0060173166, -0.009838198, 0.024453642, -0.00016373165, 0.04528317, -0.03177509, 0.0095636435, 0.026686685, -0.00089573365, 0.01131164, 0.023867926, 0.014853391, 0.022934442, -0.019456754, -0.055130515, 0.03777868, 0.0010181391, -0.00014549952, 0.00014685799, -0.0018212106, -0.0121993655, 0.015091338, -0.029779997, -0.024179088, 0.05937696, -0.0041206037, 0.033257686, -0.017333532, 0.002633434, 0.012446465, 0.018907644, 0.01151298, -0.026942935, 0.03388001, 0.012437313, 0.0017685877, -0.009536188, -0.0058114007, -0.014112094, -0.026174184, -0.014285979, -0.006145442, -0.045612633, -0.0031070402, 0.013517227, -0.009408063, -0.01121097, -0.0449537, 0.0013327326, -0.0026517375, -0.01843175, -0.001952768, -0.0052439882, -0.021470152, 0.021470152, 0.054325156, 0.0031573751, -0.02267819, 0.016098037, 0.02181792, 0.01867885, -0.047369782, -0.03201304, 0.026759898, -0.025057662, -0.007975805, -0.008762861, 0.012922359, 0.014322586, 0.04872425, 0.018834429, -0.0353626, -0.0169217, -0.03605814, -0.038291182, -0.01004869, 0.01676612, -0.030621964, 0.015356741, 0.004230425, 0.020426845, -0.035051443, -0.0540323, 0.011604498, 0.014587989, -0.020829525, -0.009554492, 0.0054590562, 0.015118794, 0.02216569, -0.010725924, 0.017425051, 0.01353553, 0.016152948, -0.033294294, 0.031646967, 4.339961e-05, -0.005125015, 0.017242014, -0.008172568, 0.017470809, -0.013709415, -0.025533557, 0.00017960432, 0.006095107, 0.003857489, -0.003120768, 0.002972051, 0.022238905, 0.012300036, -0.034154564, 0.009856502, -0.023501854, -0.02954205, -0.006003589, -0.023062566, 0.0066076084, 0.009147236, -0.03221438, -0.0065618493, 0.004596498, -0.008195448, -0.029175978, 0.03014607, 0.0028210462, 0.0063422057, 0.022531763, 0.0055002393, 0.027675081, -0.021506758, -0.02242194, 0.008959624, 0.021049168, -0.007266539, -0.019566575, 0.029871516, 0.003937567, 0.0022696494]": "ty Privacy (SP) ,\n2019, pp. 707–723.[46] W. Chen, B. Wu, and H. Wang, “Effective backdoor defense by\nexploiting sensitivity of poisoned samples,” in Proc. 36th Conf. Neural\nInf. Process. Syst. (NeurIPS) , 2022, pp. 1–11.\n[47] Y . Gao, C. Xu, D. Wang, S. Chen, D. C. Ranasinghe, and S. Nepal,\n“Strip: A defence against trojan attacks on deep neural networks,”\ninProc. 35th Annu. Comput. Secur. Appl. Conf. (ACSAC) , 2019,\npp. 113–125.\n[48] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu,\n“Towards deep learning models resistant to adversarial attacks,” 2017,\narXiv:1706.06083 .\n[49] E. Chou, F. Tramer, and G. Pellegrino, “Sentinet: Detecting localized\nuniversal attacks against deep learning systems,” in Proc. IEEE Security\nPrivacy Workshops (SPW) , 2020, pp. 48–54.\n[50] Y . Li, N. Koren, L. Lyu, X. Lyu, B. Li, and X. Ma, “Neural attention\ndistillation: Erasing backdoor triggers from deep neural networks,” 2021,\narXiv:2101.05930 .\n[51] Q. Huynh-Thu and M. Ghanbari, “Scope of validit"}
{"[-0.06560828, 0.104871355, 0.02063222, 0.013299959, 0.029183494, 0.015055698, -0.07299512, -0.049160723, -0.05574702, 0.03349552, -0.03618826, 0.038389757, -0.05913114, -0.05123486, -0.007359553, -0.078526154, 0.04697742, -0.008169195, -0.042938307, 0.054509815, 0.01950418, 0.023033854, 0.036242843, 0.08594939, -0.015237641, -0.088714905, -0.047232136, 0.08172834, 0.0360609, 0.014628135, 0.01614735, 0.13485539, 0.10414359, -0.00887422, 0.032130953, 0.033386353, 0.026236033, -0.06415274, 0.01872183, -0.048396565, -0.015437777, 0.022742746, -0.02141457, 0.032986082, 0.054691758, -0.0253991, 0.01614735, -0.040354732, -0.008678633, 0.05691145, -0.0014543987, 0.006927441, 0.014828271, 0.033095244, -0.008769603, 0.044612173, -0.014427999, -0.008887866, 0.025107993, 0.018703636, 0.011971782, -0.0011894457, -0.046104096, -0.05873087, 0.034860082, 0.03129402, -0.0016784148, -0.041337218, 0.042356092, 0.017848508, 0.011453248, -0.039590575, 0.0045917607, -0.008769603, 0.025362711, 0.0269638, 0.017948575, -0.025599236, 0.027455045, 0.0069228923, 0.004348413, -0.012344764, -0.00446895, 0.033277187, -0.025762985, -0.06757325, 0.027618792, -0.01081645, -0.017948575, -0.005521939, 0.016547622, 0.012999754, -0.030784583, -0.0044484814, 0.04082778, 0.01708435, -0.06699104, -0.0033545552, -0.019558763, 0.042756364, 0.0043006535, -0.0029247173, -0.008100967, -0.008883317, 0.050288763, -0.05334539, 0.018703636, -0.038098652, -0.0417011, -0.053381775, -0.015419583, -0.044866893, 0.013190794, -0.031312216, 0.0056674927, 0.033695653, 0.020905133, -0.047559634, -0.013345444, 0.01894016, 0.0014032274, -0.016574914, 0.04057306, -0.033222605, -0.022615388, 0.0332408, -0.017047964, 0.0075551406, 0.0313486, 0.010834645, 0.025490072, -0.0105526345, -0.0548737, 0.042974696, 0.00409142, 0.011999073, -0.0043438645, 0.018230585, 0.018367043, 0.016092768, -0.052035406, -0.0013998161, 0.045048833, -0.021996785, 0.0031521448, -0.019522374, 0.02903794, 0.032567613, 0.007764374, -0.0012110512, -0.017102545, 0.032622196, 0.0030316082, 0.0039458666, -0.004744137, -0.007668854, -0.018794606, -0.02903794, -0.013445512, -0.00912439, -0.059240308, -0.006727305, 0.04097333, -0.017229905, 0.0037047935, -0.051125694, 0.022306086, -0.0009603125, 0.009370012, -0.002904249, -0.008237423, -0.0033386352, 0.013854882, 0.031821653, 0.009570148, -0.0034227835, 0.0027996323, 0.0033727493, -0.013145308, -0.044757728, -0.030038621, 0.023670651, -0.03203998, -0.015765272, -0.002449394, -0.012817812, 0.0048805936, 0.025853954, 0.00417102, -0.021996785, -0.010907422, -0.017775731, -0.045922156, -0.0103343045, -0.0076142717, -0.01430064, 0.006008634, 0.009165327, 0.008924254, 0.002590399, -0.043811627, 0.0060814107, -0.021942202, -0.015483262, 0.00029395, 0.007609723, 0.018385237, 0.0010512834, 0.03405954, 0.0015931295, -0.009697507, 0.013718425, -0.011416859, 0.014755494, 0.014946533, 0.010925616, 0.012026365, -0.014255154, 0.007573335, -0.0039435923, -0.026927413, -0.028674055, 0.0053763855, -0.021050686, 0.017784828, -0.014846466, 0.008783249, 0.0041778428, -0.07146681, 0.011735258, -0.01235386, -0.047741573, -0.0036820509, 0.0038298785, 4.4703713e-05, -0.002070727, -0.033823013, 0.01276323, 0.019613346, -0.026836442, -0.037298106, 0.033440936, 0.023852594, 0.026145061, 0.029274464, -0.010525343, 0.018776411, -0.0068182754, -0.03191262, 0.025380906, -8.7346365e-05, -0.030820971, -0.024725914, 0.0060859593, -0.013964047, 0.021651095]": "n, L. Lyu, X. Lyu, B. Li, and X. Ma, “Neural attention\ndistillation: Erasing backdoor triggers from deep neural networks,” 2021,\narXiv:2101.05930 .\n[51] Q. Huynh-Thu and M. Ghanbari, “Scope of validity of PSNR in\nimage/video quality assessment,” Electron. Lett. , vol. 44, no. 13,\npp. 800–801, 2008.\n[52] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and\nD. Batra, “Grad-CAM: Visual explanations from deep networks viagradient-based localization,” in Proc. IEEE Int. Conf. Comput. Vis.\n(ICCV) , 2017, pp. 618–626.\n[53] F. R. Hampel, “The inﬂuence curve and its role in robust estimation,”\nJ. Am. Statist. Assoc. , vol. 69, no. 346, pp. 383–393, 1974.\nXiang Chen received the B.S. degree in computer\nscience and technology from the Nanyang Instituteof Technology, Nanyang, China, in 2022.\nHe is currently pursuing the master’s degree\nin cyberspace security with Zhengzhou University,Zhengzhou, China. His research interests includeneural networks, AI security, and accelerated\ncomputin"}
{"[-0.052267082, 0.056349874, 0.006395453, 0.008988577, 0.050391205, -0.0055816537, -0.05745333, -0.06933388, -0.06554535, 0.0067218924, -0.0024253067, 0.05958668, -0.08606965, -0.040975038, -0.03520028, -0.0483682, 0.00018491526, -0.022896733, 0.011338021, 0.03501637, 0.018317387, 0.05105328, -0.009931114, 0.0697017, -0.0510165, -0.063595906, 0.030639324, 0.06227176, 0.035494536, -0.01622082, 0.033195667, 0.1473483, 0.12483777, 0.002103465, 0.053701576, 0.043623336, 0.01973349, -0.046381976, 0.06385338, -0.009452948, -0.01810589, 0.02381628, -0.009425363, 0.009765595, 0.06650168, -0.01857486, -0.020947292, -0.012459869, -0.032423247, 0.031117488, -0.029370349, 0.02107603, -0.015834609, 0.04009227, 0.038952034, 0.0034942806, -0.025232384, 0.007517301, 0.0010028816, -0.0045149783, 0.02609676, -0.023945017, -0.0011942623, -0.036119826, 0.045499213, 0.023190988, -0.021719713, -0.054510776, 0.031650826, -0.012809297, -0.028597929, -0.07974316, -0.0325152, -0.025600202, -0.018078305, 0.013388612, 0.004131067, -0.023264553, 0.02745769, -0.02107603, -0.009802377, -0.03639569, 0.026023194, 0.02320938, -0.054657906, -0.014308159, 0.04406472, -0.0011373654, -0.0042161252, -0.006473615, 0.0035885342, -0.013002402, -0.02087373, 0.016533464, 0.027328953, 0.0039011803, -0.06230854, -0.011770208, 0.037646275, 0.039908364, -0.0035540513, 0.029830122, -0.026740443, 0.029351957, 0.036083046, -0.011981704, 0.03214738, -0.03832674, -0.0402394, -0.06403729, -0.022731215, -0.049839474, 0.022933515, -0.00017025997, 0.011172502, 0.030620933, 0.04855211, -0.0184921, 0.005310387, -0.028505974, -0.028616318, -0.003365544, 0.06267636, -0.06120508, -0.002733355, 0.045940593, -0.004891993, 0.031705998, -0.007825349, 0.010961006, 0.035347406, -0.008202364, -0.031246224, 0.023448462, -0.005540274, -0.005903495, 0.00046178527, -0.03479568, 0.021167984, 0.0063770623, -0.03196347, -0.005204639, 0.046676233, -0.024312837, -0.0033195666, -0.018234627, 0.024312837, 0.027825508, 0.008606965, -0.015319662, -0.025305947, 0.006960975, 0.0038988816, 0.0121564185, -0.01054721, 0.010418474, -0.0026528947, -0.01481391, -0.022345005, -0.008409262, -0.04027618, -0.017140366, -0.0043701497, -0.016211623, -0.008257537, -0.0569016, 0.011623081, -0.00977479, -0.019384062, 0.0013965628, 0.0093334075, -0.009710422, -0.0059218863, 0.03891525, 0.011825381, -0.02552664, 0.011292044, 0.0039885375, -0.0010620774, -0.023853064, -0.06609707, 0.008101214, 0.003609224, -0.021903623, 0.014446092, -0.011521931, 0.0057609654, 0.067200534, -0.0039540543, -0.025453076, -0.00890122, -0.0068966066, 0.0019046129, -0.018409342, -0.018124282, 0.0003686811, 0.020469127, 0.027972637, 0.012312741, 0.007135689, -0.03288302, -0.01286447, 0.007972477, -0.03814283, -0.00087357016, -0.014280573, 0.024533529, -0.01556794, 0.006731088, 0.0028827814, -0.017710485, -0.009301223, 0.016551856, 0.033968087, -0.0025724343, 0.0129656205, 0.016763352, -0.0019069117, 0.021922013, -0.028138155, -0.039577324, -0.0041632513, -0.006450626, -0.00134139, 0.00483682, -0.02105764, 0.013489762, 0.0103633, -0.039135944, 0.029591039, -0.017278299, -0.04263022, -0.002993127, -0.00735638, -0.024239274, -0.011144916, -0.021756494, -0.015292075, -0.007360978, -0.007972477, -0.0205243, 0.018666815, 0.0119909, 0.03968767, -0.002751746, 0.0056322287, 0.027568035, -0.013480566, -0.016395532, 0.00904375, 0.01760014, 0.00016207025, -0.022528915, 0.0046184273, 0.023448462, -0.01392195]": "22.\nHe is currently pursuing the master’s degree\nin cyberspace security with Zhengzhou University,Zhengzhou, China. His research interests includeneural networks, AI security, and accelerated\ncomputing.\nBo Liu received the M.S. degree in computer\nscience and engineering from Zhengzhou University,\nZhengzhou, and the Ph.D. degree in computer archi-tecture from the Huazhong University of Science andTechnology, Wuhan.\nShe is currently a Lecturer with Zhengzhou\nUniversity. Her research interests focus on deeplearning, AI security, and AI accelerator design.She has served as a Reviewer for top conferences\nor journals, such as IEEE T\nRANSACTIONS ON\nPARALLEL AND DISTRIBUTED SYSTEMS andACM\nTransactions on Architecture and Code Optimization .\nShaofeng Zhao received the B.S. and M.S.\ndegrees in computer science and engineering fromZhengzhou University, Zhengzhou, and the Ph.D.degree in computer architecture from the Huazhong\nUniversity of Science and Technology, Wuhan.\nHe is currently a Lecturer "}
{"[-0.07814983, 0.05772017, 0.0025241193, -0.026493011, 0.044209644, 0.0310997, -0.058375664, -0.07509084, -0.07381626, -0.008448631, 0.016860845, 0.07618334, -0.08273831, -0.050691783, -0.04883454, -0.05549876, -0.02461756, 0.014630333, -0.015203893, 0.038965665, 0.04318998, 0.035833847, 0.011862678, 0.0498542, -0.04144199, -0.05935891, 0.0076156026, 0.076474674, 0.027385216, -0.011853574, 0.027804006, 0.1316821, 0.113619514, -0.026019596, 0.021777073, 0.040130995, 0.012126698, -0.053386603, 0.057647336, 0.007715748, -0.03932983, 0.04541139, -0.012627425, 0.029042166, 0.036653217, -0.02212303, -0.016250867, 0.002435354, -0.006523107, 0.015604475, -0.0701382, 0.016050577, 0.008148194, 0.0122723635, 0.0066004926, 0.00028251245, -0.017288739, 0.05167503, -0.008248339, 0.014411834, -0.0007419864, -0.014193335, 0.0071285316, -0.017980652, 0.06791679, 0.017753048, -0.032010112, -0.07028387, 0.053714354, 0.018335713, -0.0029747738, -0.040313076, -0.0026106085, -0.03526939, 0.00426756, 0.015112852, 0.015458808, -0.04664955, 0.011179868, 0.011380159, -0.0013144084, -0.011525826, -0.0048251874, 0.038565084, -0.033211857, -0.053058855, 0.040058162, -0.018736294, -0.02243257, 0.0040900293, 0.0020450146, -0.007902383, 0.00076133263, -0.006209015, 0.046103302, 0.004085477, -0.06008724, 0.00357337, 0.015340455, 0.029388124, -0.013000694, 0.0058175377, -0.012609216, 0.005221217, 0.018499587, -0.051383696, 0.061288986, -0.01753455, -0.04577555, -0.047924127, -0.030808367, -0.032392487, 0.023015235, 0.001930075, 0.036598593, 0.020375038, 0.035852052, -0.026875384, -0.007788581, -0.020411454, -0.0075063533, -0.012873236, 0.0505097, -0.04362698, 0.03435898, 0.0430079, 0.012217739, -0.00036843267, -0.001861794, -0.011981032, 0.00743352, 0.0058994745, -0.05058253, 0.033612438, -0.026838968, -0.015977744, -0.01607789, -0.0055262055, 0.023069859, -0.021631407, -0.055243846, 0.022068406, 0.050364032, -0.022723902, -0.007633811, -0.03119074, 0.034996267, 0.0425709, -0.016269077, -0.025801098, -0.01215401, 0.025309475, -0.008967565, 0.010205727, -0.020393245, 0.008767275, -0.021686032, 0.009559334, -0.014257063, 0.0017582346, -0.07516368, -0.016696969, 0.0017491304, -0.030589867, 0.019082252, -0.03827375, 0.0047660107, -0.0068189916, -0.018426754, 0.005708288, 0.0055171014, 0.0030430546, -0.0034094958, 0.04027666, 0.001353101, -0.01268205, 0.01268205, 0.0058357455, -0.0039648474, -0.010943161, -0.017780362, 0.0073788953, -0.009668583, -0.015076435, 0.009541126, -0.018253775, 0.0017718908, 0.04766921, 0.022086613, -0.015167477, -0.036853507, -0.030753743, -0.009941707, -0.019555666, -0.012745778, -0.0078113414, -0.004199279, 0.008598848, 0.008776379, -0.002785863, -0.015522538, 0.012345197, 0.017024718, -0.02066637, -0.001354239, 0.00083814876, -0.009941707, 0.0008660301, 0.012618321, 0.009686791, -0.0005698615, 0.010615413, 0.03648934, 0.017234113, 0.027458047, 0.011899095, 0.011325534, 0.0036939997, 0.029442748, 0.00063785794, -0.041806154, -0.012946069, -0.006209015, -0.009805146, -0.0064411703, 0.007934247, -0.00050527905, 0.00769754, -0.064784974, 0.03180982, -0.013501421, -0.037017383, -0.00048763983, -0.0039011186, -0.033648856, 0.005826642, -0.042097487, -0.011389264, -0.00038607192, -0.010952265, -0.02483606, 0.024271604, 0.022997025, 0.032082945, -0.0014111397, 0.024016688, 0.046139717, -0.0035096412, -0.04151482, 0.036689635, 0.0110159945, -0.017907819, -0.011553138, 0.0061361818, 0.011088828, 0.008494151]": "ter science and engineering fromZhengzhou University, Zhengzhou, and the Ph.D.degree in computer architecture from the Huazhong\nUniversity of Science and Technology, Wuhan.\nHe is currently a Lecturer with the Henan\nUniversity of Economics and Law. His currentresearch interests focus on Internet security and\nnonvolatile memory systems.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. 6758 IEEE TRANSACTIONS ON CONSUMER ELECTRONICS, VOL. 70, NO. 4, NOVEMBER 2024\nMing Liu received the Ph.D. degree from Monash\nUniversity in 2019. He joined the School ofIT, Deakin University as a Research Fellowlater and became an Assistant Professor in\n2022. His main research area includes natural\nlanguage processing, machine learning, and con-tinual learning. He is a member of the ChinaComputer Federation Technical Committee of\nNatural Language Processing and a Program\nMember of the Association of ComputationalLinguis"}
{"[-0.087233335, 0.089932024, 0.032530155, -0.021279536, 0.029412074, 0.0304332, -0.0453307, -0.034353595, -0.038766317, 0.016210375, 0.007982105, 0.069181286, -0.073703416, -0.04642476, -0.031855483, -0.070384756, -0.0031887393, 0.012873481, -0.03566647, 0.02246477, 0.045403637, 0.042668477, 0.032767203, 0.10087266, -0.03362422, -0.072755225, -0.018781424, 0.041647352, 0.028135667, 0.010676237, 0.031034935, 0.13070412, 0.11560605, -0.021662457, 0.041173257, 0.03931335, 0.035028268, -0.03807341, 0.036724064, -0.018115869, -0.027296884, 0.043033164, -0.032402515, 0.030414965, 0.072135255, -0.0040411972, 0.021352474, -0.014724271, -0.032730732, 0.053244423, -0.05039986, -0.008109746, 0.006733049, 0.036797002, 0.034390062, 0.009016907, -0.007275522, 0.023303553, -0.008360469, -0.013466098, 0.022428302, 0.026293993, -0.014159005, -0.02747923, 0.052989144, 0.043871947, -0.0017368258, -0.04172029, 0.035921752, 0.0087980945, -0.0034440209, -0.02777098, -0.017897056, -0.027005134, 0.01934669, 0.004718149, 0.009003231, -0.04219438, 0.045257762, 0.009007789, 0.004360299, 0.008980438, 0.0012946419, 0.046607107, -0.032475453, -0.025765195, 0.0269869, -0.009098962, -0.005160333, 0.00010919267, 0.027625104, 0.0026645006, -0.009892157, 0.006851573, 0.037307564, -0.01193441, -0.0660085, 0.014915733, 0.027333353, 0.02860976, 0.006518795, -0.008875591, -0.0093132155, 0.0075763897, 0.032238405, -0.051165704, 0.024269976, -0.017213266, -0.060902867, -0.05484905, -0.017650891, -0.011670011, 0.017195031, -0.0031226396, 0.0048366725, 0.022428302, 0.028846808, -0.049561076, -0.0009943442, 0.000718549, 0.012846129, 0.0070247995, 0.031490795, -0.012709371, 0.0092266025, 0.078116134, -0.0012171457, 0.0006609967, 0.021042489, -0.017550603, 0.023030037, -0.0023077903, -0.04401782, 0.046862386, -0.02656751, 0.017796766, -0.008105188, -0.019000236, 0.034390062, -0.006555264, -0.039240412, 0.029302668, 0.0528068, -0.018097633, -0.009190134, -0.018608198, 0.015344241, 0.023686476, -0.012481442, 0.010539479, -0.020495456, 0.058204178, -0.026166353, 0.008738833, 0.004804762, 0.01170648, -0.025145227, 0.012472324, -0.01989372, -0.004490219, -0.069071874, -0.0014257015, 0.013602857, -0.033387173, 0.019948425, -0.009399829, 0.031271983, 0.007266405, -0.024634663, -0.0067740767, 0.00011930706, 0.0072025848, -0.01635625, 0.041501477, 0.0047272663, 0.014933967, 0.010840346, 0.028427416, 0.00012764074, -0.03475475, -0.039532162, 0.01303759, -0.002009202, -0.018589962, 0.011907058, -0.004540364, -0.0053016497, 0.024178803, 0.013684911, -0.023394724, -0.020531924, -0.027223947, -0.007234495, 0.009231161, -0.018963767, -0.015243951, 0.008533696, 0.0046907975, 0.020495456, -0.009272188, -0.029740293, 0.010612416, 0.010548595, -0.022701818, 0.007216261, -0.0076857964, -0.011505901, 0.023595303, 0.003254839, 0.016237726, 0.0022713214, 0.014642217, 0.0061039627, 0.014168123, 0.00715244, 0.026020477, 0.017951759, 0.0064367405, 0.032858375, -0.016757406, -0.046862386, -0.019000236, -0.010995339, -0.014560162, -0.007859023, 0.0018963767, 0.016319782, 0.02682279, -0.07957488, 0.012189691, -0.02034958, -0.057438336, -0.013912841, 0.023267085, -0.010348017, -0.006609967, -0.037453443, -0.004540364, -0.025637556, -0.015307772, -0.024361148, 0.02727865, 0.038948663, 0.043981355, 0.016848579, 0.0088847075, 0.03872985, -0.02425174, -0.022774756, 0.03249369, 0.02416057, -0.024069397, -0.016538594, 0.0013937913, 0.0034622552, -0.004918727]": "ine learning, and con-tinual learning. He is a member of the ChinaComputer Federation Technical Committee of\nNatural Language Processing and a Program\nMember of the Association of ComputationalLinguistics.\nHui Xu received the Ph.D. degree in computer archi-\ntecture from the Huazhong University of Science and\nTechnology, Wuhan.\nShe is currently an Assistant Researcher with\nthe China Academy of Industrial Internet, Beijing,\nChina. Her research interests focus on deep learning,\ndata privacy, and industrial Internet security. Shehas served as a Reviewer for international confer-ences or journals, such as HPCC, ICPADS, and\nCybersecurity .\nZhanbo Li received the M.S. degree from Sun\nYat-sen University in 1993. He has participatedin more than ten provincial science and technol-ogy research projects and has undertaken several\nnetwork engineering planning and design, provincial\nand municipal information construction planning,and software development projects, with richexperience in system desig"}
{"[-0.09297636, 0.0926812, 0.0036826201, -0.029276485, 0.06940021, 0.012692011, -0.057077155, -0.03936737, -0.07718514, -0.047004715, 0.018290885, 0.04814847, -0.07013812, -0.046045434, 0.0017640603, -0.075045206, 0.0021064957, 0.019388523, -0.00820461, 0.042909328, 0.04785331, 0.01273813, 0.026453989, 0.06423486, -0.039588742, -0.03051248, -0.026546227, -0.021546902, 0.013881887, 0.01972058, 0.019941954, 0.10957928, 0.15031178, -0.039478056, 0.044126876, 0.018429242, 0.015643641, -0.048037786, 0.039551847, -0.003449718, -0.027505506, 0.017986499, 0.0075266575, 0.031877607, 0.045971643, 0.0037886945, -0.02898132, -0.029811468, 0.0001314398, 0.037208993, -0.07356939, 0.018189423, 0.008342968, 0.0021203314, 0.03881394, 0.010293812, -0.011631269, -0.011741955, -0.0037010678, -0.0069132717, -0.0031914504, -0.005368278, 0.0016245497, -0.021122605, 0.032080535, 0.014333855, -0.021823619, -0.046930924, 0.03650798, -0.009574351, -0.030457137, -0.028759949, -0.037891556, -0.002923959, 0.018346228, 0.050583567, 0.050362196, -0.036323503, 0.019148702, 0.004531214, 0.0133192325, -0.0036088293, 0.023594595, 0.02804049, -0.0495136, -0.037596393, 0.018420018, -0.0036803142, -0.0025919005, -0.014398422, 0.025310231, -0.019923506, 0.0069962866, 0.009602022, 0.049734972, -0.0077849254, -0.06755544, 0.007974014, 0.019794371, 0.027487058, -0.001969291, 0.00357424, -0.028409444, 0.008246117, 0.03689538, -0.029055113, 0.02427716, -0.02091968, -0.05951225, -0.05637614, -0.0008612765, -0.029221142, 0.012267714, -0.0048978617, 0.043462757, 0.008047805, 0.0056449934, -0.040142175, 0.020587623, -0.01640922, -0.0016879636, -0.0026703032, 0.031822264, -0.051505953, -0.0006975533, 0.046377495, 0.010764227, 0.028095832, 0.012258491, -0.021473112, 0.009685038, -0.010109334, -0.043020014, 0.044053085, -0.012184699, 0.009085488, -0.0053913374, -0.019111807, 0.030309556, 0.0021180254, -0.034238912, -0.0044205277, 0.049070857, -0.0124152955, 0.0068118097, -0.020698309, 0.0479271, 0.027173448, -0.03259707, 0.0039639473, -0.01134533, 0.049661182, -0.022413943, -0.008910234, -0.016104834, 0.0012913384, -0.031748474, -0.007904835, -0.026878284, 0.026453989, -0.083900094, -0.0070008985, -0.0049808766, -0.0030807643, -0.005774127, -0.03711675, 0.0055250833, -0.022598421, -0.01645534, -0.027579296, 0.018023394, -0.010736556, 0.013208547, 0.019314732, -0.004178402, 0.0039501116, 0.0071208086, -0.022450838, 0.0051653534, -0.028058937, -0.037208993, 0.018881211, -0.023465462, -0.017958827, 0.0012878794, -0.004637288, 0.0011195441, 0.02341012, 0.018106408, -0.0399577, -0.012867264, -0.017589873, 0.010515183, -0.012276938, 0.007914059, -0.032320354, 0.027284134, 0.018742854, 0.013466814, -0.01972058, -0.05161664, 0.013909559, 0.0013778119, -0.02986681, -0.013540605, 0.023299433, -0.007074689, -0.008407535, 0.004448199, -0.010828794, 0.010422945, -0.021860514, 0.015957251, 0.02036625, -0.0035373445, 0.008550504, 0.025789872, -0.003638807, 0.022746002, 0.013568277, -0.033962198, 0.023465462, -0.0059447684, -0.029460961, -0.018318556, -0.00041392006, 0.01964679, 0.016132506, -0.05478964, 0.024553876, -0.0031937563, -0.034626316, -0.011022495, -0.02652778, 0.0033551736, -0.02276445, -0.015662089, 0.009961753, -0.019240942, -0.016436892, -0.0153853735, 0.019296285, 0.02012643, 0.056781992, -0.0027694595, 0.0029008994, 0.019038016, 0.010192349, -0.01561597, 0.042060733, 0.006613497, -0.0049808766, -0.019628342, 0.018161751, 0.01153903, -0.007632732]": "ts and has undertaken several\nnetwork engineering planning and design, provincial\nand municipal information construction planning,and software development projects, with richexperience in system design, development, and\nengineering implementation. His research interests\ninclude network security, e-government, and urbaninformatization.\nZhigao Zheng (Member, IEEE) received the\nPh.D. degree from the Huazhong Universityof Science and Technology, Wuhan, China. Hepublished more than 20 peer-reviewed publica-\ntions (such as the IEEE T\nRANSACTIONS ON\nPARALLEL AND DISTRIBUTED SYSTEMS ,a n d\nIEEE T RANSACTIONS ON COMPUTERS ). He joins\nresearch projects from various governmental and\nindustrial organizations, such as the National\nScience Foundation of China, the Ministry ofScience and Technology, and the Ministry of\nEducation. His current research interests focus on cloud computing, big data\nprocessing, and AI systems. He is also an Editorial Board Member of some\nhigh quality journals, such as the"}
{"[-0.07960119, 0.046890873, 0.001419655, -0.0156059265, 0.06465312, 0.03254585, -0.053652223, -0.050984234, -0.074009374, 0.01021512, -0.01662013, 0.07711594, -0.10182227, -0.0354514, -0.027027126, -0.048425883, -0.03903309, 0.004696397, -0.017150072, 0.046525396, -0.013138947, 0.06034048, 0.006829877, 0.08106311, -0.029695118, -0.063995264, -0.010224258, 0.02881797, 0.009648629, -0.049449224, -0.0021277694, 0.14151323, 0.112567335, -0.019516544, 0.02373782, 0.06991601, 0.02923827, -0.061948583, 0.048096955, -0.015121668, -0.06428765, -0.01021512, -0.016519623, 0.021362212, 0.021051554, 0.001972441, -0.021526676, -0.0058430857, -0.004161885, -0.0036821945, -0.04915684, 0.022312455, -0.012992756, -0.017387634, 0.028945887, -0.009109548, -0.0028073308, 0.035506222, -0.012508498, -0.013604932, 0.008693817, -0.045830987, 0.028598683, -0.02265966, 0.03176007, 0.004751219, -0.019370353, -0.062094774, 0.022696206, 0.017013019, 0.017287128, -0.05946333, -0.006094352, -0.011804951, 0.015816076, 0.0012746059, 0.03645647, -0.040275715, 0.02229418, 0.004495384, -0.009986697, -0.012864838, 0.015889172, 0.011183638, -0.024889078, -0.0405681, 0.03563414, -0.015021161, -0.031997632, -0.016145008, 0.049120292, -0.023134781, -0.0005345121, 0.020631254, 0.056027833, 0.013467878, -0.037297066, 0.021709416, 0.014080054, 0.020137858, 0.013138947, 0.0013911021, -0.0047831982, 0.037333615, 0.05171519, -0.01746073, 0.027776357, 0.010489229, -0.05357913, -0.040458456, -0.041006673, -0.03477527, 0.022093168, -0.015907446, 0.05376187, -0.0038626494, 0.026241347, -0.0073552523, -0.012206977, -0.03870416, 0.021910429, 0.004390309, 0.04378431, -0.06596885, 0.010799886, 0.019114519, 0.0014402132, 0.0120973345, 0.015551105, -0.006857288, 0.012965345, -0.015094257, -0.04137215, 0.027155044, -0.014811011, -0.02298859, 0.009237465, -0.00844255, 0.029950952, -0.005610093, -0.04612337, 0.011083132, 0.04305335, 0.0076247924, 0.0030334706, -0.059901904, 0.042724423, 0.0333499, 0.006893836, 0.0019792938, -0.010553188, 0.008273517, -0.019004876, -0.004769493, -0.0025606328, -0.010269943, -0.020722624, -0.024724612, -0.027045399, -0.0048654308, -0.06428765, -0.0019210457, -0.007857785, -0.023774369, 0.012133882, -0.035213843, 0.02265966, 0.0003894629, -0.013550111, -0.011695308, 0.03176007, -0.007551697, 0.011503432, 0.041810725, 0.013906452, 0.019991666, 0.012855702, 0.014445533, 0.0039083343, -0.026935756, -0.03623718, 0.026789565, -0.003353264, -0.021599771, -0.00093139877, -0.039690953, 0.015916582, 0.035652414, 0.018803863, -0.03022506, -0.020594707, -9.186927e-05, -0.014354163, -0.020302324, -0.011439473, -0.022111442, 0.021581497, 0.018356152, 0.01902315, 0.008086209, -0.040348813, 0.0054776073, 0.010827296, -0.032107275, -0.0127095105, -0.000209579, -0.0062999334, 0.015788665, 0.0065466315, 0.017214032, 0.028251478, 0.004732945, 0.02415812, 0.04780457, 0.013787672, 0.019479997, 0.017515551, -0.0032824527, 0.008255242, -0.0059938454, -0.050143633, -0.010425271, 0.00062131323, -0.010946077, 0.013212043, 0.0022613974, -0.008602447, 0.027100222, -0.058695827, 0.032984424, -0.016154144, -0.039764047, 0.0015167353, -0.027886, -0.02839767, -0.015587653, -0.022769302, -0.027027126, -0.0056192297, -0.016501348, -0.028982434, 0.01769829, 0.033843298, 0.035871703, 0.0008714375, 0.0009987839, 0.015331818, -0.011768403, -0.01589831, 0.041847274, 0.00793088, 0.011530843, -0.022769302, 0.015551105, 0.03059054, 0.02163632]": "the Ministry of\nEducation. His current research interests focus on cloud computing, big data\nprocessing, and AI systems. He is also an Editorial Board Member of some\nhigh quality journals, such as the IEEE T\nRANSACTIONS ON CONSUMER\nELECTRONICS andMobile Networks and Applications . He is a PC member\nof several TOP conferences, such as TheWebConf (formally WWW) and\nNeurIPS, and the Vice PC Chair of CPSCom 2023. He is an ExecutiveCommittee Member of the Technical Committee on Distributed Computingand Systems and Embedded Systems of CCF. He is a member of ACM\nand CCF.\nAuthorized licensed use limited to: Zhengzhou University. Downloaded on May 04,2025 at 03:23:27 UTC from IEEE Xplore.  Restrictions apply. "}
